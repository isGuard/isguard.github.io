<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>代理Google站点</title>
    <url>/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/</url>
    <content><![CDATA[<h2 id="创建-Worker"><a href="#创建-Worker" class="headerlink" title="创建 Worker"></a>创建 Worker</h2><p>首先，登录 Cloudflare，切换至Workers &amp; Pages菜单，点击Create Application按钮：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image.png" class="" alt="alt text">

<p>然后，点击Create Worker按钮新建一个 Worker：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-1.png" class="" alt="alt text">

<p>接着，设置一个三级域名 g.harrisonwang.workers.dev，点击Deploy按钮：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-2.png" class="" alt="alt text">

<p>再接着，我们点击Edit code按钮编辑代码：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-3.png" class="" alt="alt text">

<p>最后，粘贴以下代码片段后，点击Save and Deploy完成部署，然后通过域名 g.harrisonwang.workers.dev 访问镜像站：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 反代目标网站</span></span><br><span class="line"><span class="keyword">const</span> upstream = <span class="string">&#x27;ipv6.google.com.hk&#x27;</span></span><br><span class="line"><span class="keyword">const</span> upstream_v4 = <span class="string">&#x27;www.google.com.hk&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 访问区域黑名单（按需设置）.</span></span><br><span class="line"><span class="keyword">const</span> blocked_region = [<span class="string">&#x27;TK&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">//资源重定向</span></span><br><span class="line"><span class="keyword">const</span> replace_dict = &#123;</span><br><span class="line">  <span class="attr">$upstream</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;www.google.com/&#x27;</span>: <span class="string">&#x27;g.wss.so/&#x27;</span>, <span class="comment">//填入你的子域名</span></span><br><span class="line">  <span class="string">&#x27;gstatic.com&#x27;</span>: <span class="string">&#x27;gstatic.cn&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;ajax.googleapis.com&#x27;</span>: <span class="string">&#x27;ajax.lug.ustc.edu.cn&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;fonts.googleapis.com&#x27;</span>: <span class="string">&#x27;fonts.googleapis.cn&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;themes.googleusercontent.com&#x27;</span>: <span class="string">&#x27;google-themes.lug.ustc.edu.cn&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;www.gravatar.com/avatar&#x27;</span>: <span class="string">&#x27;dn-qiniu-avatar.qbox.me/avatar&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;www.google.co.jp&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;www.google.com.sg&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;books.google.com.hk&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;books.google.co.jp&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;books.google.com.sg&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;maps.google.com.hk&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;maps.google.co.jp&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;maps.google.com.sg&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;maps.google.com&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">  <span class="string">&#x27;books.google.com&#x27;</span>: <span class="string">&#x27;$custom_domain&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="title function_">addEventListener</span>(<span class="string">&#x27;fetch&#x27;</span>, <span class="function">(<span class="params">event</span>) =&gt;</span> &#123;</span><br><span class="line">  event.<span class="title function_">respondWith</span>(<span class="title function_">fetchAndApply</span>(event.<span class="property">request</span>))</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">fetchAndApply</span>(<span class="params">request</span>) &#123;</span><br><span class="line">  <span class="keyword">const</span> region = request.<span class="property">headers</span>.<span class="title function_">get</span>(<span class="string">&#x27;cf-ipcountry&#x27;</span>).<span class="title function_">toUpperCase</span>()</span><br><span class="line"><span class="comment">//   const ip_address = request.headers.get(&#x27;cf-connecting-ip&#x27;)</span></span><br><span class="line"><span class="comment">//   const user_agent = request.headers.get(&#x27;user-agent&#x27;)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> response = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">let</span> url = <span class="keyword">new</span> <span class="title function_">URL</span>(request.<span class="property">url</span>)</span><br><span class="line">  <span class="keyword">let</span> url_host = url.<span class="property">host</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (url.<span class="property">protocol</span> == <span class="string">&#x27;http:&#x27;</span>) &#123;</span><br><span class="line">    url.<span class="property">protocol</span> = <span class="string">&#x27;https:&#x27;</span></span><br><span class="line">    response = <span class="title class_">Response</span>.<span class="title function_">redirect</span>(url.<span class="property">href</span>)</span><br><span class="line">    <span class="keyword">return</span> response</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//检查是否为图片搜索</span></span><br><span class="line">  <span class="keyword">var</span> key = url.<span class="property">href</span></span><br><span class="line">  <span class="keyword">var</span> ikey1 = <span class="string">&#x27;tbm=isch&#x27;</span></span><br><span class="line">  <span class="keyword">var</span> ikey2 = <span class="string">&#x27;/img&#x27;</span></span><br><span class="line">  <span class="keyword">if</span> ((key.<span class="title function_">search</span>(ikey1) == -<span class="number">1</span>) &amp;&amp; (key.<span class="title function_">search</span>(ikey2) == -<span class="number">1</span>)) &#123;</span><br><span class="line">    <span class="keyword">var</span> upstream_domain = upstream</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> upstream_domain = upstream_v4</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  url.<span class="property">host</span> = upstream_domain</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (blocked_region.<span class="title function_">includes</span>(region)) &#123;</span><br><span class="line">    response = <span class="keyword">new</span> <span class="title class_">Response</span>(</span><br><span class="line">      <span class="string">&#x27;Access denied: WorkersProxy is not available in your region yet.&#x27;</span>,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">status</span>: <span class="number">403</span>,</span><br><span class="line">      &#125;</span><br><span class="line">    )</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">let</span> method = request.<span class="property">method</span></span><br><span class="line">    <span class="keyword">let</span> request_headers = request.<span class="property">headers</span></span><br><span class="line">    <span class="keyword">let</span> new_request_headers = <span class="keyword">new</span> <span class="title class_">Headers</span>(request_headers)</span><br><span class="line"></span><br><span class="line">    new_request_headers.<span class="title function_">set</span>(<span class="string">&#x27;Host&#x27;</span>, upstream_domain)</span><br><span class="line">    new_request_headers.<span class="title function_">set</span>(<span class="string">&#x27;Referer&#x27;</span>, url.<span class="property">href</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> original_response = <span class="keyword">await</span> <span class="title function_">fetch</span>(url.<span class="property">href</span>, &#123;</span><br><span class="line">      <span class="attr">method</span>: method,</span><br><span class="line">      <span class="attr">headers</span>: new_request_headers,</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> original_response_clone = original_response.<span class="title function_">clone</span>()</span><br><span class="line">    <span class="keyword">let</span> original_text = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">let</span> response_headers = original_response.<span class="property">headers</span></span><br><span class="line">    <span class="keyword">let</span> new_response_headers = <span class="keyword">new</span> <span class="title class_">Headers</span>(response_headers)</span><br><span class="line">    <span class="keyword">let</span> status = original_response.<span class="property">status</span></span><br><span class="line"></span><br><span class="line">    new_response_headers.<span class="title function_">set</span>(<span class="string">&#x27;cache-control&#x27;</span>, <span class="string">&#x27;public, max-age=14400&#x27;</span>)</span><br><span class="line">    new_response_headers.<span class="title function_">set</span>(<span class="string">&#x27;access-control-allow-origin&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">    new_response_headers.<span class="title function_">set</span>(<span class="string">&#x27;access-control-allow-credentials&#x27;</span>, <span class="literal">true</span>)</span><br><span class="line">    new_response_headers.<span class="title function_">delete</span>(<span class="string">&#x27;content-security-policy&#x27;</span>)</span><br><span class="line">    new_response_headers.<span class="title function_">delete</span>(<span class="string">&#x27;content-security-policy-report-only&#x27;</span>)</span><br><span class="line">    new_response_headers.<span class="title function_">delete</span>(<span class="string">&#x27;clear-site-data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> content_type = new_response_headers.<span class="title function_">get</span>(<span class="string">&#x27;content-type&#x27;</span>)</span><br><span class="line">    <span class="keyword">if</span> (content_type.<span class="title function_">includes</span>(<span class="string">&#x27;text/html&#x27;</span>) &amp;&amp; content_type.<span class="title function_">includes</span>(<span class="string">&#x27;UTF-8&#x27;</span>)) &#123;</span><br><span class="line">      <span class="comment">// &amp;&amp; content_type.includes(&#x27;UTF-8&#x27;)</span></span><br><span class="line">      original_text = <span class="keyword">await</span> <span class="title function_">replace_response_text</span>(</span><br><span class="line">        original_response_clone,</span><br><span class="line">        upstream_domain,</span><br><span class="line">        url_host</span><br><span class="line">      )</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      original_text = original_response_clone.<span class="property">body</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    response = <span class="keyword">new</span> <span class="title class_">Response</span>(original_text, &#123;</span><br><span class="line">      status,</span><br><span class="line">      <span class="attr">headers</span>: new_response_headers,</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> response</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">replace_response_text</span>(<span class="params">response, upstream_domain, host_name</span>) &#123;</span><br><span class="line">  <span class="keyword">let</span> text = <span class="keyword">await</span> response.<span class="title function_">text</span>()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">var</span> i, j</span><br><span class="line">  <span class="keyword">for</span> (i <span class="keyword">in</span> replace_dict) &#123;</span><br><span class="line">    j = replace_dict[i]</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="string">&#x27;$upstream&#x27;</span>) &#123;</span><br><span class="line">      i = upstream_domain</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (i == <span class="string">&#x27;$custom_domain&#x27;</span>) &#123;</span><br><span class="line">      i = host_name</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (j == <span class="string">&#x27;$upstream&#x27;</span>) &#123;</span><br><span class="line">      j = upstream_domain</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (j == <span class="string">&#x27;$custom_domain&#x27;</span>) &#123;</span><br><span class="line">      j = host_name</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> re = <span class="keyword">new</span> <span class="title class_">RegExp</span>(i, <span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">    text = text.<span class="title function_">replace</span>(re, j)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> text</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>记得将 ‘<a href="http://www.google.com/">www.google.com/</a>‘: ‘g.wss.so&#x2F;‘, 此处的 g.wss.so 替换为你的子域名。</p>
</blockquote>
<p>至此，代理 Google 站点已完成，我们任意搜索输入一个关键字 strapi，搜索结果如下图图所示。但是由于国内 workers.dev 域名的 DNS 已污染导致无法访问，所以需要绑定一个自定义域名来绕过该问题。</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-4.png" class="" alt="alt text">

<h2 id="绑定自定义域名"><a href="#绑定自定义域名" class="headerlink" title="绑定自定义域名"></a>绑定自定义域名</h2><p>首先，点击Add Custom Domain添加一个自定义域名：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-5.png" class="" alt="alt text">

<p>然后，输入要绑定自定义域名如 g.wss.so，点击Add Custom Domain绑定：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-6.png" class="" alt="alt text">

<p>最后，等待 DNS 解析生效，然后使用 g.wss.so 域名访问：</p>
<img data-src="/2024/06/24/cloudflare/%E4%BB%A3%E7%90%86Google%E7%AB%99%E7%82%B9/image-7.png" class="" alt="alt text">

]]></content>
      <categories>
        <category>cloudflare</category>
      </categories>
      <tags>
        <tag>cloudflare</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker安装</title>
    <url>/2024/04/08/docker/Docker%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="使用官方安装脚本自动安装"><a href="#使用官方安装脚本自动安装" class="headerlink" title="使用官方安装脚本自动安装"></a>使用官方安装脚本自动安装</h2><p>安装命令如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://get.docker.com | bash -s docker --mirror Aliyun</span><br></pre></td></tr></table></figure>

<p>也可以使用国内 daocloud 一键安装命令：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -sSL https://get.daocloud.io/docker | sh</span><br></pre></td></tr></table></figure>

<h2 id="手动安装"><a href="#手动安装" class="headerlink" title="手动安装"></a>手动安装</h2><h3 id="卸载旧版本"><a href="#卸载旧版本" class="headerlink" title="卸载旧版本"></a>卸载旧版本</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum remove docker \</span><br><span class="line">                 docker-client \</span><br><span class="line">                 docker-client-latest \</span><br><span class="line">                 docker-common \</span><br><span class="line">                 docker-latest \</span><br><span class="line">                 docker-latest-logrotate \</span><br><span class="line">                 docker-logrotate \</span><br><span class="line">                 docker-engine</span><br></pre></td></tr></table></figure>

<h3 id="使用-Docker-仓库进行安装"><a href="#使用-Docker-仓库进行安装" class="headerlink" title="使用 Docker 仓库进行安装"></a>使用 Docker 仓库进行安装</h3><p>在新主机上首次安装 Docker Engine-Community 之前，需要设置 Docker 仓库。之后，您可以从仓库安装和更新 Docker。</p>
<h4 id="设置仓库"><a href="#设置仓库" class="headerlink" title="设置仓库"></a>设置仓库</h4><p>安装所需的软件包。yum-utils 提供了 yum-config-manager ，并且 device mapper 存储驱动程序需要 device-mapper-persistent-data 和 lvm2。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure>

<p>使用以下命令来设置稳定的仓库。</p>
<h5 id="使用官方源地址（比较慢）"><a href="#使用官方源地址（比较慢）" class="headerlink" title="使用官方源地址（比较慢）"></a>使用官方源地址（比较慢）</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<h5 id="阿里云"><a href="#阿里云" class="headerlink" title="阿里云"></a>阿里云</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<h5 id="清华大学源"><a href="#清华大学源" class="headerlink" title="清华大学源"></a>清华大学源</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure>

<h3 id="安装-Docker-Engine-Community"><a href="#安装-Docker-Engine-Community" class="headerlink" title="安装 Docker Engine-Community"></a>安装 Docker Engine-Community</h3><p>安装</p>
<p>最新版本的 Docker Engine-Community 和 containerd，或者转到下一步安装特定版本：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure>

<p>如果提示您接受 GPG 密钥，请选是。</p>
<blockquote>
<p><strong>有多个 Docker 仓库吗？</strong></p>
<p>如果启用了多个 Docker 仓库，则在未在 yum install 或 yum update 命令中指定版本的情况下，进行的安装或更新将始终安装最高版本，这可能不适合您的稳定性需求。</p>
</blockquote>
<p>Docker 安装完默认未启动。并且已经创建好 docker 用户组，但该用户组下没有用户。</p>
<p><strong>要安装特定版本的 Docker Engine-Community，请在存储库中列出可用版本，然后选择并安装：</strong></p>
<p>1、列出并排序您存储库中可用的版本。此示例按版本号（从高到低）对结果进行排序。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | <span class="built_in">sort</span> -r</span><br><span class="line"></span><br><span class="line">docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable</span><br></pre></td></tr></table></figure>

<p>2、通过其完整的软件包名称安装特定版本，该软件包名称是软件包名称（docker-ce）加上版本字符串（第二列），从第一个冒号（:）一直到第一个连字符，并用连字符（-）分隔。例如：docker-ce-18.09.1。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io</span><br></pre></td></tr></table></figure>

<p>启动 Docker。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo systemctl start docker</span><br></pre></td></tr></table></figure>

<p>通过运行 hello-world 映像来验证是否正确安装了 Docker Engine-Community 。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure>

<h3 id="卸载-docker"><a href="#卸载-docker" class="headerlink" title="卸载 docker"></a>卸载 docker</h3><p>删除安装包：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove docker-ce</span><br></pre></td></tr></table></figure>

<p>删除镜像、容器、配置文件等内容：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /var/lib/docker</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker安装Redis</title>
    <url>/2024/06/25/docker/Docker%E5%AE%89%E8%A3%85Redis/</url>
    <content><![CDATA[<h2 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a>拉取镜像</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull redis</span><br></pre></td></tr></table></figure>

<h2 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir -p ~/redis/&#123;conf,data&#125;</span><br><span class="line">vim ~/redis/conf/redis.conf</span><br></pre></td></tr></table></figure>

<p>把下面的代码粘贴到redis.conf中即（该配置已经#daemonize yes，和设置requirepass 123456）</p>
<h3 id="完整redis-conf"><a href="#完整redis-conf" class="headerlink" title="完整redis.conf"></a>完整redis.conf</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"># Redis configuration file example.</span><br><span class="line">#</span><br><span class="line"># Note that in order to read the configuration file, Redis must be</span><br><span class="line"># started with the file path as first argument:</span><br><span class="line">#</span><br><span class="line"># ./redis-server /path/to/redis.conf</span><br><span class="line"> </span><br><span class="line"># Note on units: when memory size is needed, it is possible to specify</span><br><span class="line"># it in the usual form of 1k 5GB 4M and so forth:</span><br><span class="line">#</span><br><span class="line"># 1k =&gt; 1000 bytes</span><br><span class="line"># 1kb =&gt; 1024 bytes</span><br><span class="line"># 1m =&gt; 1000000 bytes</span><br><span class="line"># 1mb =&gt; 1024*1024 bytes</span><br><span class="line"># 1g =&gt; 1000000000 bytes</span><br><span class="line"># 1gb =&gt; 1024*1024*1024 bytes</span><br><span class="line">#</span><br><span class="line"># units are case insensitive so 1GB 1Gb 1gB are all the same.</span><br><span class="line"> </span><br><span class="line">################################## INCLUDES ###################################</span><br><span class="line"> </span><br><span class="line"># Include one or more other config files here.  This is useful if you</span><br><span class="line"># have a standard template that goes to all Redis servers but also need</span><br><span class="line"># to customize a few per-server settings.  Include files can include</span><br><span class="line"># other files, so use this wisely.</span><br><span class="line">#</span><br><span class="line"># Notice option &quot;include&quot; won&#x27;t be rewritten by command &quot;CONFIG REWRITE&quot;</span><br><span class="line"># from admin or Redis Sentinel. Since Redis always uses the last processed</span><br><span class="line"># line as value of a configuration directive, you&#x27;d better put includes</span><br><span class="line"># at the beginning of this file to avoid overwriting config change at runtime.</span><br><span class="line">#</span><br><span class="line"># If instead you are interested in using includes to override configuration</span><br><span class="line"># options, it is better to use include as the last line.</span><br><span class="line">#</span><br><span class="line"># include /path/to/local.conf</span><br><span class="line"># include /path/to/other.conf</span><br><span class="line"> </span><br><span class="line">################################## MODULES #####################################</span><br><span class="line"> </span><br><span class="line"># Load modules at startup. If the server is not able to load modules</span><br><span class="line"># it will abort. It is possible to use multiple loadmodule directives.</span><br><span class="line">#</span><br><span class="line"># loadmodule /path/to/my_module.so</span><br><span class="line"># loadmodule /path/to/other_module.so</span><br><span class="line"> </span><br><span class="line">################################## NETWORK #####################################</span><br><span class="line"> </span><br><span class="line"># By default, if no &quot;bind&quot; configuration directive is specified, Redis listens</span><br><span class="line"># for connections from all the network interfaces available on the server.</span><br><span class="line"># It is possible to listen to just one or multiple selected interfaces using</span><br><span class="line"># the &quot;bind&quot; configuration directive, followed by one or more IP addresses.</span><br><span class="line">#</span><br><span class="line"># Examples:</span><br><span class="line">#</span><br><span class="line"># bind 192.168.1.100 10.0.0.1</span><br><span class="line"># bind 127.0.0.1 ::1</span><br><span class="line">#</span><br><span class="line"># ~~~ WARNING ~~~ If the computer running Redis is directly exposed to the</span><br><span class="line"># internet, binding to all the interfaces is dangerous and will expose the</span><br><span class="line"># instance to everybody on the internet. So by default we uncomment the</span><br><span class="line"># following bind directive, that will force Redis to listen only into</span><br><span class="line"># the IPv4 lookback interface address (this means Redis will be able to</span><br><span class="line"># accept connections only from clients running into the same computer it</span><br><span class="line"># is running).</span><br><span class="line">#</span><br><span class="line"># IF YOU ARE SURE YOU WANT YOUR INSTANCE TO LISTEN TO ALL THE INTERFACES</span><br><span class="line"># JUST COMMENT THE FOLLOWING LINE.</span><br><span class="line"># ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~</span><br><span class="line">bind *</span><br><span class="line"> </span><br><span class="line"># Protected mode is a layer of security protection, in order to avoid that</span><br><span class="line"># Redis instances left open on the internet are accessed and exploited.</span><br><span class="line">#</span><br><span class="line"># When protected mode is on and if:</span><br><span class="line">#</span><br><span class="line"># 1) The server is not binding explicitly to a set of addresses using the</span><br><span class="line">#    &quot;bind&quot; directive.</span><br><span class="line"># 2) No password is configured.</span><br><span class="line">#</span><br><span class="line"># The server only accepts connections from clients connecting from the</span><br><span class="line"># IPv4 and IPv6 loopback addresses 127.0.0.1 and ::1, and from Unix domain</span><br><span class="line"># sockets.</span><br><span class="line">#</span><br><span class="line"># By default protected mode is enabled. You should disable it only if</span><br><span class="line"># you are sure you want clients from other hosts to connect to Redis</span><br><span class="line"># even if no authentication is configured, nor a specific set of interfaces</span><br><span class="line"># are explicitly listed using the &quot;bind&quot; directive.</span><br><span class="line">protected-mode yes</span><br><span class="line"> </span><br><span class="line"># Accept connections on the specified port, default is 6379 (IANA #815344).</span><br><span class="line"># If port 0 is specified Redis will not listen on a TCP socket.</span><br><span class="line">port 6379</span><br><span class="line"> </span><br><span class="line"># TCP listen() backlog.</span><br><span class="line">#</span><br><span class="line"># In high requests-per-second environments you need an high backlog in order</span><br><span class="line"># to avoid slow clients connections issues. Note that the Linux kernel</span><br><span class="line"># will silently truncate it to the value of /proc/sys/net/core/somaxconn so</span><br><span class="line"># make sure to raise both the value of somaxconn and tcp_max_syn_backlog</span><br><span class="line"># in order to get the desired effect.</span><br><span class="line">tcp-backlog 511</span><br><span class="line"> </span><br><span class="line"># Unix socket.</span><br><span class="line">#</span><br><span class="line"># Specify the path for the Unix socket that will be used to listen for</span><br><span class="line"># incoming connections. There is no default, so Redis will not listen</span><br><span class="line"># on a unix socket when not specified.</span><br><span class="line">#</span><br><span class="line"># unixsocket /tmp/redis.sock</span><br><span class="line"># unixsocketperm 700</span><br><span class="line"> </span><br><span class="line"># Close the connection after a client is idle for N seconds (0 to disable)</span><br><span class="line">timeout 0</span><br><span class="line"> </span><br><span class="line"># TCP keepalive.</span><br><span class="line">#</span><br><span class="line"># If non-zero, use SO_KEEPALIVE to send TCP ACKs to clients in absence</span><br><span class="line"># of communication. This is useful for two reasons:</span><br><span class="line">#</span><br><span class="line"># 1) Detect dead peers.</span><br><span class="line"># 2) Take the connection alive from the point of view of network</span><br><span class="line">#    equipment in the middle.</span><br><span class="line">#</span><br><span class="line"># On Linux, the specified value (in seconds) is the period used to send ACKs.</span><br><span class="line"># Note that to close the connection the double of the time is needed.</span><br><span class="line"># On other kernels the period depends on the kernel configuration.</span><br><span class="line">#</span><br><span class="line"># A reasonable value for this option is 300 seconds, which is the new</span><br><span class="line"># Redis default starting with Redis 3.2.1.</span><br><span class="line">tcp-keepalive 300</span><br><span class="line"> </span><br><span class="line">################################# GENERAL #####################################</span><br><span class="line"> </span><br><span class="line"># By default Redis does not run as a daemon. Use &#x27;yes&#x27; if you need it.</span><br><span class="line"># Note that Redis will write a pid file in /var/run/redis.pid when daemonized.</span><br><span class="line">#daemonize yes</span><br><span class="line"> </span><br><span class="line"># If you run Redis from upstart or systemd, Redis can interact with your</span><br><span class="line"># supervision tree. Options:</span><br><span class="line">#   supervised no      - no supervision interaction</span><br><span class="line">#   supervised upstart - signal upstart by putting Redis into SIGSTOP mode</span><br><span class="line">#   supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET</span><br><span class="line">#   supervised auto    - detect upstart or systemd method based on</span><br><span class="line">#                        UPSTART_JOB or NOTIFY_SOCKET environment variables</span><br><span class="line"># Note: these supervision methods only signal &quot;process is ready.&quot;</span><br><span class="line">#       They do not enable continuous liveness pings back to your supervisor.</span><br><span class="line">supervised no</span><br><span class="line"> </span><br><span class="line"># If a pid file is specified, Redis writes it where specified at startup</span><br><span class="line"># and removes it at exit.</span><br><span class="line">#</span><br><span class="line"># When the server runs non daemonized, no pid file is created if none is</span><br><span class="line"># specified in the configuration. When the server is daemonized, the pid file</span><br><span class="line"># is used even if not specified, defaulting to &quot;/var/run/redis.pid&quot;.</span><br><span class="line">#</span><br><span class="line"># Creating a pid file is best effort: if Redis is not able to create it</span><br><span class="line"># nothing bad happens, the server will start and run normally.</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line"> </span><br><span class="line"># Specify the server verbosity level.</span><br><span class="line"># This can be one of:</span><br><span class="line"># debug (a lot of information, useful for development/testing)</span><br><span class="line"># verbose (many rarely useful info, but not a mess like the debug level)</span><br><span class="line"># notice (moderately verbose, what you want in production probably)</span><br><span class="line"># warning (only very important / critical messages are logged)</span><br><span class="line">loglevel notice</span><br><span class="line"> </span><br><span class="line"># Specify the log file name. Also the empty string can be used to force</span><br><span class="line"># Redis to log on the standard output. Note that if you use standard</span><br><span class="line"># output for logging but daemonize, logs will be sent to /dev/null</span><br><span class="line">logfile &quot;&quot;</span><br><span class="line"> </span><br><span class="line"># To enable logging to the system logger, just set &#x27;syslog-enabled&#x27; to yes,</span><br><span class="line"># and optionally update the other syslog parameters to suit your needs.</span><br><span class="line"># syslog-enabled no</span><br><span class="line"> </span><br><span class="line"># Specify the syslog identity.</span><br><span class="line"># syslog-ident redis</span><br><span class="line"> </span><br><span class="line"># Specify the syslog facility. Must be USER or between LOCAL0-LOCAL7.</span><br><span class="line"># syslog-facility local0</span><br><span class="line"> </span><br><span class="line"># Set the number of databases. The default database is DB 0, you can select</span><br><span class="line"># a different one on a per-connection basis using SELECT &lt;dbid&gt; where</span><br><span class="line"># dbid is a number between 0 and &#x27;databases&#x27;-1</span><br><span class="line">databases 16</span><br><span class="line"> </span><br><span class="line"># By default Redis shows an ASCII art logo only when started to log to the</span><br><span class="line"># standard output and if the standard output is a TTY. Basically this means</span><br><span class="line"># that normally a logo is displayed only in interactive sessions.</span><br><span class="line">#</span><br><span class="line"># However it is possible to force the pre-4.0 behavior and always show a</span><br><span class="line"># ASCII art logo in startup logs by setting the following option to yes.</span><br><span class="line">always-show-logo yes</span><br><span class="line"> </span><br><span class="line">################################ SNAPSHOTTING  ################################</span><br><span class="line">#</span><br><span class="line"># Save the DB on disk:</span><br><span class="line">#</span><br><span class="line">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">#</span><br><span class="line">#   Will save the DB if both the given number of seconds and the given</span><br><span class="line">#   number of write operations against the DB occurred.</span><br><span class="line">#</span><br><span class="line">#   In the example below the behaviour will be to save:</span><br><span class="line">#   after 900 sec (15 min) if at least 1 key changed</span><br><span class="line">#   after 300 sec (5 min) if at least 10 keys changed</span><br><span class="line">#   after 60 sec if at least 10000 keys changed</span><br><span class="line">#</span><br><span class="line">#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.</span><br><span class="line">#</span><br><span class="line">#   It is also possible to remove all the previously configured save</span><br><span class="line">#   points by adding a save directive with a single empty string argument</span><br><span class="line">#   like in the following example:</span><br><span class="line">#</span><br><span class="line">#   save &quot;&quot;</span><br><span class="line"> </span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"> </span><br><span class="line"># By default Redis will stop accepting writes if RDB snapshots are enabled</span><br><span class="line"># (at least one save point) and the latest background save failed.</span><br><span class="line"># This will make the user aware (in a hard way) that data is not persisting</span><br><span class="line"># on disk properly, otherwise chances are that no one will notice and some</span><br><span class="line"># disaster will happen.</span><br><span class="line">#</span><br><span class="line"># If the background saving process will start working again Redis will</span><br><span class="line"># automatically allow writes again.</span><br><span class="line">#</span><br><span class="line"># However if you have setup your proper monitoring of the Redis server</span><br><span class="line"># and persistence, you may want to disable this feature so that Redis will</span><br><span class="line"># continue to work as usual even if there are problems with disk,</span><br><span class="line"># permissions, and so forth.</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"> </span><br><span class="line"># Compress string objects using LZF when dump .rdb databases?</span><br><span class="line"># For default that&#x27;s set to &#x27;yes&#x27; as it&#x27;s almost always a win.</span><br><span class="line"># If you want to save some CPU in the saving child set it to &#x27;no&#x27; but</span><br><span class="line"># the dataset will likely be bigger if you have compressible values or keys.</span><br><span class="line">rdbcompression yes</span><br><span class="line"> </span><br><span class="line"># Since version 5 of RDB a CRC64 checksum is placed at the end of the file.</span><br><span class="line"># This makes the format more resistant to corruption but there is a performance</span><br><span class="line"># hit to pay (around 10%) when saving and loading RDB files, so you can disable it</span><br><span class="line"># for maximum performances.</span><br><span class="line">#</span><br><span class="line"># RDB files created with checksum disabled have a checksum of zero that will</span><br><span class="line"># tell the loading code to skip the check.</span><br><span class="line">rdbchecksum yes</span><br><span class="line"> </span><br><span class="line"># The filename where to dump the DB</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line"> </span><br><span class="line"># The working directory.</span><br><span class="line">#</span><br><span class="line"># The DB will be written inside this directory, with the filename specified</span><br><span class="line"># above using the &#x27;dbfilename&#x27; configuration directive.</span><br><span class="line">#</span><br><span class="line"># The Append Only File will also be created inside this directory.</span><br><span class="line">#</span><br><span class="line"># Note that you must specify a directory here, not a file name.</span><br><span class="line">dir ./</span><br><span class="line"> </span><br><span class="line">################################# REPLICATION #################################</span><br><span class="line"> </span><br><span class="line"># Master-Slave replication. Use slaveof to make a Redis instance a copy of</span><br><span class="line"># another Redis server. A few things to understand ASAP about Redis replication.</span><br><span class="line">#</span><br><span class="line"># 1) Redis replication is asynchronous, but you can configure a master to</span><br><span class="line">#    stop accepting writes if it appears to be not connected with at least</span><br><span class="line">#    a given number of slaves.</span><br><span class="line"># 2) Redis slaves are able to perform a partial resynchronization with the</span><br><span class="line">#    master if the replication link is lost for a relatively small amount of</span><br><span class="line">#    time. You may want to configure the replication backlog size (see the next</span><br><span class="line">#    sections of this file) with a sensible value depending on your needs.</span><br><span class="line"># 3) Replication is automatic and does not need user intervention. After a</span><br><span class="line">#    network partition slaves automatically try to reconnect to masters</span><br><span class="line">#    and resynchronize with them.</span><br><span class="line">#</span><br><span class="line"># slaveof &lt;masterip&gt; &lt;masterport&gt;</span><br><span class="line"> </span><br><span class="line"># If the master is password protected (using the &quot;requirepass&quot; configuration</span><br><span class="line"># directive below) it is possible to tell the slave to authenticate before</span><br><span class="line"># starting the replication synchronization process, otherwise the master will</span><br><span class="line"># refuse the slave request.</span><br><span class="line">#</span><br><span class="line"># masterauth &lt;master-password&gt;</span><br><span class="line"> </span><br><span class="line"># When a slave loses its connection with the master, or when the replication</span><br><span class="line"># is still in progress, the slave can act in two different ways:</span><br><span class="line">#</span><br><span class="line"># 1) if slave-serve-stale-data is set to &#x27;yes&#x27; (the default) the slave will</span><br><span class="line">#    still reply to client requests, possibly with out of date data, or the</span><br><span class="line">#    data set may just be empty if this is the first synchronization.</span><br><span class="line">#</span><br><span class="line"># 2) if slave-serve-stale-data is set to &#x27;no&#x27; the slave will reply with</span><br><span class="line">#    an error &quot;SYNC with master in progress&quot; to all the kind of commands</span><br><span class="line">#    but to INFO and SLAVEOF.</span><br><span class="line">#</span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"> </span><br><span class="line"># You can configure a slave instance to accept writes or not. Writing against</span><br><span class="line"># a slave instance may be useful to store some ephemeral data (because data</span><br><span class="line"># written on a slave will be easily deleted after resync with the master) but</span><br><span class="line"># may also cause problems if clients are writing to it because of a</span><br><span class="line"># misconfiguration.</span><br><span class="line">#</span><br><span class="line"># Since Redis 2.6 by default slaves are read-only.</span><br><span class="line">#</span><br><span class="line"># Note: read only slaves are not designed to be exposed to untrusted clients</span><br><span class="line"># on the internet. It&#x27;s just a protection layer against misuse of the instance.</span><br><span class="line"># Still a read only slave exports by default all the administrative commands</span><br><span class="line"># such as CONFIG, DEBUG, and so forth. To a limited extent you can improve</span><br><span class="line"># security of read only slaves using &#x27;rename-command&#x27; to shadow all the</span><br><span class="line"># administrative / dangerous commands.</span><br><span class="line">slave-read-only yes</span><br><span class="line"> </span><br><span class="line"># Replication SYNC strategy: disk or socket.</span><br><span class="line">#</span><br><span class="line"># -------------------------------------------------------</span><br><span class="line"># WARNING: DISKLESS REPLICATION IS EXPERIMENTAL CURRENTLY</span><br><span class="line"># -------------------------------------------------------</span><br><span class="line">#</span><br><span class="line"># New slaves and reconnecting slaves that are not able to continue the replication</span><br><span class="line"># process just receiving differences, need to do what is called a &quot;full</span><br><span class="line"># synchronization&quot;. An RDB file is transmitted from the master to the slaves.</span><br><span class="line"># The transmission can happen in two different ways:</span><br><span class="line">#</span><br><span class="line"># 1) Disk-backed: The Redis master creates a new process that writes the RDB</span><br><span class="line">#                 file on disk. Later the file is transferred by the parent</span><br><span class="line">#                 process to the slaves incrementally.</span><br><span class="line"># 2) Diskless: The Redis master creates a new process that directly writes the</span><br><span class="line">#              RDB file to slave sockets, without touching the disk at all.</span><br><span class="line">#</span><br><span class="line"># With disk-backed replication, while the RDB file is generated, more slaves</span><br><span class="line"># can be queued and served with the RDB file as soon as the current child producing</span><br><span class="line"># the RDB file finishes its work. With diskless replication instead once</span><br><span class="line"># the transfer starts, new slaves arriving will be queued and a new transfer</span><br><span class="line"># will start when the current one terminates.</span><br><span class="line">#</span><br><span class="line"># When diskless replication is used, the master waits a configurable amount of</span><br><span class="line"># time (in seconds) before starting the transfer in the hope that multiple slaves</span><br><span class="line"># will arrive and the transfer can be parallelized.</span><br><span class="line">#</span><br><span class="line"># With slow disks and fast (large bandwidth) networks, diskless replication</span><br><span class="line"># works better.</span><br><span class="line">repl-diskless-sync no</span><br><span class="line"> </span><br><span class="line"># When diskless replication is enabled, it is possible to configure the delay</span><br><span class="line"># the server waits in order to spawn the child that transfers the RDB via socket</span><br><span class="line"># to the slaves.</span><br><span class="line">#</span><br><span class="line"># This is important since once the transfer starts, it is not possible to serve</span><br><span class="line"># new slaves arriving, that will be queued for the next RDB transfer, so the server</span><br><span class="line"># waits a delay in order to let more slaves arrive.</span><br><span class="line">#</span><br><span class="line"># The delay is specified in seconds, and by default is 5 seconds. To disable</span><br><span class="line"># it entirely just set it to 0 seconds and the transfer will start ASAP.</span><br><span class="line">repl-diskless-sync-delay 5</span><br><span class="line"> </span><br><span class="line"># Slaves send PINGs to server in a predefined interval. It&#x27;s possible to change</span><br><span class="line"># this interval with the repl_ping_slave_period option. The default value is 10</span><br><span class="line"># seconds.</span><br><span class="line">#</span><br><span class="line"># repl-ping-slave-period 10</span><br><span class="line"> </span><br><span class="line"># The following option sets the replication timeout for:</span><br><span class="line">#</span><br><span class="line"># 1) Bulk transfer I/O during SYNC, from the point of view of slave.</span><br><span class="line"># 2) Master timeout from the point of view of slaves (data, pings).</span><br><span class="line"># 3) Slave timeout from the point of view of masters (REPLCONF ACK pings).</span><br><span class="line">#</span><br><span class="line"># It is important to make sure that this value is greater than the value</span><br><span class="line"># specified for repl-ping-slave-period otherwise a timeout will be detected</span><br><span class="line"># every time there is low traffic between the master and the slave.</span><br><span class="line">#</span><br><span class="line"># repl-timeout 60</span><br><span class="line"> </span><br><span class="line"># Disable TCP_NODELAY on the slave socket after SYNC?</span><br><span class="line">#</span><br><span class="line"># If you select &quot;yes&quot; Redis will use a smaller number of TCP packets and</span><br><span class="line"># less bandwidth to send data to slaves. But this can add a delay for</span><br><span class="line"># the data to appear on the slave side, up to 40 milliseconds with</span><br><span class="line"># Linux kernels using a default configuration.</span><br><span class="line">#</span><br><span class="line"># If you select &quot;no&quot; the delay for data to appear on the slave side will</span><br><span class="line"># be reduced but more bandwidth will be used for replication.</span><br><span class="line">#</span><br><span class="line"># By default we optimize for low latency, but in very high traffic conditions</span><br><span class="line"># or when the master and slaves are many hops away, turning this to &quot;yes&quot; may</span><br><span class="line"># be a good idea.</span><br><span class="line">repl-disable-tcp-nodelay no</span><br><span class="line"> </span><br><span class="line"># Set the replication backlog size. The backlog is a buffer that accumulates</span><br><span class="line"># slave data when slaves are disconnected for some time, so that when a slave</span><br><span class="line"># wants to reconnect again, often a full resync is not needed, but a partial</span><br><span class="line"># resync is enough, just passing the portion of data the slave missed while</span><br><span class="line"># disconnected.</span><br><span class="line">#</span><br><span class="line"># The bigger the replication backlog, the longer the time the slave can be</span><br><span class="line"># disconnected and later be able to perform a partial resynchronization.</span><br><span class="line">#</span><br><span class="line"># The backlog is only allocated once there is at least a slave connected.</span><br><span class="line">#</span><br><span class="line"># repl-backlog-size 1mb</span><br><span class="line"> </span><br><span class="line"># After a master has no longer connected slaves for some time, the backlog</span><br><span class="line"># will be freed. The following option configures the amount of seconds that</span><br><span class="line"># need to elapse, starting from the time the last slave disconnected, for</span><br><span class="line"># the backlog buffer to be freed.</span><br><span class="line">#</span><br><span class="line"># Note that slaves never free the backlog for timeout, since they may be</span><br><span class="line"># promoted to masters later, and should be able to correctly &quot;partially</span><br><span class="line"># resynchronize&quot; with the slaves: hence they should always accumulate backlog.</span><br><span class="line">#</span><br><span class="line"># A value of 0 means to never release the backlog.</span><br><span class="line">#</span><br><span class="line"># repl-backlog-ttl 3600</span><br><span class="line"> </span><br><span class="line"># The slave priority is an integer number published by Redis in the INFO output.</span><br><span class="line"># It is used by Redis Sentinel in order to select a slave to promote into a</span><br><span class="line"># master if the master is no longer working correctly.</span><br><span class="line">#</span><br><span class="line"># A slave with a low priority number is considered better for promotion, so</span><br><span class="line"># for instance if there are three slaves with priority 10, 100, 25 Sentinel will</span><br><span class="line"># pick the one with priority 10, that is the lowest.</span><br><span class="line">#</span><br><span class="line"># However a special priority of 0 marks the slave as not able to perform the</span><br><span class="line"># role of master, so a slave with priority of 0 will never be selected by</span><br><span class="line"># Redis Sentinel for promotion.</span><br><span class="line">#</span><br><span class="line"># By default the priority is 100.</span><br><span class="line">slave-priority 100</span><br><span class="line"> </span><br><span class="line"># It is possible for a master to stop accepting writes if there are less than</span><br><span class="line"># N slaves connected, having a lag less or equal than M seconds.</span><br><span class="line">#</span><br><span class="line"># The N slaves need to be in &quot;online&quot; state.</span><br><span class="line">#</span><br><span class="line"># The lag in seconds, that must be &lt;= the specified value, is calculated from</span><br><span class="line"># the last ping received from the slave, that is usually sent every second.</span><br><span class="line">#</span><br><span class="line"># This option does not GUARANTEE that N replicas will accept the write, but</span><br><span class="line"># will limit the window of exposure for lost writes in case not enough slaves</span><br><span class="line"># are available, to the specified number of seconds.</span><br><span class="line">#</span><br><span class="line"># For example to require at least 3 slaves with a lag &lt;= 10 seconds use:</span><br><span class="line">#</span><br><span class="line"># min-slaves-to-write 3</span><br><span class="line"># min-slaves-max-lag 10</span><br><span class="line">#</span><br><span class="line"># Setting one or the other to 0 disables the feature.</span><br><span class="line">#</span><br><span class="line"># By default min-slaves-to-write is set to 0 (feature disabled) and</span><br><span class="line"># min-slaves-max-lag is set to 10.</span><br><span class="line"> </span><br><span class="line"># A Redis master is able to list the address and port of the attached</span><br><span class="line"># slaves in different ways. For example the &quot;INFO replication&quot; section</span><br><span class="line"># offers this information, which is used, among other tools, by</span><br><span class="line"># Redis Sentinel in order to discover slave instances.</span><br><span class="line"># Another place where this info is available is in the output of the</span><br><span class="line"># &quot;ROLE&quot; command of a master.</span><br><span class="line">#</span><br><span class="line"># The listed IP and address normally reported by a slave is obtained</span><br><span class="line"># in the following way:</span><br><span class="line">#</span><br><span class="line">#   IP: The address is auto detected by checking the peer address</span><br><span class="line">#   of the socket used by the slave to connect with the master.</span><br><span class="line">#</span><br><span class="line">#   Port: The port is communicated by the slave during the replication</span><br><span class="line">#   handshake, and is normally the port that the slave is using to</span><br><span class="line">#   list for connections.</span><br><span class="line">#</span><br><span class="line"># However when port forwarding or Network Address Translation (NAT) is</span><br><span class="line"># used, the slave may be actually reachable via different IP and port</span><br><span class="line"># pairs. The following two options can be used by a slave in order to</span><br><span class="line"># report to its master a specific set of IP and port, so that both INFO</span><br><span class="line"># and ROLE will report those values.</span><br><span class="line">#</span><br><span class="line"># There is no need to use both the options if you need to override just</span><br><span class="line"># the port or the IP address.</span><br><span class="line">#</span><br><span class="line"># slave-announce-ip 5.5.5.5</span><br><span class="line"># slave-announce-port 1234</span><br><span class="line"> </span><br><span class="line">################################## SECURITY ###################################</span><br><span class="line"> </span><br><span class="line"># Require clients to issue AUTH &lt;PASSWORD&gt; before processing any other</span><br><span class="line"># commands.  This might be useful in environments in which you do not trust</span><br><span class="line"># others with access to the host running redis-server.</span><br><span class="line">#</span><br><span class="line"># This should stay commented out for backward compatibility and because most</span><br><span class="line"># people do not need auth (e.g. they run their own servers).</span><br><span class="line">#</span><br><span class="line"># Warning: since Redis is pretty fast an outside user can try up to</span><br><span class="line"># 150k passwords per second against a good box. This means that you should</span><br><span class="line"># use a very strong password otherwise it will be very easy to break.</span><br><span class="line">#</span><br><span class="line">requirepass 123456</span><br><span class="line"> </span><br><span class="line"># Command renaming.</span><br><span class="line">#</span><br><span class="line"># It is possible to change the name of dangerous commands in a shared</span><br><span class="line"># environment. For instance the CONFIG command may be renamed into something</span><br><span class="line"># hard to guess so that it will still be available for internal-use tools</span><br><span class="line"># but not available for general clients.</span><br><span class="line">#</span><br><span class="line"># Example:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52</span><br><span class="line">#</span><br><span class="line"># It is also possible to completely kill a command by renaming it into</span><br><span class="line"># an empty string:</span><br><span class="line">#</span><br><span class="line"># rename-command CONFIG &quot;&quot;</span><br><span class="line">#</span><br><span class="line"># Please note that changing the name of commands that are logged into the</span><br><span class="line"># AOF file or transmitted to slaves may cause problems.</span><br><span class="line"> </span><br><span class="line">################################### CLIENTS ####################################</span><br><span class="line"> </span><br><span class="line"># Set the max number of connected clients at the same time. By default</span><br><span class="line"># this limit is set to 10000 clients, however if the Redis server is not</span><br><span class="line"># able to configure the process file limit to allow for the specified limit</span><br><span class="line"># the max number of allowed clients is set to the current file limit</span><br><span class="line"># minus 32 (as Redis reserves a few file descriptors for internal uses).</span><br><span class="line">#</span><br><span class="line"># Once the limit is reached Redis will close all the new connections sending</span><br><span class="line"># an error &#x27;max number of clients reached&#x27;.</span><br><span class="line">#</span><br><span class="line"># maxclients 10000</span><br><span class="line"> </span><br><span class="line">############################## MEMORY MANAGEMENT ################################</span><br><span class="line"> </span><br><span class="line"># Set a memory usage limit to the specified amount of bytes.</span><br><span class="line"># When the memory limit is reached Redis will try to remove keys</span><br><span class="line"># according to the eviction policy selected (see maxmemory-policy).</span><br><span class="line">#</span><br><span class="line"># If Redis can&#x27;t remove keys according to the policy, or if the policy is</span><br><span class="line"># set to &#x27;noeviction&#x27;, Redis will start to reply with errors to commands</span><br><span class="line"># that would use more memory, like SET, LPUSH, and so on, and will continue</span><br><span class="line"># to reply to read-only commands like GET.</span><br><span class="line">#</span><br><span class="line"># This option is usually useful when using Redis as an LRU or LFU cache, or to</span><br><span class="line"># set a hard memory limit for an instance (using the &#x27;noeviction&#x27; policy).</span><br><span class="line">#</span><br><span class="line"># WARNING: If you have slaves attached to an instance with maxmemory on,</span><br><span class="line"># the size of the output buffers needed to feed the slaves are subtracted</span><br><span class="line"># from the used memory count, so that network problems / resyncs will</span><br><span class="line"># not trigger a loop where keys are evicted, and in turn the output</span><br><span class="line"># buffer of slaves is full with DELs of keys evicted triggering the deletion</span><br><span class="line"># of more keys, and so forth until the database is completely emptied.</span><br><span class="line">#</span><br><span class="line"># In short... if you have slaves attached it is suggested that you set a lower</span><br><span class="line"># limit for maxmemory so that there is some free RAM on the system for slave</span><br><span class="line"># output buffers (but this is not needed if the policy is &#x27;noeviction&#x27;).</span><br><span class="line">#</span><br><span class="line"># maxmemory &lt;bytes&gt;</span><br><span class="line"> </span><br><span class="line"># MAXMEMORY POLICY: how Redis will select what to remove when maxmemory</span><br><span class="line"># is reached. You can select among five behaviors:</span><br><span class="line">#</span><br><span class="line"># volatile-lru -&gt; Evict using approximated LRU among the keys with an expire set.</span><br><span class="line"># allkeys-lru -&gt; Evict any key using approximated LRU.</span><br><span class="line"># volatile-lfu -&gt; Evict using approximated LFU among the keys with an expire set.</span><br><span class="line"># allkeys-lfu -&gt; Evict any key using approximated LFU.</span><br><span class="line"># volatile-random -&gt; Remove a random key among the ones with an expire set.</span><br><span class="line"># allkeys-random -&gt; Remove a random key, any key.</span><br><span class="line"># volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL)</span><br><span class="line"># noeviction -&gt; Don&#x27;t evict anything, just return an error on write operations.</span><br><span class="line">#</span><br><span class="line"># LRU means Least Recently Used</span><br><span class="line"># LFU means Least Frequently Used</span><br><span class="line">#</span><br><span class="line"># Both LRU, LFU and volatile-ttl are implemented using approximated</span><br><span class="line"># randomized algorithms.</span><br><span class="line">#</span><br><span class="line"># Note: with any of the above policies, Redis will return an error on write</span><br><span class="line">#       operations, when there are no suitable keys for eviction.</span><br><span class="line">#</span><br><span class="line">#       At the date of writing these commands are: set setnx setex append</span><br><span class="line">#       incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd</span><br><span class="line">#       sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby</span><br><span class="line">#       zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby</span><br><span class="line">#       getset mset msetnx exec sort</span><br><span class="line">#</span><br><span class="line"># The default is:</span><br><span class="line">#</span><br><span class="line"># maxmemory-policy noeviction</span><br><span class="line"> </span><br><span class="line"># LRU, LFU and minimal TTL algorithms are not precise algorithms but approximated</span><br><span class="line"># algorithms (in order to save memory), so you can tune it for speed or</span><br><span class="line"># accuracy. For default Redis will check five keys and pick the one that was</span><br><span class="line"># used less recently, you can change the sample size using the following</span><br><span class="line"># configuration directive.</span><br><span class="line">#</span><br><span class="line"># The default of 5 produces good enough results. 10 Approximates very closely</span><br><span class="line"># true LRU but costs more CPU. 3 is faster but not very accurate.</span><br><span class="line">#</span><br><span class="line"># maxmemory-samples 5</span><br><span class="line"> </span><br><span class="line">############################# LAZY FREEING ####################################</span><br><span class="line"> </span><br><span class="line"># Redis has two primitives to delete keys. One is called DEL and is a blocking</span><br><span class="line"># deletion of the object. It means that the server stops processing new commands</span><br><span class="line"># in order to reclaim all the memory associated with an object in a synchronous</span><br><span class="line"># way. If the key deleted is associated with a small object, the time needed</span><br><span class="line"># in order to execute the DEL command is very small and comparable to most other</span><br><span class="line"># O(1) or O(log_N) commands in Redis. However if the key is associated with an</span><br><span class="line"># aggregated value containing millions of elements, the server can block for</span><br><span class="line"># a long time (even seconds) in order to complete the operation.</span><br><span class="line">#</span><br><span class="line"># For the above reasons Redis also offers non blocking deletion primitives</span><br><span class="line"># such as UNLINK (non blocking DEL) and the ASYNC option of FLUSHALL and</span><br><span class="line"># FLUSHDB commands, in order to reclaim memory in background. Those commands</span><br><span class="line"># are executed in constant time. Another thread will incrementally free the</span><br><span class="line"># object in the background as fast as possible.</span><br><span class="line">#</span><br><span class="line"># DEL, UNLINK and ASYNC option of FLUSHALL and FLUSHDB are user-controlled.</span><br><span class="line"># It&#x27;s up to the design of the application to understand when it is a good</span><br><span class="line"># idea to use one or the other. However the Redis server sometimes has to</span><br><span class="line"># delete keys or flush the whole database as a side effect of other operations.</span><br><span class="line"># Specifically Redis deletes objects independently of a user call in the</span><br><span class="line"># following scenarios:</span><br><span class="line">#</span><br><span class="line"># 1) On eviction, because of the maxmemory and maxmemory policy configurations,</span><br><span class="line">#    in order to make room for new data, without going over the specified</span><br><span class="line">#    memory limit.</span><br><span class="line"># 2) Because of expire: when a key with an associated time to live (see the</span><br><span class="line">#    EXPIRE command) must be deleted from memory.</span><br><span class="line"># 3) Because of a side effect of a command that stores data on a key that may</span><br><span class="line">#    already exist. For example the RENAME command may delete the old key</span><br><span class="line">#    content when it is replaced with another one. Similarly SUNIONSTORE</span><br><span class="line">#    or SORT with STORE option may delete existing keys. The SET command</span><br><span class="line">#    itself removes any old content of the specified key in order to replace</span><br><span class="line">#    it with the specified string.</span><br><span class="line"># 4) During replication, when a slave performs a full resynchronization with</span><br><span class="line">#    its master, the content of the whole database is removed in order to</span><br><span class="line">#    load the RDB file just transfered.</span><br><span class="line">#</span><br><span class="line"># In all the above cases the default is to delete objects in a blocking way,</span><br><span class="line"># like if DEL was called. However you can configure each case specifically</span><br><span class="line"># in order to instead release memory in a non-blocking way like if UNLINK</span><br><span class="line"># was called, using the following configuration directives:</span><br><span class="line"> </span><br><span class="line">lazyfree-lazy-eviction no</span><br><span class="line">lazyfree-lazy-expire no</span><br><span class="line">lazyfree-lazy-server-del no</span><br><span class="line">slave-lazy-flush no</span><br><span class="line"> </span><br><span class="line">############################## APPEND ONLY MODE ###############################</span><br><span class="line"> </span><br><span class="line"># By default Redis asynchronously dumps the dataset on disk. This mode is</span><br><span class="line"># good enough in many applications, but an issue with the Redis process or</span><br><span class="line"># a power outage may result into a few minutes of writes lost (depending on</span><br><span class="line"># the configured save points).</span><br><span class="line">#</span><br><span class="line"># The Append Only File is an alternative persistence mode that provides</span><br><span class="line"># much better durability. For instance using the default data fsync policy</span><br><span class="line"># (see later in the config file) Redis can lose just one second of writes in a</span><br><span class="line"># dramatic event like a server power outage, or a single write if something</span><br><span class="line"># wrong with the Redis process itself happens, but the operating system is</span><br><span class="line"># still running correctly.</span><br><span class="line">#</span><br><span class="line"># AOF and RDB persistence can be enabled at the same time without problems.</span><br><span class="line"># If the AOF is enabled on startup Redis will load the AOF, that is the file</span><br><span class="line"># with the better durability guarantees.</span><br><span class="line">#</span><br><span class="line"># Please check http://redis.io/topics/persistence for more information.</span><br><span class="line"> </span><br><span class="line">appendonly no</span><br><span class="line"> </span><br><span class="line"># The name of the append only file (default: &quot;appendonly.aof&quot;)</span><br><span class="line"> </span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"> </span><br><span class="line"># The fsync() call tells the Operating System to actually write data on disk</span><br><span class="line"># instead of waiting for more data in the output buffer. Some OS will really flush</span><br><span class="line"># data on disk, some other OS will just try to do it ASAP.</span><br><span class="line">#</span><br><span class="line"># Redis supports three different modes:</span><br><span class="line">#</span><br><span class="line"># no: don&#x27;t fsync, just let the OS flush the data when it wants. Faster.</span><br><span class="line"># always: fsync after every write to the append only log. Slow, Safest.</span><br><span class="line"># everysec: fsync only one time every second. Compromise.</span><br><span class="line">#</span><br><span class="line"># The default is &quot;everysec&quot;, as that&#x27;s usually the right compromise between</span><br><span class="line"># speed and data safety. It&#x27;s up to you to understand if you can relax this to</span><br><span class="line"># &quot;no&quot; that will let the operating system flush the output buffer when</span><br><span class="line"># it wants, for better performances (but if you can live with the idea of</span><br><span class="line"># some data loss consider the default persistence mode that&#x27;s snapshotting),</span><br><span class="line"># or on the contrary, use &quot;always&quot; that&#x27;s very slow but a bit safer than</span><br><span class="line"># everysec.</span><br><span class="line">#</span><br><span class="line"># More details please check the following article:</span><br><span class="line"># http://antirez.com/post/redis-persistence-demystified.html</span><br><span class="line">#</span><br><span class="line"># If unsure, use &quot;everysec&quot;.</span><br><span class="line"> </span><br><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"> </span><br><span class="line"># When the AOF fsync policy is set to always or everysec, and a background</span><br><span class="line"># saving process (a background save or AOF log background rewriting) is</span><br><span class="line"># performing a lot of I/O against the disk, in some Linux configurations</span><br><span class="line"># Redis may block too long on the fsync() call. Note that there is no fix for</span><br><span class="line"># this currently, as even performing fsync in a different thread will block</span><br><span class="line"># our synchronous write(2) call.</span><br><span class="line">#</span><br><span class="line"># In order to mitigate this problem it&#x27;s possible to use the following option</span><br><span class="line"># that will prevent fsync() from being called in the main process while a</span><br><span class="line"># BGSAVE or BGREWRITEAOF is in progress.</span><br><span class="line">#</span><br><span class="line"># This means that while another child is saving, the durability of Redis is</span><br><span class="line"># the same as &quot;appendfsync none&quot;. In practical terms, this means that it is</span><br><span class="line"># possible to lose up to 30 seconds of log in the worst scenario (with the</span><br><span class="line"># default Linux settings).</span><br><span class="line">#</span><br><span class="line"># If you have latency problems turn this to &quot;yes&quot;. Otherwise leave it as</span><br><span class="line"># &quot;no&quot; that is the safest pick from the point of view of durability.</span><br><span class="line"> </span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"> </span><br><span class="line"># Automatic rewrite of the append only file.</span><br><span class="line"># Redis is able to automatically rewrite the log file implicitly calling</span><br><span class="line"># BGREWRITEAOF when the AOF log size grows by the specified percentage.</span><br><span class="line">#</span><br><span class="line"># This is how it works: Redis remembers the size of the AOF file after the</span><br><span class="line"># latest rewrite (if no rewrite has happened since the restart, the size of</span><br><span class="line"># the AOF at startup is used).</span><br><span class="line">#</span><br><span class="line"># This base size is compared to the current size. If the current size is</span><br><span class="line"># bigger than the specified percentage, the rewrite is triggered. Also</span><br><span class="line"># you need to specify a minimal size for the AOF file to be rewritten, this</span><br><span class="line"># is useful to avoid rewriting the AOF file even if the percentage increase</span><br><span class="line"># is reached but it is still pretty small.</span><br><span class="line">#</span><br><span class="line"># Specify a percentage of zero in order to disable the automatic AOF</span><br><span class="line"># rewrite feature.</span><br><span class="line"> </span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"> </span><br><span class="line"># An AOF file may be found to be truncated at the end during the Redis</span><br><span class="line"># startup process, when the AOF data gets loaded back into memory.</span><br><span class="line"># This may happen when the system where Redis is running</span><br><span class="line"># crashes, especially when an ext4 filesystem is mounted without the</span><br><span class="line"># data=ordered option (however this can&#x27;t happen when Redis itself</span><br><span class="line"># crashes or aborts but the operating system still works correctly).</span><br><span class="line">#</span><br><span class="line"># Redis can either exit with an error when this happens, or load as much</span><br><span class="line"># data as possible (the default now) and start if the AOF file is found</span><br><span class="line"># to be truncated at the end. The following option controls this behavior.</span><br><span class="line">#</span><br><span class="line"># If aof-load-truncated is set to yes, a truncated AOF file is loaded and</span><br><span class="line"># the Redis server starts emitting a log to inform the user of the event.</span><br><span class="line"># Otherwise if the option is set to no, the server aborts with an error</span><br><span class="line"># and refuses to start. When the option is set to no, the user requires</span><br><span class="line"># to fix the AOF file using the &quot;redis-check-aof&quot; utility before to restart</span><br><span class="line"># the server.</span><br><span class="line">#</span><br><span class="line"># Note that if the AOF file will be found to be corrupted in the middle</span><br><span class="line"># the server will still exit with an error. This option only applies when</span><br><span class="line"># Redis will try to read more data from the AOF file but not enough bytes</span><br><span class="line"># will be found.</span><br><span class="line">aof-load-truncated yes</span><br><span class="line"> </span><br><span class="line"># When rewriting the AOF file, Redis is able to use an RDB preamble in the</span><br><span class="line"># AOF file for faster rewrites and recoveries. When this option is turned</span><br><span class="line"># on the rewritten AOF file is composed of two different stanzas:</span><br><span class="line">#</span><br><span class="line">#   [RDB file][AOF tail]</span><br><span class="line">#</span><br><span class="line"># When loading Redis recognizes that the AOF file starts with the &quot;REDIS&quot;</span><br><span class="line"># string and loads the prefixed RDB file, and continues loading the AOF</span><br><span class="line"># tail.</span><br><span class="line">#</span><br><span class="line"># This is currently turned off by default in order to avoid the surprise</span><br><span class="line"># of a format change, but will at some point be used as the default.</span><br><span class="line">aof-use-rdb-preamble no</span><br><span class="line"> </span><br><span class="line">################################ LUA SCRIPTING  ###############################</span><br><span class="line"> </span><br><span class="line"># Max execution time of a Lua script in milliseconds.</span><br><span class="line">#</span><br><span class="line"># If the maximum execution time is reached Redis will log that a script is</span><br><span class="line"># still in execution after the maximum allowed time and will start to</span><br><span class="line"># reply to queries with an error.</span><br><span class="line">#</span><br><span class="line"># When a long running script exceeds the maximum execution time only the</span><br><span class="line"># SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be</span><br><span class="line"># used to stop a script that did not yet called write commands. The second</span><br><span class="line"># is the only way to shut down the server in the case a write command was</span><br><span class="line"># already issued by the script but the user doesn&#x27;t want to wait for the natural</span><br><span class="line"># termination of the script.</span><br><span class="line">#</span><br><span class="line"># Set it to 0 or a negative value for unlimited execution without warnings.</span><br><span class="line">lua-time-limit 5000</span><br><span class="line"> </span><br><span class="line">################################ REDIS CLUSTER  ###############################</span><br><span class="line">#</span><br><span class="line"># ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line"># WARNING EXPERIMENTAL: Redis Cluster is considered to be stable code, however</span><br><span class="line"># in order to mark it as &quot;mature&quot; we need to wait for a non trivial percentage</span><br><span class="line"># of users to deploy it in production.</span><br><span class="line"># ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</span><br><span class="line">#</span><br><span class="line"># Normal Redis instances can&#x27;t be part of a Redis Cluster; only nodes that are</span><br><span class="line"># started as cluster nodes can. In order to start a Redis instance as a</span><br><span class="line"># cluster node enable the cluster support uncommenting the following:</span><br><span class="line">#</span><br><span class="line"># cluster-enabled yes</span><br><span class="line"> </span><br><span class="line"># Every cluster node has a cluster configuration file. This file is not</span><br><span class="line"># intended to be edited by hand. It is created and updated by Redis nodes.</span><br><span class="line"># Every Redis Cluster node requires a different cluster configuration file.</span><br><span class="line"># Make sure that instances running in the same system do not have</span><br><span class="line"># overlapping cluster configuration file names.</span><br><span class="line">#</span><br><span class="line"># cluster-config-file nodes-6379.conf</span><br><span class="line"> </span><br><span class="line"># Cluster node timeout is the amount of milliseconds a node must be unreachable</span><br><span class="line"># for it to be considered in failure state.</span><br><span class="line"># Most other internal time limits are multiple of the node timeout.</span><br><span class="line">#</span><br><span class="line"># cluster-node-timeout 15000</span><br><span class="line"> </span><br><span class="line"># A slave of a failing master will avoid to start a failover if its data</span><br><span class="line"># looks too old.</span><br><span class="line">#</span><br><span class="line"># There is no simple way for a slave to actually have an exact measure of</span><br><span class="line"># its &quot;data age&quot;, so the following two checks are performed:</span><br><span class="line">#</span><br><span class="line"># 1) If there are multiple slaves able to failover, they exchange messages</span><br><span class="line">#    in order to try to give an advantage to the slave with the best</span><br><span class="line">#    replication offset (more data from the master processed).</span><br><span class="line">#    Slaves will try to get their rank by offset, and apply to the start</span><br><span class="line">#    of the failover a delay proportional to their rank.</span><br><span class="line">#</span><br><span class="line"># 2) Every single slave computes the time of the last interaction with</span><br><span class="line">#    its master. This can be the last ping or command received (if the master</span><br><span class="line">#    is still in the &quot;connected&quot; state), or the time that elapsed since the</span><br><span class="line">#    disconnection with the master (if the replication link is currently down).</span><br><span class="line">#    If the last interaction is too old, the slave will not try to failover</span><br><span class="line">#    at all.</span><br><span class="line">#</span><br><span class="line"># The point &quot;2&quot; can be tuned by user. Specifically a slave will not perform</span><br><span class="line"># the failover if, since the last interaction with the master, the time</span><br><span class="line"># elapsed is greater than:</span><br><span class="line">#</span><br><span class="line">#   (node-timeout * slave-validity-factor) + repl-ping-slave-period</span><br><span class="line">#</span><br><span class="line"># So for example if node-timeout is 30 seconds, and the slave-validity-factor</span><br><span class="line"># is 10, and assuming a default repl-ping-slave-period of 10 seconds, the</span><br><span class="line"># slave will not try to failover if it was not able to talk with the master</span><br><span class="line"># for longer than 310 seconds.</span><br><span class="line">#</span><br><span class="line"># A large slave-validity-factor may allow slaves with too old data to failover</span><br><span class="line"># a master, while a too small value may prevent the cluster from being able to</span><br><span class="line"># elect a slave at all.</span><br><span class="line">#</span><br><span class="line"># For maximum availability, it is possible to set the slave-validity-factor</span><br><span class="line"># to a value of 0, which means, that slaves will always try to failover the</span><br><span class="line"># master regardless of the last time they interacted with the master.</span><br><span class="line"># (However they&#x27;ll always try to apply a delay proportional to their</span><br><span class="line"># offset rank).</span><br><span class="line">#</span><br><span class="line"># Zero is the only value able to guarantee that when all the partitions heal</span><br><span class="line"># the cluster will always be able to continue.</span><br><span class="line">#</span><br><span class="line"># cluster-slave-validity-factor 10</span><br><span class="line"> </span><br><span class="line"># Cluster slaves are able to migrate to orphaned masters, that are masters</span><br><span class="line"># that are left without working slaves. This improves the cluster ability</span><br><span class="line"># to resist to failures as otherwise an orphaned master can&#x27;t be failed over</span><br><span class="line"># in case of failure if it has no working slaves.</span><br><span class="line">#</span><br><span class="line"># Slaves migrate to orphaned masters only if there are still at least a</span><br><span class="line"># given number of other working slaves for their old master. This number</span><br><span class="line"># is the &quot;migration barrier&quot;. A migration barrier of 1 means that a slave</span><br><span class="line"># will migrate only if there is at least 1 other working slave for its master</span><br><span class="line"># and so forth. It usually reflects the number of slaves you want for every</span><br><span class="line"># master in your cluster.</span><br><span class="line">#</span><br><span class="line"># Default is 1 (slaves migrate only if their masters remain with at least</span><br><span class="line"># one slave). To disable migration just set it to a very large value.</span><br><span class="line"># A value of 0 can be set but is useful only for debugging and dangerous</span><br><span class="line"># in production.</span><br><span class="line">#</span><br><span class="line"># cluster-migration-barrier 1</span><br><span class="line"> </span><br><span class="line"># By default Redis Cluster nodes stop accepting queries if they detect there</span><br><span class="line"># is at least an hash slot uncovered (no available node is serving it).</span><br><span class="line"># This way if the cluster is partially down (for example a range of hash slots</span><br><span class="line"># are no longer covered) all the cluster becomes, eventually, unavailable.</span><br><span class="line"># It automatically returns available as soon as all the slots are covered again.</span><br><span class="line">#</span><br><span class="line"># However sometimes you want the subset of the cluster which is working,</span><br><span class="line"># to continue to accept queries for the part of the key space that is still</span><br><span class="line"># covered. In order to do so, just set the cluster-require-full-coverage</span><br><span class="line"># option to no.</span><br><span class="line">#</span><br><span class="line"># cluster-require-full-coverage yes</span><br><span class="line"> </span><br><span class="line"># In order to setup your cluster make sure to read the documentation</span><br><span class="line"># available at http://redis.io web site.</span><br><span class="line"> </span><br><span class="line">########################## CLUSTER DOCKER/NAT support  ########################</span><br><span class="line"> </span><br><span class="line"># In certain deployments, Redis Cluster nodes address discovery fails, because</span><br><span class="line"># addresses are NAT-ted or because ports are forwarded (the typical case is</span><br><span class="line"># Docker and other containers).</span><br><span class="line">#</span><br><span class="line"># In order to make Redis Cluster working in such environments, a static</span><br><span class="line"># configuration where each node knows its public address is needed. The</span><br><span class="line"># following two options are used for this scope, and are:</span><br><span class="line">#</span><br><span class="line"># * cluster-announce-ip</span><br><span class="line"># * cluster-announce-port</span><br><span class="line"># * cluster-announce-bus-port</span><br><span class="line">#</span><br><span class="line"># Each instruct the node about its address, client port, and cluster message</span><br><span class="line"># bus port. The information is then published in the header of the bus packets</span><br><span class="line"># so that other nodes will be able to correctly map the address of the node</span><br><span class="line"># publishing the information.</span><br><span class="line">#</span><br><span class="line"># If the above options are not used, the normal Redis Cluster auto-detection</span><br><span class="line"># will be used instead.</span><br><span class="line">#</span><br><span class="line"># Note that when remapped, the bus port may not be at the fixed offset of</span><br><span class="line"># clients port + 10000, so you can specify any port and bus-port depending</span><br><span class="line"># on how they get remapped. If the bus-port is not set, a fixed offset of</span><br><span class="line"># 10000 will be used as usually.</span><br><span class="line">#</span><br><span class="line"># Example:</span><br><span class="line">#</span><br><span class="line"># cluster-announce-ip 10.1.1.5</span><br><span class="line"># cluster-announce-port 6379</span><br><span class="line"># cluster-announce-bus-port 6380</span><br><span class="line"> </span><br><span class="line">################################## SLOW LOG ###################################</span><br><span class="line"> </span><br><span class="line"># The Redis Slow Log is a system to log queries that exceeded a specified</span><br><span class="line"># execution time. The execution time does not include the I/O operations</span><br><span class="line"># like talking with the client, sending the reply and so forth,</span><br><span class="line"># but just the time needed to actually execute the command (this is the only</span><br><span class="line"># stage of command execution where the thread is blocked and can not serve</span><br><span class="line"># other requests in the meantime).</span><br><span class="line">#</span><br><span class="line"># You can configure the slow log with two parameters: one tells Redis</span><br><span class="line"># what is the execution time, in microseconds, to exceed in order for the</span><br><span class="line"># command to get logged, and the other parameter is the length of the</span><br><span class="line"># slow log. When a new command is logged the oldest one is removed from the</span><br><span class="line"># queue of logged commands.</span><br><span class="line"> </span><br><span class="line"># The following time is expressed in microseconds, so 1000000 is equivalent</span><br><span class="line"># to one second. Note that a negative number disables the slow log, while</span><br><span class="line"># a value of zero forces the logging of every command.</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"> </span><br><span class="line"># There is no limit to this length. Just be aware that it will consume memory.</span><br><span class="line"># You can reclaim memory used by the slow log with SLOWLOG RESET.</span><br><span class="line">slowlog-max-len 128</span><br><span class="line"> </span><br><span class="line">################################ LATENCY MONITOR ##############################</span><br><span class="line"> </span><br><span class="line"># The Redis latency monitoring subsystem samples different operations</span><br><span class="line"># at runtime in order to collect data related to possible sources of</span><br><span class="line"># latency of a Redis instance.</span><br><span class="line">#</span><br><span class="line"># Via the LATENCY command this information is available to the user that can</span><br><span class="line"># print graphs and obtain reports.</span><br><span class="line">#</span><br><span class="line"># The system only logs operations that were performed in a time equal or</span><br><span class="line"># greater than the amount of milliseconds specified via the</span><br><span class="line"># latency-monitor-threshold configuration directive. When its value is set</span><br><span class="line"># to zero, the latency monitor is turned off.</span><br><span class="line">#</span><br><span class="line"># By default latency monitoring is disabled since it is mostly not needed</span><br><span class="line"># if you don&#x27;t have latency issues, and collecting data has a performance</span><br><span class="line"># impact, that while very small, can be measured under big load. Latency</span><br><span class="line"># monitoring can easily be enabled at runtime using the command</span><br><span class="line"># &quot;CONFIG SET latency-monitor-threshold &lt;milliseconds&gt;&quot; if needed.</span><br><span class="line">latency-monitor-threshold 0</span><br><span class="line"> </span><br><span class="line">############################# EVENT NOTIFICATION ##############################</span><br><span class="line"> </span><br><span class="line"># Redis can notify Pub/Sub clients about events happening in the key space.</span><br><span class="line"># This feature is documented at http://redis.io/topics/notifications</span><br><span class="line">#</span><br><span class="line"># For instance if keyspace events notification is enabled, and a client</span><br><span class="line"># performs a DEL operation on key &quot;foo&quot; stored in the Database 0, two</span><br><span class="line"># messages will be published via Pub/Sub:</span><br><span class="line">#</span><br><span class="line"># PUBLISH __keyspace@0__:foo del</span><br><span class="line"># PUBLISH __keyevent@0__:del foo</span><br><span class="line">#</span><br><span class="line"># It is possible to select the events that Redis will notify among a set</span><br><span class="line"># of classes. Every class is identified by a single character:</span><br><span class="line">#</span><br><span class="line">#  K     Keyspace events, published with __keyspace@&lt;db&gt;__ prefix.</span><br><span class="line">#  E     Keyevent events, published with __keyevent@&lt;db&gt;__ prefix.</span><br><span class="line">#  g     Generic commands (non-type specific) like DEL, EXPIRE, RENAME, ...</span><br><span class="line">#  $     String commands</span><br><span class="line">#  l     List commands</span><br><span class="line">#  s     Set commands</span><br><span class="line">#  h     Hash commands</span><br><span class="line">#  z     Sorted set commands</span><br><span class="line">#  x     Expired events (events generated every time a key expires)</span><br><span class="line">#  e     Evicted events (events generated when a key is evicted for maxmemory)</span><br><span class="line">#  A     Alias for g$lshzxe, so that the &quot;AKE&quot; string means all the events.</span><br><span class="line">#</span><br><span class="line">#  The &quot;notify-keyspace-events&quot; takes as argument a string that is composed</span><br><span class="line">#  of zero or multiple characters. The empty string means that notifications</span><br><span class="line">#  are disabled.</span><br><span class="line">#</span><br><span class="line">#  Example: to enable list and generic events, from the point of view of the</span><br><span class="line">#           event name, use:</span><br><span class="line">#</span><br><span class="line">#  notify-keyspace-events Elg</span><br><span class="line">#</span><br><span class="line">#  Example 2: to get the stream of the expired keys subscribing to channel</span><br><span class="line">#             name __keyevent@0__:expired use:</span><br><span class="line">#</span><br><span class="line">#  notify-keyspace-events Ex</span><br><span class="line">#</span><br><span class="line">#  By default all notifications are disabled because most users don&#x27;t need</span><br><span class="line">#  this feature and the feature has some overhead. Note that if you don&#x27;t</span><br><span class="line">#  specify at least one of K or E, no events will be delivered.</span><br><span class="line">notify-keyspace-events &quot;&quot;</span><br><span class="line"> </span><br><span class="line">############################### ADVANCED CONFIG ###############################</span><br><span class="line"> </span><br><span class="line"># Hashes are encoded using a memory efficient data structure when they have a</span><br><span class="line"># small number of entries, and the biggest entry does not exceed a given</span><br><span class="line"># threshold. These thresholds can be configured using the following directives.</span><br><span class="line">hash-max-ziplist-entries 512</span><br><span class="line">hash-max-ziplist-value 64</span><br><span class="line"> </span><br><span class="line"># Lists are also encoded in a special way to save a lot of space.</span><br><span class="line"># The number of entries allowed per internal list node can be specified</span><br><span class="line"># as a fixed maximum size or a maximum number of elements.</span><br><span class="line"># For a fixed maximum size, use -5 through -1, meaning:</span><br><span class="line"># -5: max size: 64 Kb  &lt;-- not recommended for normal workloads</span><br><span class="line"># -4: max size: 32 Kb  &lt;-- not recommended</span><br><span class="line"># -3: max size: 16 Kb  &lt;-- probably not recommended</span><br><span class="line"># -2: max size: 8 Kb   &lt;-- good</span><br><span class="line"># -1: max size: 4 Kb   &lt;-- good</span><br><span class="line"># Positive numbers mean store up to _exactly_ that number of elements</span><br><span class="line"># per list node.</span><br><span class="line"># The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),</span><br><span class="line"># but if your use case is unique, adjust the settings as necessary.</span><br><span class="line">list-max-ziplist-size -2</span><br><span class="line"> </span><br><span class="line"># Lists may also be compressed.</span><br><span class="line"># Compress depth is the number of quicklist ziplist nodes from *each* side of</span><br><span class="line"># the list to *exclude* from compression.  The head and tail of the list</span><br><span class="line"># are always uncompressed for fast push/pop operations.  Settings are:</span><br><span class="line"># 0: disable all list compression</span><br><span class="line"># 1: depth 1 means &quot;don&#x27;t start compressing until after 1 node into the list,</span><br><span class="line">#    going from either the head or tail&quot;</span><br><span class="line">#    So: [head]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[tail]</span><br><span class="line">#    [head], [tail] will always be uncompressed; inner nodes will compress.</span><br><span class="line"># 2: [head]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[tail]</span><br><span class="line">#    2 here means: don&#x27;t compress head or head-&gt;next or tail-&gt;prev or tail,</span><br><span class="line">#    but compress all nodes between them.</span><br><span class="line"># 3: [head]-&gt;[next]-&gt;[next]-&gt;node-&gt;node-&gt;...-&gt;node-&gt;[prev]-&gt;[prev]-&gt;[tail]</span><br><span class="line"># etc.</span><br><span class="line">list-compress-depth 0</span><br><span class="line"> </span><br><span class="line"># Sets have a special encoding in just one case: when a set is composed</span><br><span class="line"># of just strings that happen to be integers in radix 10 in the range</span><br><span class="line"># of 64 bit signed integers.</span><br><span class="line"># The following configuration setting sets the limit in the size of the</span><br><span class="line"># set in order to use this special memory saving encoding.</span><br><span class="line">set-max-intset-entries 512</span><br><span class="line"> </span><br><span class="line"># Similarly to hashes and lists, sorted sets are also specially encoded in</span><br><span class="line"># order to save a lot of space. This encoding is only used when the length and</span><br><span class="line"># elements of a sorted set are below the following limits:</span><br><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br><span class="line"> </span><br><span class="line"># HyperLogLog sparse representation bytes limit. The limit includes the</span><br><span class="line"># 16 bytes header. When an HyperLogLog using the sparse representation crosses</span><br><span class="line"># this limit, it is converted into the dense representation.</span><br><span class="line">#</span><br><span class="line"># A value greater than 16000 is totally useless, since at that point the</span><br><span class="line"># dense representation is more memory efficient.</span><br><span class="line">#</span><br><span class="line"># The suggested value is ~ 3000 in order to have the benefits of</span><br><span class="line"># the space efficient encoding without slowing down too much PFADD,</span><br><span class="line"># which is O(N) with the sparse encoding. The value can be raised to</span><br><span class="line"># ~ 10000 when CPU is not a concern, but space is, and the data set is</span><br><span class="line"># composed of many HyperLogLogs with cardinality in the 0 - 15000 range.</span><br><span class="line">hll-sparse-max-bytes 3000</span><br><span class="line"> </span><br><span class="line"># Active rehashing uses 1 millisecond every 100 milliseconds of CPU time in</span><br><span class="line"># order to help rehashing the main Redis hash table (the one mapping top-level</span><br><span class="line"># keys to values). The hash table implementation Redis uses (see dict.c)</span><br><span class="line"># performs a lazy rehashing: the more operation you run into a hash table</span><br><span class="line"># that is rehashing, the more rehashing &quot;steps&quot; are performed, so if the</span><br><span class="line"># server is idle the rehashing is never complete and some more memory is used</span><br><span class="line"># by the hash table.</span><br><span class="line">#</span><br><span class="line"># The default is to use this millisecond 10 times every second in order to</span><br><span class="line"># actively rehash the main dictionaries, freeing memory when possible.</span><br><span class="line">#</span><br><span class="line"># If unsure:</span><br><span class="line"># use &quot;activerehashing no&quot; if you have hard latency requirements and it is</span><br><span class="line"># not a good thing in your environment that Redis can reply from time to time</span><br><span class="line"># to queries with 2 milliseconds delay.</span><br><span class="line">#</span><br><span class="line"># use &quot;activerehashing yes&quot; if you don&#x27;t have such hard requirements but</span><br><span class="line"># want to free memory asap when possible.</span><br><span class="line">activerehashing yes</span><br><span class="line"> </span><br><span class="line"># The client output buffer limits can be used to force disconnection of clients</span><br><span class="line"># that are not reading data from the server fast enough for some reason (a</span><br><span class="line"># common reason is that a Pub/Sub client can&#x27;t consume messages as fast as the</span><br><span class="line"># publisher can produce them).</span><br><span class="line">#</span><br><span class="line"># The limit can be set differently for the three different classes of clients:</span><br><span class="line">#</span><br><span class="line"># normal -&gt; normal clients including MONITOR clients</span><br><span class="line"># slave  -&gt; slave clients</span><br><span class="line"># pubsub -&gt; clients subscribed to at least one pubsub channel or pattern</span><br><span class="line">#</span><br><span class="line"># The syntax of every client-output-buffer-limit directive is the following:</span><br><span class="line">#</span><br><span class="line"># client-output-buffer-limit &lt;class&gt; &lt;hard limit&gt; &lt;soft limit&gt; &lt;soft seconds&gt;</span><br><span class="line">#</span><br><span class="line"># A client is immediately disconnected once the hard limit is reached, or if</span><br><span class="line"># the soft limit is reached and remains reached for the specified number of</span><br><span class="line"># seconds (continuously).</span><br><span class="line"># So for instance if the hard limit is 32 megabytes and the soft limit is</span><br><span class="line"># 16 megabytes / 10 seconds, the client will get disconnected immediately</span><br><span class="line"># if the size of the output buffers reach 32 megabytes, but will also get</span><br><span class="line"># disconnected if the client reaches 16 megabytes and continuously overcomes</span><br><span class="line"># the limit for 10 seconds.</span><br><span class="line">#</span><br><span class="line"># By default normal clients are not limited because they don&#x27;t receive data</span><br><span class="line"># without asking (in a push way), but just after a request, so only</span><br><span class="line"># asynchronous clients may create a scenario where data is requested faster</span><br><span class="line"># than it can read.</span><br><span class="line">#</span><br><span class="line"># Instead there is a default limit for pubsub and slave clients, since</span><br><span class="line"># subscribers and slaves receive data in a push fashion.</span><br><span class="line">#</span><br><span class="line"># Both the hard or the soft limit can be disabled by setting them to zero.</span><br><span class="line">client-output-buffer-limit normal 0 0 0</span><br><span class="line">client-output-buffer-limit slave 256mb 64mb 60</span><br><span class="line">client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line"> </span><br><span class="line"># Client query buffers accumulate new commands. They are limited to a fixed</span><br><span class="line"># amount by default in order to avoid that a protocol desynchronization (for</span><br><span class="line"># instance due to a bug in the client) will lead to unbound memory usage in</span><br><span class="line"># the query buffer. However you can configure it here if you have very special</span><br><span class="line"># needs, such us huge multi/exec requests or alike.</span><br><span class="line">#</span><br><span class="line"># client-query-buffer-limit 1gb</span><br><span class="line"> </span><br><span class="line"># In the Redis protocol, bulk requests, that are, elements representing single</span><br><span class="line"># strings, are normally limited ot 512 mb. However you can change this limit</span><br><span class="line"># here.</span><br><span class="line">#</span><br><span class="line"># proto-max-bulk-len 512mb</span><br><span class="line"> </span><br><span class="line"># Redis calls an internal function to perform many background tasks, like</span><br><span class="line"># closing connections of clients in timeout, purging expired keys that are</span><br><span class="line"># never requested, and so forth.</span><br><span class="line">#</span><br><span class="line"># Not all tasks are performed with the same frequency, but Redis checks for</span><br><span class="line"># tasks to perform according to the specified &quot;hz&quot; value.</span><br><span class="line">#</span><br><span class="line"># By default &quot;hz&quot; is set to 10. Raising the value will use more CPU when</span><br><span class="line"># Redis is idle, but at the same time will make Redis more responsive when</span><br><span class="line"># there are many keys expiring at the same time, and timeouts may be</span><br><span class="line"># handled with more precision.</span><br><span class="line">#</span><br><span class="line"># The range is between 1 and 500, however a value over 100 is usually not</span><br><span class="line"># a good idea. Most users should use the default of 10 and raise this up to</span><br><span class="line"># 100 only in environments where very low latency is required.</span><br><span class="line">hz 10</span><br><span class="line"> </span><br><span class="line"># When a child rewrites the AOF file, if the following option is enabled</span><br><span class="line"># the file will be fsync-ed every 32 MB of data generated. This is useful</span><br><span class="line"># in order to commit the file to the disk more incrementally and avoid</span><br><span class="line"># big latency spikes.</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br><span class="line"> </span><br><span class="line"># Redis LFU eviction (see maxmemory setting) can be tuned. However it is a good</span><br><span class="line"># idea to start with the default settings and only change them after investigating</span><br><span class="line"># how to improve the performances and how the keys LFU change over time, which</span><br><span class="line"># is possible to inspect via the OBJECT FREQ command.</span><br><span class="line">#</span><br><span class="line"># There are two tunable parameters in the Redis LFU implementation: the</span><br><span class="line"># counter logarithm factor and the counter decay time. It is important to</span><br><span class="line"># understand what the two parameters mean before changing them.</span><br><span class="line">#</span><br><span class="line"># The LFU counter is just 8 bits per key, it&#x27;s maximum value is 255, so Redis</span><br><span class="line"># uses a probabilistic increment with logarithmic behavior. Given the value</span><br><span class="line"># of the old counter, when a key is accessed, the counter is incremented in</span><br><span class="line"># this way:</span><br><span class="line">#</span><br><span class="line"># 1. A random number R between 0 and 1 is extracted.</span><br><span class="line"># 2. A probability P is calculated as 1/(old_value*lfu_log_factor+1).</span><br><span class="line"># 3. The counter is incremented only if R &lt; P.</span><br><span class="line">#</span><br><span class="line"># The default lfu-log-factor is 10. This is a table of how the frequency</span><br><span class="line"># counter changes with a different number of accesses with different</span><br><span class="line"># logarithmic factors:</span><br><span class="line">#</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line"># | factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line"># | 0      | 104        | 255        | 255        | 255        | 255        |</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line"># | 1      | 18         | 49         | 255        | 255        | 255        |</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line"># | 10     | 10         | 18         | 142        | 255        | 255        |</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line"># | 100    | 8          | 11         | 49         | 143        | 255        |</span><br><span class="line"># +--------+------------+------------+------------+------------+------------+</span><br><span class="line">#</span><br><span class="line"># NOTE: The above table was obtained by running the following commands:</span><br><span class="line">#</span><br><span class="line">#   redis-benchmark -n 1000000 incr foo</span><br><span class="line">#   redis-cli object freq foo</span><br><span class="line">#</span><br><span class="line"># NOTE 2: The counter initial value is 5 in order to give new objects a chance</span><br><span class="line"># to accumulate hits.</span><br><span class="line">#</span><br><span class="line"># The counter decay time is the time, in minutes, that must elapse in order</span><br><span class="line"># for the key counter to be divided by two (or decremented if it has a value</span><br><span class="line"># less &lt;= 10).</span><br><span class="line">#</span><br><span class="line"># The default value for the lfu-decay-time is 1. A Special value of 0 means to</span><br><span class="line"># decay the counter every time it happens to be scanned.</span><br><span class="line">#</span><br><span class="line"># lfu-log-factor 10</span><br><span class="line"># lfu-decay-time 1</span><br><span class="line"> </span><br><span class="line">########################### ACTIVE DEFRAGMENTATION #######################</span><br><span class="line">#</span><br><span class="line"># WARNING THIS FEATURE IS EXPERIMENTAL. However it was stress tested</span><br><span class="line"># even in production and manually tested by multiple engineers for some</span><br><span class="line"># time.</span><br><span class="line">#</span><br><span class="line"># What is active defragmentation?</span><br><span class="line"># -------------------------------</span><br><span class="line">#</span><br><span class="line"># Active (online) defragmentation allows a Redis server to compact the</span><br><span class="line"># spaces left between small allocations and deallocations of data in memory,</span><br><span class="line"># thus allowing to reclaim back memory.</span><br><span class="line">#</span><br><span class="line"># Fragmentation is a natural process that happens with every allocator (but</span><br><span class="line"># less so with Jemalloc, fortunately) and certain workloads. Normally a server</span><br><span class="line"># restart is needed in order to lower the fragmentation, or at least to flush</span><br><span class="line"># away all the data and create it again. However thanks to this feature</span><br><span class="line"># implemented by Oran Agra for Redis 4.0 this process can happen at runtime</span><br><span class="line"># in an &quot;hot&quot; way, while the server is running.</span><br><span class="line">#</span><br><span class="line"># Basically when the fragmentation is over a certain level (see the</span><br><span class="line"># configuration options below) Redis will start to create new copies of the</span><br><span class="line"># values in contiguous memory regions by exploiting certain specific Jemalloc</span><br><span class="line"># features (in order to understand if an allocation is causing fragmentation</span><br><span class="line"># and to allocate it in a better place), and at the same time, will release the</span><br><span class="line"># old copies of the data. This process, repeated incrementally for all the keys</span><br><span class="line"># will cause the fragmentation to drop back to normal values.</span><br><span class="line">#</span><br><span class="line"># Important things to understand:</span><br><span class="line">#</span><br><span class="line"># 1. This feature is disabled by default, and only works if you compiled Redis</span><br><span class="line">#    to use the copy of Jemalloc we ship with the source code of Redis.</span><br><span class="line">#    This is the default with Linux builds.</span><br><span class="line">#</span><br><span class="line"># 2. You never need to enable this feature if you don&#x27;t have fragmentation</span><br><span class="line">#    issues.</span><br><span class="line">#</span><br><span class="line"># 3. Once you experience fragmentation, you can enable this feature when</span><br><span class="line">#    needed with the command &quot;CONFIG SET activedefrag yes&quot;.</span><br><span class="line">#</span><br><span class="line"># The configuration parameters are able to fine tune the behavior of the</span><br><span class="line"># defragmentation process. If you are not sure about what they mean it is</span><br><span class="line"># a good idea to leave the defaults untouched.</span><br><span class="line"> </span><br><span class="line"># Enabled active defragmentation</span><br><span class="line"># activedefrag yes</span><br><span class="line"> </span><br><span class="line"># Minimum amount of fragmentation waste to start active defrag</span><br><span class="line"># active-defrag-ignore-bytes 100mb</span><br><span class="line"> </span><br><span class="line"># Minimum percentage of fragmentation to start active defrag</span><br><span class="line"># active-defrag-threshold-lower 10</span><br><span class="line"> </span><br><span class="line"># Maximum percentage of fragmentation at which we use maximum effort</span><br><span class="line"># active-defrag-threshold-upper 100</span><br><span class="line"> </span><br><span class="line"># Minimal effort for defrag in CPU percentage</span><br><span class="line"># active-defrag-cycle-min 25</span><br><span class="line"> </span><br><span class="line"># Maximal effort for defrag in CPU percentage</span><br><span class="line"># active-defrag-cycle-max 75</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="精简redis-conf"><a href="#精简redis-conf" class="headerlink" title="精简redis.conf"></a>精简redis.conf</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bind *</span><br><span class="line">protected-mode yes</span><br><span class="line">port 6379</span><br><span class="line">tcp-backlog 511</span><br><span class="line">timeout 0</span><br><span class="line">tcp-keepalive 300</span><br><span class="line">supervised no</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line">loglevel notice</span><br><span class="line">logfile &quot;/data/redis.log&quot;</span><br><span class="line">databases 16</span><br><span class="line">always-show-logo yes</span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line">rdbcompression yes</span><br><span class="line">rdbchecksum yes</span><br><span class="line">dbfilename dump.rdb</span><br><span class="line">dir ./</span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line">slave-read-only yes</span><br><span class="line">repl-diskless-sync no</span><br><span class="line">repl-diskless-sync-delay 5</span><br><span class="line">repl-disable-tcp-nodelay no</span><br><span class="line">slave-priority 100</span><br><span class="line">requirepass 123456</span><br><span class="line">lazyfree-lazy-eviction no</span><br><span class="line">lazyfree-lazy-expire no</span><br><span class="line">lazyfree-lazy-server-del no</span><br><span class="line">slave-lazy-flush no</span><br><span class="line">appendonly no</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line">appendfsync everysec</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line">aof-load-truncated yes</span><br><span class="line">aof-use-rdb-preamble no</span><br><span class="line">lua-time-limit 5000</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line">slowlog-max-len 128</span><br><span class="line">latency-monitor-threshold 0</span><br><span class="line">notify-keyspace-events &quot;&quot;</span><br><span class="line">hash-max-ziplist-entries 512</span><br><span class="line">hash-max-ziplist-value 64</span><br><span class="line">list-max-ziplist-size -2</span><br><span class="line">list-compress-depth 0</span><br><span class="line">set-max-intset-entries 512</span><br><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br><span class="line">hll-sparse-max-bytes 3000</span><br><span class="line">activerehashing yes</span><br><span class="line">client-output-buffer-limit normal 0 0 0</span><br><span class="line">client-output-buffer-limit slave 256mb 64mb 60</span><br><span class="line">client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line">hz 10</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br></pre></td></tr></table></figure>

<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name redis --restart=always -p 6379:6379 -v ~/redis/log/redis.log:/data/redis.log -v /etc/localtime:/etc/localtime:ro -v ~/redis/conf/redis.conf:/etc/redis/redis.conf -v ~/redis/data:/data -d redis:latest redis-server /etc/redis/redis.conf</span><br></pre></td></tr></table></figure>

<h2 id="快速运行"><a href="#快速运行" class="headerlink" title="快速运行"></a>快速运行</h2><h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> -vp /data/redis/&#123;data,conf,<span class="built_in">log</span>&#125;</span><br><span class="line"><span class="built_in">touch</span> /data/redis/conf/redis.conf</span><br><span class="line"><span class="built_in">touch</span> /data/redis/log/redis.log</span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line"><span class="built_in">cat</span> &lt;&lt; <span class="string">EOF &gt; /data/redis/conf/data.conf</span></span><br><span class="line"><span class="string">bind *</span></span><br><span class="line"><span class="string">protected-mode yes</span></span><br><span class="line"><span class="string">port 6379</span></span><br><span class="line"><span class="string">tcp-backlog 511</span></span><br><span class="line"><span class="string">timeout 0</span></span><br><span class="line"><span class="string">tcp-keepalive 300</span></span><br><span class="line"><span class="string">supervised no</span></span><br><span class="line"><span class="string">pidfile /var/run/redis_6379.pid</span></span><br><span class="line"><span class="string">loglevel notice</span></span><br><span class="line"><span class="string">logfile &quot;/data/redis.log&quot;</span></span><br><span class="line"><span class="string">databases 16</span></span><br><span class="line"><span class="string">always-show-logo yes</span></span><br><span class="line"><span class="string">save 900 1</span></span><br><span class="line"><span class="string">save 300 10</span></span><br><span class="line"><span class="string">save 60 10000</span></span><br><span class="line"><span class="string">stop-writes-on-bgsave-error yes</span></span><br><span class="line"><span class="string">rdbcompression yes</span></span><br><span class="line"><span class="string">rdbchecksum yes</span></span><br><span class="line"><span class="string">dbfilename dump.rdb</span></span><br><span class="line"><span class="string">dir ./</span></span><br><span class="line"><span class="string">slave-serve-stale-data yes</span></span><br><span class="line"><span class="string">slave-read-only yes</span></span><br><span class="line"><span class="string">repl-diskless-sync no</span></span><br><span class="line"><span class="string">repl-diskless-sync-delay 5</span></span><br><span class="line"><span class="string">repl-disable-tcp-nodelay no</span></span><br><span class="line"><span class="string">slave-priority 100</span></span><br><span class="line"><span class="string">requirepass 123456</span></span><br><span class="line"><span class="string">lazyfree-lazy-eviction no</span></span><br><span class="line"><span class="string">lazyfree-lazy-expire no</span></span><br><span class="line"><span class="string">lazyfree-lazy-server-del no</span></span><br><span class="line"><span class="string">slave-lazy-flush no</span></span><br><span class="line"><span class="string">appendonly no</span></span><br><span class="line"><span class="string">appendfilename &quot;appendonly.aof&quot;</span></span><br><span class="line"><span class="string">appendfsync everysec</span></span><br><span class="line"><span class="string">no-appendfsync-on-rewrite no</span></span><br><span class="line"><span class="string">auto-aof-rewrite-percentage 100</span></span><br><span class="line"><span class="string">auto-aof-rewrite-min-size 64mb</span></span><br><span class="line"><span class="string">aof-load-truncated yes</span></span><br><span class="line"><span class="string">aof-use-rdb-preamble no</span></span><br><span class="line"><span class="string">lua-time-limit 5000</span></span><br><span class="line"><span class="string">slowlog-log-slower-than 10000</span></span><br><span class="line"><span class="string">slowlog-max-len 128</span></span><br><span class="line"><span class="string">latency-monitor-threshold 0</span></span><br><span class="line"><span class="string">notify-keyspace-events &quot;&quot;</span></span><br><span class="line"><span class="string">hash-max-ziplist-entries 512</span></span><br><span class="line"><span class="string">hash-max-ziplist-value 64</span></span><br><span class="line"><span class="string">list-max-ziplist-size -2</span></span><br><span class="line"><span class="string">list-compress-depth 0</span></span><br><span class="line"><span class="string">set-max-intset-entries 512</span></span><br><span class="line"><span class="string">zset-max-ziplist-entries 128</span></span><br><span class="line"><span class="string">zset-max-ziplist-value 64</span></span><br><span class="line"><span class="string">hll-sparse-max-bytes 3000</span></span><br><span class="line"><span class="string">activerehashing yes</span></span><br><span class="line"><span class="string">client-output-buffer-limit normal 0 0 0</span></span><br><span class="line"><span class="string">client-output-buffer-limit slave 256mb 64mb 60</span></span><br><span class="line"><span class="string">client-output-buffer-limit pubsub 32mb 8mb 60</span></span><br><span class="line"><span class="string">hz 10</span></span><br><span class="line"><span class="string">aof-rewrite-incremental-fsync yes</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">docker run --name redis --restart=always -p 6379:6379 -v ~/redis/log/redis.log:/data/redis.log -v /etc/localtime:/etc/localtime:ro -v ~/redis/conf/redis.conf:/etc/redis/redis.conf -v ~/redis/data:/data -d redis:latest redis-server /etc/redis/redis.conf</span><br><span class="line"></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
        <category>redis</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker镜像代理加速</title>
    <url>/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/</url>
    <content><![CDATA[<h2 id="打开大善人网站"><a href="#打开大善人网站" class="headerlink" title="打开大善人网站"></a>打开大善人网站</h2><p><a href="https://dash.cloudflare.com/">https://dash.cloudflare.com/</a></p>
<h2 id="找到-Workers-Pages"><a href="#找到-Workers-Pages" class="headerlink" title="找到 Workers &amp; Pages"></a>找到 Workers &amp; Pages</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image.png" class="" alt="找到 Workers &amp; Pages">

<h2 id="找到-Create-按钮"><a href="#找到-Create-按钮" class="headerlink" title="找到 Create 按钮"></a>找到 Create 按钮</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image2.png" class="" alt="找到 Create 按钮">

<h2 id="选择Workers-然后点击Create-Workers"><a href="#选择Workers-然后点击Create-Workers" class="headerlink" title="选择Workers 然后点击Create Workers"></a>选择Workers 然后点击Create Workers</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image3.png" class="" alt="选择Workers 然后点击Create Workers">

<h2 id="输入前缀-比如：dockerproxy"><a href="#输入前缀-比如：dockerproxy" class="headerlink" title="输入前缀 比如：dockerproxy"></a>输入前缀 比如：dockerproxy</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image4.png" class="" alt="输入前缀 比如：dockerproxy">

<h2 id="然后点击Save保存"><a href="#然后点击Save保存" class="headerlink" title="然后点击Save保存"></a>然后点击Save保存</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-1.png" class="" alt="Save保存">

<h2 id="保存好之后-就会出现这个页面-什么也不用管-直接finish"><a href="#保存好之后-就会出现这个页面-什么也不用管-直接finish" class="headerlink" title="保存好之后 就会出现这个页面 什么也不用管 直接finish"></a>保存好之后 就会出现这个页面 什么也不用管 直接finish</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-2.png" class="" alt="直接finish">

<h2 id="成功-然后点击‘Edit-code’开始编辑workers-js"><a href="#成功-然后点击‘Edit-code’开始编辑workers-js" class="headerlink" title="成功 然后点击‘Edit code’开始编辑workers.js"></a>成功 然后点击‘Edit code’开始编辑workers.js</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-3.png" class="" alt="workers.js">

<h2 id="把自带的内容删除掉"><a href="#把自带的内容删除掉" class="headerlink" title="把自带的内容删除掉"></a>把自带的内容删除掉</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-4.png" class="" alt="把自带的内容删除掉">


<h2 id="把代码粘贴进去"><a href="#把代码粘贴进去" class="headerlink" title="把代码粘贴进去"></a>把代码粘贴进去</h2><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// _worker.js</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Docker镜像仓库主机地址</span></span><br><span class="line"><span class="keyword">let</span> hub_host = <span class="string">&#x27;registry-1.docker.io&#x27;</span></span><br><span class="line"><span class="comment">// Docker认证服务器地址</span></span><br><span class="line"><span class="keyword">const</span> auth_url = <span class="string">&#x27;https://auth.docker.io&#x27;</span></span><br><span class="line"><span class="comment">// 自定义的工作服务器地址</span></span><br><span class="line"><span class="keyword">let</span> workers_url = <span class="string">&#x27;https://你的域名&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 根据主机名选择对应的上游地址</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">routeByHosts</span>(<span class="params">host</span>) &#123;</span><br><span class="line">		<span class="comment">// 定义路由表</span></span><br><span class="line">	<span class="keyword">const</span> routes = &#123;</span><br><span class="line">		<span class="comment">// 生产环境</span></span><br><span class="line">		<span class="string">&quot;quay&quot;</span>: <span class="string">&quot;quay.io&quot;</span>,</span><br><span class="line">		<span class="string">&quot;gcr&quot;</span>: <span class="string">&quot;gcr.io&quot;</span>,</span><br><span class="line">		<span class="string">&quot;k8s-gcr&quot;</span>: <span class="string">&quot;k8s.gcr.io&quot;</span>,</span><br><span class="line">		<span class="string">&quot;k8s&quot;</span>: <span class="string">&quot;registry.k8s.io&quot;</span>,</span><br><span class="line">		<span class="string">&quot;ghcr&quot;</span>: <span class="string">&quot;ghcr.io&quot;</span>,</span><br><span class="line">		<span class="string">&quot;cloudsmith&quot;</span>: <span class="string">&quot;docker.cloudsmith.io&quot;</span>,</span><br><span class="line">		</span><br><span class="line">		<span class="comment">// 测试环境</span></span><br><span class="line">		<span class="string">&quot;test&quot;</span>: <span class="string">&quot;registry-1.docker.io&quot;</span>,</span><br><span class="line">	&#125;;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (host <span class="keyword">in</span> routes) <span class="keyword">return</span> [ routes[host], <span class="literal">false</span> ];</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">return</span> [ hub_host, <span class="literal">true</span> ];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/** <span class="doctag">@type</span> &#123;<span class="type">RequestInit</span>&#125; */</span></span><br><span class="line"><span class="keyword">const</span> <span class="variable constant_">PREFLIGHT_INIT</span> = &#123;</span><br><span class="line">	<span class="comment">// 预检请求配置</span></span><br><span class="line">	<span class="attr">headers</span>: <span class="keyword">new</span> <span class="title class_">Headers</span>(&#123;</span><br><span class="line">		<span class="string">&#x27;access-control-allow-origin&#x27;</span>: <span class="string">&#x27;*&#x27;</span>, <span class="comment">// 允许所有来源</span></span><br><span class="line">		<span class="string">&#x27;access-control-allow-methods&#x27;</span>: <span class="string">&#x27;GET,POST,PUT,PATCH,TRACE,DELETE,HEAD,OPTIONS&#x27;</span>, <span class="comment">// 允许的HTTP方法</span></span><br><span class="line">		<span class="string">&#x27;access-control-max-age&#x27;</span>: <span class="string">&#x27;1728000&#x27;</span>, <span class="comment">// 预检请求的缓存时间</span></span><br><span class="line">	&#125;),</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造响应</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">any</span>&#125; body 响应体</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">number</span>&#125; status 响应状态码</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">Object&lt;string, string&gt;</span>&#125; headers 响应头</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">makeRes</span>(<span class="params">body, status = <span class="number">200</span>, headers = &#123;&#125;</span>) &#123;</span><br><span class="line">	headers[<span class="string">&#x27;access-control-allow-origin&#x27;</span>] = <span class="string">&#x27;*&#x27;</span> <span class="comment">// 允许所有来源</span></span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(body, &#123; status, headers &#125;) <span class="comment">// 返回新构造的响应</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 构造新的URL对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; urlStr URL字符串</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">newUrl</span>(<span class="params">urlStr</span>) &#123;</span><br><span class="line">	<span class="keyword">try</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> <span class="title function_">URL</span>(urlStr) <span class="comment">// 尝试构造新的URL对象</span></span><br><span class="line">	&#125; <span class="keyword">catch</span> (err) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">null</span> <span class="comment">// 构造失败返回null</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">isUUID</span>(<span class="params">uuid</span>) &#123;</span><br><span class="line">	<span class="comment">// 定义一个正则表达式来匹配 UUID 格式</span></span><br><span class="line">	<span class="keyword">const</span> uuidRegex = <span class="regexp">/^[0-9a-f]&#123;8&#125;-[0-9a-f]&#123;4&#125;-[4][0-9a-f]&#123;3&#125;-[89ab][0-9a-f]&#123;3&#125;-[0-9a-f]&#123;12&#125;$/i</span>;</span><br><span class="line">	</span><br><span class="line">	<span class="comment">// 使用正则表达式测试 UUID 字符串</span></span><br><span class="line">	<span class="keyword">return</span> uuidRegex.<span class="title function_">test</span>(uuid);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">nginx</span>(<span class="params"></span>) &#123;</span><br><span class="line">	<span class="keyword">const</span> text = <span class="string">`</span></span><br><span class="line"><span class="string">	&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="string">	&lt;html&gt;</span></span><br><span class="line"><span class="string">	&lt;head&gt;</span></span><br><span class="line"><span class="string">	&lt;title&gt;Welcome to nginx!&lt;/title&gt;</span></span><br><span class="line"><span class="string">	&lt;style&gt;</span></span><br><span class="line"><span class="string">		body &#123;</span></span><br><span class="line"><span class="string">			width: 35em;</span></span><br><span class="line"><span class="string">			margin: 0 auto;</span></span><br><span class="line"><span class="string">			font-family: Tahoma, Verdana, Arial, sans-serif;</span></span><br><span class="line"><span class="string">		&#125;</span></span><br><span class="line"><span class="string">	&lt;/style&gt;</span></span><br><span class="line"><span class="string">	&lt;/head&gt;</span></span><br><span class="line"><span class="string">	&lt;body&gt;</span></span><br><span class="line"><span class="string">	&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;</span></span><br><span class="line"><span class="string">	&lt;p&gt;If you see this page, the nginx web server is successfully installed and</span></span><br><span class="line"><span class="string">	working. Further configuration is required.&lt;/p&gt;</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">	&lt;p&gt;For online documentation and support please refer to</span></span><br><span class="line"><span class="string">	&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;</span></span><br><span class="line"><span class="string">	Commercial support is available at</span></span><br><span class="line"><span class="string">	&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">	&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">	&lt;/body&gt;</span></span><br><span class="line"><span class="string">	&lt;/html&gt;</span></span><br><span class="line"><span class="string">	`</span></span><br><span class="line">	<span class="keyword">return</span> text ;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">	<span class="keyword">async</span> <span class="title function_">fetch</span>(<span class="params">request, env, ctx</span>) &#123;</span><br><span class="line">		<span class="keyword">const</span> <span class="title function_">getReqHeader</span> = (<span class="params">key</span>) =&gt; request.<span class="property">headers</span>.<span class="title function_">get</span>(key); <span class="comment">// 获取请求头</span></span><br><span class="line"></span><br><span class="line">		<span class="keyword">let</span> url = <span class="keyword">new</span> <span class="title function_">URL</span>(request.<span class="property">url</span>); <span class="comment">// 解析请求URL</span></span><br><span class="line">		workers_url = <span class="string">`https://<span class="subst">$&#123;url.hostname&#125;</span>`</span>;</span><br><span class="line">		<span class="keyword">const</span> pathname = url.<span class="property">pathname</span>;</span><br><span class="line">		<span class="keyword">const</span> hostname = url.<span class="property">searchParams</span>.<span class="title function_">get</span>(<span class="string">&#x27;hubhost&#x27;</span>) || url.<span class="property">hostname</span>; </span><br><span class="line">		<span class="keyword">const</span> hostTop = hostname.<span class="title function_">split</span>(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>];<span class="comment">// 获取主机名的第一部分</span></span><br><span class="line">		<span class="keyword">const</span> checkHost = <span class="title function_">routeByHosts</span>(hostTop);</span><br><span class="line">		hub_host = checkHost[<span class="number">0</span>]; <span class="comment">// 获取上游地址</span></span><br><span class="line">		<span class="keyword">const</span> fakePage = checkHost[<span class="number">1</span>];</span><br><span class="line">		<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`域名头部: <span class="subst">$&#123;hostTop&#125;</span>\n反代地址: <span class="subst">$&#123;hub_host&#125;</span>\n伪装首页: <span class="subst">$&#123;fakePage&#125;</span>`</span>);</span><br><span class="line">		<span class="keyword">const</span> isUuid = <span class="title function_">isUUID</span>(pathname.<span class="title function_">split</span>(<span class="string">&#x27;/&#x27;</span>)[<span class="number">1</span>].<span class="title function_">split</span>(<span class="string">&#x27;/&#x27;</span>)[<span class="number">0</span>]);</span><br><span class="line">		</span><br><span class="line">		<span class="keyword">const</span> conditions = [</span><br><span class="line">			isUuid,</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/_&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/r&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/v2/user&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/v2/orgs&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/v2/_catalog&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/v2/categories&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;/v2/feature-flags&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;search&#x27;</span>),</span><br><span class="line">			pathname.<span class="title function_">includes</span>(<span class="string">&#x27;source&#x27;</span>),</span><br><span class="line">			pathname === <span class="string">&#x27;/&#x27;</span>,</span><br><span class="line">			pathname === <span class="string">&#x27;/favicon.ico&#x27;</span>,</span><br><span class="line">			pathname === <span class="string">&#x27;/auth/profile&#x27;</span>,</span><br><span class="line">		];</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (conditions.<span class="title function_">some</span>(<span class="function"><span class="params">condition</span> =&gt;</span> condition) &amp;&amp; (fakePage === <span class="literal">true</span> || hostTop == <span class="string">&#x27;docker&#x27;</span>)) &#123;</span><br><span class="line">			<span class="keyword">if</span> (env.<span class="property">URL302</span>)&#123;</span><br><span class="line">				<span class="keyword">return</span> <span class="title class_">Response</span>.<span class="title function_">redirect</span>(env.<span class="property">URL302</span>, <span class="number">302</span>);</span><br><span class="line">			&#125; <span class="keyword">else</span> <span class="keyword">if</span> (env.<span class="property">URL</span>)&#123;</span><br><span class="line">				<span class="keyword">if</span> (env.<span class="property">URL</span>.<span class="title function_">toLowerCase</span>() == <span class="string">&#x27;nginx&#x27;</span>)&#123;</span><br><span class="line">					<span class="comment">//首页改成一个nginx伪装页</span></span><br><span class="line">					<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(<span class="keyword">await</span> <span class="title function_">nginx</span>(), &#123;</span><br><span class="line">						<span class="attr">headers</span>: &#123;</span><br><span class="line">							<span class="string">&#x27;Content-Type&#x27;</span>: <span class="string">&#x27;text/html; charset=UTF-8&#x27;</span>,</span><br><span class="line">						&#125;,</span><br><span class="line">					&#125;);</span><br><span class="line">				&#125; <span class="keyword">else</span> <span class="keyword">return</span> <span class="title function_">fetch</span>(<span class="keyword">new</span> <span class="title class_">Request</span>(env.<span class="property">URL</span>, request));</span><br><span class="line">			&#125;</span><br><span class="line">			</span><br><span class="line">			<span class="keyword">const</span> newUrl = <span class="keyword">new</span> <span class="title function_">URL</span>(<span class="string">&quot;https://registry.hub.docker.com&quot;</span> + pathname + url.<span class="property">search</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 复制原始请求的标头</span></span><br><span class="line">			<span class="keyword">const</span> headers = <span class="keyword">new</span> <span class="title class_">Headers</span>(request.<span class="property">headers</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 确保 Host 头部被替换为 hub.docker.com</span></span><br><span class="line">			headers.<span class="title function_">set</span>(<span class="string">&#x27;Host&#x27;</span>, <span class="string">&#x27;registry.hub.docker.com&#x27;</span>);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">const</span> newRequest = <span class="keyword">new</span> <span class="title class_">Request</span>(newUrl, &#123;</span><br><span class="line">					<span class="attr">method</span>: request.<span class="property">method</span>,</span><br><span class="line">					<span class="attr">headers</span>: headers,</span><br><span class="line">					<span class="attr">body</span>: request.<span class="property">method</span> !== <span class="string">&#x27;GET&#x27;</span> &amp;&amp; request.<span class="property">method</span> !== <span class="string">&#x27;HEAD&#x27;</span> ? <span class="keyword">await</span> request.<span class="title function_">blob</span>() : <span class="literal">null</span>,</span><br><span class="line">					<span class="attr">redirect</span>: <span class="string">&#x27;follow&#x27;</span></span><br><span class="line">			&#125;);</span><br><span class="line"></span><br><span class="line">			<span class="keyword">return</span> <span class="title function_">fetch</span>(newRequest);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 修改包含 %2F 和 %3A 的请求</span></span><br><span class="line">		<span class="keyword">if</span> (!<span class="regexp">/%2F/</span>.<span class="title function_">test</span>(url.<span class="property">search</span>) &amp;&amp; <span class="regexp">/%3A/</span>.<span class="title function_">test</span>(url.<span class="title function_">toString</span>())) &#123;</span><br><span class="line">			<span class="keyword">let</span> modifiedUrl = url.<span class="title function_">toString</span>().<span class="title function_">replace</span>(<span class="regexp">/%3A(?=.*?&amp;)/</span>, <span class="string">&#x27;%3Alibrary%2F&#x27;</span>);</span><br><span class="line">			url = <span class="keyword">new</span> <span class="title function_">URL</span>(modifiedUrl);</span><br><span class="line">			<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`handle_url: <span class="subst">$&#123;url&#125;</span>`</span>)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 处理token请求</span></span><br><span class="line">		<span class="keyword">if</span> (url.<span class="property">pathname</span>.<span class="title function_">includes</span>(<span class="string">&#x27;/token&#x27;</span>)) &#123;</span><br><span class="line">			<span class="keyword">let</span> token_parameter = &#123;</span><br><span class="line">				<span class="attr">headers</span>: &#123;</span><br><span class="line">					<span class="string">&#x27;Host&#x27;</span>: <span class="string">&#x27;auth.docker.io&#x27;</span>,</span><br><span class="line">					<span class="string">&#x27;User-Agent&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;User-Agent&quot;</span>),</span><br><span class="line">					<span class="string">&#x27;Accept&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept&quot;</span>),</span><br><span class="line">					<span class="string">&#x27;Accept-Language&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept-Language&quot;</span>),</span><br><span class="line">					<span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept-Encoding&quot;</span>),</span><br><span class="line">					<span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">					<span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;max-age=0&#x27;</span></span><br><span class="line">				&#125;</span><br><span class="line">			&#125;;</span><br><span class="line">			<span class="keyword">let</span> token_url = auth_url + url.<span class="property">pathname</span> + url.<span class="property">search</span></span><br><span class="line">			<span class="keyword">return</span> <span class="title function_">fetch</span>(<span class="keyword">new</span> <span class="title class_">Request</span>(token_url, request), token_parameter)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 修改 /v2/ 请求路径</span></span><br><span class="line">		<span class="keyword">if</span> (<span class="regexp">/^\/v2\/[^/]+\/[^/]+\/[^/]+$/</span>.<span class="title function_">test</span>(url.<span class="property">pathname</span>) &amp;&amp; !<span class="regexp">/^\/v2\/library/</span>.<span class="title function_">test</span>(url.<span class="property">pathname</span>)) &#123;</span><br><span class="line">			url.<span class="property">pathname</span> = url.<span class="property">pathname</span>.<span class="title function_">replace</span>(<span class="regexp">/\/v2\//</span>, <span class="string">&#x27;/v2/library/&#x27;</span>);</span><br><span class="line">			<span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`modified_url: <span class="subst">$&#123;url.pathname&#125;</span>`</span>)</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 更改请求的主机名</span></span><br><span class="line">		url.<span class="property">hostname</span> = hub_host;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 构造请求参数</span></span><br><span class="line">		<span class="keyword">let</span> parameter = &#123;</span><br><span class="line">			<span class="attr">headers</span>: &#123;</span><br><span class="line">				<span class="string">&#x27;Host&#x27;</span>: hub_host,</span><br><span class="line">				<span class="string">&#x27;User-Agent&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;User-Agent&quot;</span>),</span><br><span class="line">				<span class="string">&#x27;Accept&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept&quot;</span>),</span><br><span class="line">				<span class="string">&#x27;Accept-Language&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept-Language&quot;</span>),</span><br><span class="line">				<span class="string">&#x27;Accept-Encoding&#x27;</span>: <span class="title function_">getReqHeader</span>(<span class="string">&quot;Accept-Encoding&quot;</span>),</span><br><span class="line">				<span class="string">&#x27;Connection&#x27;</span>: <span class="string">&#x27;keep-alive&#x27;</span>,</span><br><span class="line">				<span class="string">&#x27;Cache-Control&#x27;</span>: <span class="string">&#x27;max-age=0&#x27;</span></span><br><span class="line">			&#125;,</span><br><span class="line">			<span class="attr">cacheTtl</span>: <span class="number">3600</span> <span class="comment">// 缓存时间</span></span><br><span class="line">		&#125;;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 添加Authorization头</span></span><br><span class="line">		<span class="keyword">if</span> (request.<span class="property">headers</span>.<span class="title function_">has</span>(<span class="string">&quot;Authorization&quot;</span>)) &#123;</span><br><span class="line">			parameter.<span class="property">headers</span>.<span class="property">Authorization</span> = <span class="title function_">getReqHeader</span>(<span class="string">&quot;Authorization&quot;</span>);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 发起请求并处理响应</span></span><br><span class="line">		<span class="keyword">let</span> original_response = <span class="keyword">await</span> <span class="title function_">fetch</span>(<span class="keyword">new</span> <span class="title class_">Request</span>(url, request), parameter)</span><br><span class="line">		<span class="keyword">let</span> original_response_clone = original_response.<span class="title function_">clone</span>();</span><br><span class="line">		<span class="keyword">let</span> original_text = original_response_clone.<span class="property">body</span>;</span><br><span class="line">		<span class="keyword">let</span> response_headers = original_response.<span class="property">headers</span>;</span><br><span class="line">		<span class="keyword">let</span> new_response_headers = <span class="keyword">new</span> <span class="title class_">Headers</span>(response_headers);</span><br><span class="line">		<span class="keyword">let</span> status = original_response.<span class="property">status</span>;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 修改 Www-Authenticate 头</span></span><br><span class="line">		<span class="keyword">if</span> (new_response_headers.<span class="title function_">get</span>(<span class="string">&quot;Www-Authenticate&quot;</span>)) &#123;</span><br><span class="line">			<span class="keyword">let</span> auth = new_response_headers.<span class="title function_">get</span>(<span class="string">&quot;Www-Authenticate&quot;</span>);</span><br><span class="line">			<span class="keyword">let</span> re = <span class="keyword">new</span> <span class="title class_">RegExp</span>(auth_url, <span class="string">&#x27;g&#x27;</span>);</span><br><span class="line">			new_response_headers.<span class="title function_">set</span>(<span class="string">&quot;Www-Authenticate&quot;</span>, response_headers.<span class="title function_">get</span>(<span class="string">&quot;Www-Authenticate&quot;</span>).<span class="title function_">replace</span>(re, workers_url));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 处理重定向</span></span><br><span class="line">		<span class="keyword">if</span> (new_response_headers.<span class="title function_">get</span>(<span class="string">&quot;Location&quot;</span>)) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="title function_">httpHandler</span>(request, new_response_headers.<span class="title function_">get</span>(<span class="string">&quot;Location&quot;</span>))</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 返回修改后的响应</span></span><br><span class="line">		<span class="keyword">let</span> response = <span class="keyword">new</span> <span class="title class_">Response</span>(original_text, &#123;</span><br><span class="line">			status,</span><br><span class="line">			<span class="attr">headers</span>: new_response_headers</span><br><span class="line">		&#125;)</span><br><span class="line">		<span class="keyword">return</span> response;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 处理HTTP请求</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">Request</span>&#125; req 请求对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; pathname 请求路径</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">httpHandler</span>(<span class="params">req, pathname</span>) &#123;</span><br><span class="line">	<span class="keyword">const</span> reqHdrRaw = req.<span class="property">headers</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// 处理预检请求</span></span><br><span class="line">	<span class="keyword">if</span> (req.<span class="property">method</span> === <span class="string">&#x27;OPTIONS&#x27;</span> &amp;&amp;</span><br><span class="line">		reqHdrRaw.<span class="title function_">has</span>(<span class="string">&#x27;access-control-request-headers&#x27;</span>)</span><br><span class="line">	) &#123;</span><br><span class="line">		<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(<span class="literal">null</span>, <span class="variable constant_">PREFLIGHT_INIT</span>)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">let</span> rawLen = <span class="string">&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">const</span> reqHdrNew = <span class="keyword">new</span> <span class="title class_">Headers</span>(reqHdrRaw)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">const</span> refer = reqHdrNew.<span class="title function_">get</span>(<span class="string">&#x27;referer&#x27;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">let</span> urlStr = pathname</span><br><span class="line"></span><br><span class="line">	<span class="keyword">const</span> urlObj = <span class="title function_">newUrl</span>(urlStr)</span><br><span class="line"></span><br><span class="line">	<span class="comment">/** <span class="doctag">@type</span> &#123;<span class="type">RequestInit</span>&#125; */</span></span><br><span class="line">	<span class="keyword">const</span> reqInit = &#123;</span><br><span class="line">		<span class="attr">method</span>: req.<span class="property">method</span>,</span><br><span class="line">		<span class="attr">headers</span>: reqHdrNew,</span><br><span class="line">		<span class="attr">redirect</span>: <span class="string">&#x27;follow&#x27;</span>,</span><br><span class="line">		<span class="attr">body</span>: req.<span class="property">body</span></span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="title function_">proxy</span>(urlObj, reqInit, rawLen)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 代理请求</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">URL</span>&#125; urlObj URL对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">RequestInit</span>&#125; reqInit 请求初始化对象</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &#123;<span class="type">string</span>&#125; rawLen 原始长度</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">function</span> <span class="title function_">proxy</span>(<span class="params">urlObj, reqInit, rawLen</span>) &#123;</span><br><span class="line">	<span class="keyword">const</span> res = <span class="keyword">await</span> <span class="title function_">fetch</span>(urlObj.<span class="property">href</span>, reqInit)</span><br><span class="line">	<span class="keyword">const</span> resHdrOld = res.<span class="property">headers</span></span><br><span class="line">	<span class="keyword">const</span> resHdrNew = <span class="keyword">new</span> <span class="title class_">Headers</span>(resHdrOld)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 验证长度</span></span><br><span class="line">	<span class="keyword">if</span> (rawLen) &#123;</span><br><span class="line">		<span class="keyword">const</span> newLen = resHdrOld.<span class="title function_">get</span>(<span class="string">&#x27;content-length&#x27;</span>) || <span class="string">&#x27;&#x27;</span></span><br><span class="line">		<span class="keyword">const</span> badLen = (rawLen !== newLen)</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (badLen) &#123;</span><br><span class="line">			<span class="keyword">return</span> <span class="title function_">makeRes</span>(res.<span class="property">body</span>, <span class="number">400</span>, &#123;</span><br><span class="line">				<span class="string">&#x27;--error&#x27;</span>: <span class="string">`bad len: <span class="subst">$&#123;newLen&#125;</span>, except: <span class="subst">$&#123;rawLen&#125;</span>`</span>,</span><br><span class="line">				<span class="string">&#x27;access-control-expose-headers&#x27;</span>: <span class="string">&#x27;--error&#x27;</span>,</span><br><span class="line">			&#125;)</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">const</span> status = res.<span class="property">status</span></span><br><span class="line">	resHdrNew.<span class="title function_">set</span>(<span class="string">&#x27;access-control-expose-headers&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">	resHdrNew.<span class="title function_">set</span>(<span class="string">&#x27;access-control-allow-origin&#x27;</span>, <span class="string">&#x27;*&#x27;</span>)</span><br><span class="line">	resHdrNew.<span class="title function_">set</span>(<span class="string">&#x27;Cache-Control&#x27;</span>, <span class="string">&#x27;max-age=1500&#x27;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 删除不必要的头</span></span><br><span class="line">	resHdrNew.<span class="title function_">delete</span>(<span class="string">&#x27;content-security-policy&#x27;</span>)</span><br><span class="line">	resHdrNew.<span class="title function_">delete</span>(<span class="string">&#x27;content-security-policy-report-only&#x27;</span>)</span><br><span class="line">	resHdrNew.<span class="title function_">delete</span>(<span class="string">&#x27;clear-site-data&#x27;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Response</span>(res.<span class="property">body</span>, &#123;</span><br><span class="line">		status,</span><br><span class="line">		<span class="attr">headers</span>: resHdrNew</span><br><span class="line">	&#125;)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="修改自定义域名-需要是托管dns在cloudflare的域名才可以"><a href="#修改自定义域名-需要是托管dns在cloudflare的域名才可以" class="headerlink" title="修改自定义域名 需要是托管dns在cloudflare的域名才可以"></a>修改自定义域名 需要是托管dns在cloudflare的域名才可以</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-5.png" class="" alt="需要是托管dns在cloudflare的域名才可以">

<h2 id="填写完是这样的"><a href="#填写完是这样的" class="headerlink" title="填写完是这样的"></a>填写完是这样的</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-6.png" class="" alt="alt text">

<h2 id="然后去右上角-deploy保存"><a href="#然后去右上角-deploy保存" class="headerlink" title="然后去右上角 deploy保存"></a>然后去右上角 deploy保存</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-7.png" class="" alt="alt text">

<h2 id="然后返回-回到设置"><a href="#然后返回-回到设置" class="headerlink" title="然后返回 回到设置"></a>然后返回 回到设置</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-8.png" class="" alt="alt text">

<h2 id="其他：添加上自定义域名"><a href="#其他：添加上自定义域名" class="headerlink" title="其他：添加上自定义域名"></a>其他：添加上自定义域名</h2><img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-9.png" class="" alt="alt text">

<p>保存 大功告成 现在可以用这个自定义的域名访问了<br>接下来还有可以选择开启的环境变量功能 就是伪装首页</p>
<h2 id="其他：变量说明"><a href="#其他：变量说明" class="headerlink" title="其他：变量说明"></a>其他：变量说明</h2><table>
<thead>
<tr>
<th align="left">变量名</th>
<th align="left">示例</th>
<th align="left">必填</th>
<th align="left">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="left">URL302</td>
<td align="left"><a href="https://baidu.com/">https://baidu.com</a></td>
<td align="left">否</td>
<td align="left">主页302跳转</td>
</tr>
<tr>
<td align="left">URL</td>
<td align="left"><a href="https://dockerpull.com/">https://dockerpull.com</a></td>
<td align="left">否</td>
<td align="left">主页伪装(设为<code>nginx</code>则伪装为nginx默认页面)</td>
</tr>
</tbody></table>
<p>如果你像我的<a href="https://dockerpull.com/">dockerpull.com</a>无所畏惧 就可以不管<br>如果你想自己稳定使用 不想公开的话 可以设置伪装页面<br>找到设置 环境变量</p>
<img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-10.png" class="" alt="alt text">

<p>如果想别人访问域名首页的时候重定向到别的网站<br>可以加入环境变量<code>URL302</code>必须要大写的哈 然后值填写需要目标域名 我以跳转到百度为例</p>
<img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-13.png" class="" alt="alt text">

<p>保存之后 访问首页就会自动跳转到百度 但是拉取docker镜像的时候 不会受到影响</p>
<p>第二种 是伪装首页 可以伪装成任意的网页首页 变量名称改为<code>URL</code> 也是要大写 值输入<a href="https://dockerpull.com/">https://dockerpull.com/</a> 保存</p>
<img data-src="/2024/06/23/docker/Docker%E9%95%9C%E5%83%8F%E4%BB%A3%E7%90%86%E5%8A%A0%E9%80%9F/image-14.png" class="" alt="alt text">

<p>这时候访问域名 就会出现我的那个<a href="https://dockerpull.com/">镜像站</a>的页面 当然也可以用别的页面</p>
<p>全部部署完之后呢 如何使用？</p>
<h2 id="使用方式"><a href="#使用方式" class="headerlink" title="使用方式"></a>使用方式</h2><h3 id="官方镜像路径前面加域名"><a href="#官方镜像路径前面加域名" class="headerlink" title="官方镜像路径前面加域名"></a>官方镜像路径前面加域名</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull dockerpull.com/stilleshan/frpc:latest</span><br></pre></td></tr></table></figure>

<h3 id="一键设置镜像加速"><a href="#一键设置镜像加速" class="headerlink" title="一键设置镜像加速"></a>一键设置镜像加速</h3><p>修改文件 &#x2F;etc&#x2F;docker&#x2F;daemon.json（如果不存在则创建）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line">sudo <span class="built_in">tee</span> /etc/docker/daemon.json &lt;&lt;-<span class="string">&#x27;EOF&#x27;</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;registry-mirrors&quot;</span>: [<span class="string">&quot;https://dockerpull.com&quot;</span>]  <span class="comment"># 请替换为您自己的Worker自定义域名</span></span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>docker</category>
        <category>cloudflare</category>
      </categories>
      <tags>
        <tag>cloudflare</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>IDEA链接Docker</title>
    <url>/2024/04/08/docker/IDEA%E9%93%BE%E6%8E%A5docker/</url>
    <content><![CDATA[<h2 id="下载证书（非必要）"><a href="#下载证书（非必要）" class="headerlink" title="下载证书（非必要）"></a>下载证书（非必要）</h2><p>下载生成的证书</p>


<h2 id="IDEA设置证书访问"><a href="#IDEA设置证书访问" class="headerlink" title="IDEA设置证书访问"></a>IDEA设置证书访问</h2><p>目录: file -&gt; settings</p>
]]></content>
      <categories>
        <category>docker</category>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title>WSL安装Docker</title>
    <url>/2024/06/25/docker/WSL%E5%AE%89%E8%A3%85Docker/</url>
    <content><![CDATA[<h2 id="配置初始环境"><a href="#配置初始环境" class="headerlink" title="配置初始环境"></a>配置初始环境</h2><p>使用WSL2、Ubuntu20.04.6，其他环境不保证正确</p>
<p>在用户文件夹下创建<code>.wslconfig</code>输入内容</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[boot]</span><br><span class="line">systemd=<span class="literal">true</span> <span class="comment"># 启用此设置将在 WSL 实例中启用 systemd 初始化。Systemd 是大多数现代 Linux 发行版的标准 init 系统，允许更好地管理服务和依赖关系。</span></span><br><span class="line"></span><br><span class="line">[experimental]</span><br><span class="line">autoMemoryReclaim=gradual  <span class="comment"># 此选项指定在 WSL 中如何处理内存回收。gradual 表示采用渐进式内存回收，这可能更为保守和平衡。</span></span><br><span class="line">networkingMode=mirrored <span class="comment"># 此设置控制 WSL 中的网络处理方式。mirrored 模式通常会镜像主机操作系统（Windows）的网络配置，使得 WSL 可以共享相同的网络设置。</span></span><br><span class="line">dnsTunneling=<span class="literal">true</span> <span class="comment"># 启用 DNS 隧道功能允许 WSL 使用主机的 DNS 配置，简化 DNS 解析，无需在 WSL 中额外配置。</span></span><br><span class="line">firewall=<span class="literal">true</span> <span class="comment"># 此选项可能启用与 Windows 防火墙的集成，允许 WSL 遵循在主机 Windows 系统上设置的防火墙规则。</span></span><br><span class="line">autoProxy=<span class="literal">true</span> <span class="comment"># 启用 autoProxy 可能允许 WSL 自动使用在 Windows 主机上配置的系统代理设置。</span></span><br></pre></td></tr></table></figure>

<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><p>因为docker官网提供的脚本在疯狂的安利：Docker Desktop for Windows，所以需要把这段代码给屏蔽掉</p>
<p>官方脚本：<a href="https://get.docker.com/">https://get.docker.com</a></p>
<p>需要正常访问并把脚本拷贝一份，然后搜索<code>is_wsl</code>注释掉下面的代码：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#	if is_wsl; then</span></span><br><span class="line"><span class="comment">#		echo</span></span><br><span class="line"><span class="comment">#		echo &quot;WSL DETECTED: We recommend using Docker Desktop for Windows.&quot;</span></span><br><span class="line"><span class="comment">#		echo &quot;Please get Docker Desktop from https://www.docker.com/products/docker-desktop/&quot;</span></span><br><span class="line"><span class="comment">#		echo</span></span><br><span class="line"><span class="comment">#		cat &gt;&amp;2 &lt;&lt;-&#x27;EOF&#x27;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#			You may press Ctrl+C now to abort this script.</span></span><br><span class="line"><span class="comment">#		EOF</span></span><br><span class="line"><span class="comment">#		( set -x; sleep 20 )</span></span><br><span class="line"><span class="comment">#	fi</span></span><br></pre></td></tr></table></figure>

<p>然后使用：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim get-docker.sh</span><br><span class="line"><span class="comment"># 粘贴</span></span><br><span class="line"><span class="built_in">chmod</span> +x get-docker.sh</span><br><span class="line">sudo ./get-docker.sh</span><br><span class="line"><span class="comment"># 等待安装，因为国内已经无法下载镜像了，所以需要自己解决代理问题</span></span><br></pre></td></tr></table></figure>

<h2 id="给普通用户docker权限"><a href="#给普通用户docker权限" class="headerlink" title="给普通用户docker权限"></a>给普通用户docker权限</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建一个名为 docker 的用户组。</span></span><br><span class="line">sudo groupadd docker</span><br><span class="line"><span class="comment"># 将当前用户（$USER）添加到 docker 用户组中，使得该用户能够运行 Docker 命令而无需使用 sudo。</span></span><br><span class="line">sudo usermod -aG docker <span class="variable">$USER</span></span><br><span class="line"><span class="comment"># 启动一个新的 shell，将其当前用户组切换为 docker，这样该 shell 中的命令执行时将具有 docker 组的权限。 </span></span><br><span class="line">newgrp docker</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
        <category>WSL</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title>docker-compose安装</title>
    <url>/2024/05/15/docker/docker-compose%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="docker-compose安装"><a href="#docker-compose安装" class="headerlink" title="docker-compose安装"></a>docker-compose安装</h2><blockquote>
<p>因为版本更新原因推荐安装前去<a href="https://github.com/docker/compose%E6%9F%A5%E8%AF%A2%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC">https://github.com/docker/compose查询最新版本</a></p>
</blockquote>
<p>运行下边的命令来安装 Compose：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -L https://github.com/docker/compose/releases/download/v2.23.3/docker-compose-`<span class="built_in">uname</span> -s`-`<span class="built_in">uname</span> -m` &gt; /usr/local/bin/docker-compose &amp;&amp; <span class="built_in">chmod</span> +x /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：如果你在安装的时候出现了 “Permission denied” 的错误信息，这说明你的 <code>/usr/local/bin</code> 目录是不可写的，你需要使用超级用户来安装。运行 <code>sudo -i</code> , 然后运行上边的两个命令，然后 <code>exit</code> 退出。</p>
</blockquote>
<p>可选，你也可以在 shell 中使用命令行安装。</p>
<p>Compose 适用于 OS X 和 64位的Linux 。 如果你使用其他平台，你可以安装一个 Compose 的 Python 包来完成安装。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo pip install -U docker-compose</span><br></pre></td></tr></table></figure>

<p>到这里安装就结束了；Compose已经安装完成。你可以使用 <code>docker-compose --version</code> 来进行测试 。</p>
<h2 id="docker-compose附件安装"><a href="#docker-compose附件安装" class="headerlink" title="docker-compose附件安装"></a>docker-compose附件安装</h2><p>从github上下载docker-compose二进制文件安装</p>
<p>下载最新版的docker-compose文件</p>
<p>官方文档地址：Install Docker Compose | Docker Documentation <a href="https://docs.docker.com/compose/install/">https://docs.docker.com/compose/install/</a></p>
<p><a href="https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64">https://github.com/docker/compose/releases/download/v2.5.0/docker-compose-linux-x86_64</a></p>
<p>添加可执行权限</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> docker-compose-linux-x86_64 docker-compose</span><br><span class="line">docker-compose version</span><br></pre></td></tr></table></figure>

<h3 id="pip安装"><a href="#pip安装" class="headerlink" title="pip安装"></a>pip安装</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install docker-compose</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>docker内网安装</title>
    <url>/2024/04/08/docker/%E5%86%85%E7%BD%91%E5%AE%89%E8%A3%85/</url>
    <content><![CDATA[<h2 id="下载二进制文件"><a href="#下载二进制文件" class="headerlink" title="下载二进制文件"></a>下载二进制文件</h2><p><a href="https://download.docker.com/">https://download.docker.com/</a></p>


<h2 id="上传到服务器"><a href="#上传到服务器" class="headerlink" title="上传到服务器"></a>上传到服务器</h2><p>略</p>
<h2 id="剪切文件"><a href="#剪切文件" class="headerlink" title="剪切文件"></a>剪切文件</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> /home/weihu/docker-20.10.9.tgz /home/docker</span><br></pre></td></tr></table></figure>

<h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf docker-20.10.9.tgz</span><br></pre></td></tr></table></figure>

<h2 id="将二进制文件移到可执行文件目录下"><a href="#将二进制文件移到可执行文件目录下" class="headerlink" title="将二进制文件移到可执行文件目录下"></a>将二进制文件移到可执行文件目录下</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mv</span> docker/* /usr/bin/</span><br></pre></td></tr></table></figure>

<h2 id="配置docker-service"><a href="#配置docker-service" class="headerlink" title="配置docker.service"></a>配置docker.service</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=https://docs.docker.com</span><br><span class="line">After=network-online.target firewalld.service</span><br><span class="line">Wants=network-online.target</span><br><span class="line"> </span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/bin/dockerd</span><br><span class="line">ExecReload=/bin/kill -s HUP <span class="variable">$MAINPID</span></span><br><span class="line">LimitNOFILE=infinity</span><br><span class="line">LimitNPROC=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Delegate=<span class="built_in">yes</span></span><br><span class="line">KillMode=process</span><br><span class="line">Restart=on-failure</span><br><span class="line">StartLimitBurst=3</span><br><span class="line">StartLimitInterval=60s</span><br><span class="line"> </span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<h2 id="启动dockerd服务"><a href="#启动dockerd服务" class="headerlink" title="启动dockerd服务"></a>启动dockerd服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start docker.service</span><br><span class="line">docker info</span><br></pre></td></tr></table></figure>

<h3 id="将docker设置为开机自启动"><a href="#将docker设置为开机自启动" class="headerlink" title="将docker设置为开机自启动"></a>将docker设置为开机自启动</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure>

<h2 id="导出镜像或者容器"><a href="#导出镜像或者容器" class="headerlink" title="导出镜像或者容器"></a>导出镜像或者容器</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 容器 记得指定tag</span></span><br><span class="line">docker save -o rabbitmqmanagement.tar xxx </span><br><span class="line"><span class="comment"># 镜像</span></span><br><span class="line">docker <span class="built_in">export</span> -o SMSServer.tar CONTAINER ID</span><br><span class="line"></span><br><span class="line">docker load &lt; rabbitmqmanagement.tar </span><br><span class="line"></span><br><span class="line">docker import SMSServer.tar smsserver</span><br><span class="line"><span class="comment">#重命名</span></span><br><span class="line">docker tag [镜像<span class="built_in">id</span>] [新镜像名称]:[新镜像标签]</span><br></pre></td></tr></table></figure>

<h2 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h2><h3 id="Error-response-from-daemon-No-command-specified"><a href="#Error-response-from-daemon-No-command-specified" class="headerlink" title="Error response from daemon: No command specified."></a>Error response from daemon: No command specified.</h3><p>run 后缀添加 <code>/bin/ash</code> <code>/bin/bash</code> <code>/bin/sh</code></p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker开发2375及生成证书</title>
    <url>/2024/05/15/docker/%E5%BC%80%E6%94%BE2375%E5%8F%8A%E7%94%9F%E6%88%90%E8%AF%81%E4%B9%A6/</url>
    <content><![CDATA[<h2 id="证书生成"><a href="#证书生成" class="headerlink" title="证书生成"></a>证书生成</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim docker-tls.sh</span><br></pre></td></tr></table></figure>

<p>输入下面的脚本及修改脚本内容 </p>
<h3 id="证书生成脚本"><a href="#证书生成脚本" class="headerlink" title="证书生成脚本"></a>证书生成脚本</h3><p>需要修改 SERVER PASSWORD COUNTRY STATE CITY ORGANIZATION ORGANIZATIONAL_UNIT EMAIL</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#Docker tls script</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#settings</span></span><br><span class="line">SERVER=<span class="string">&quot;服务器ip记得写哇&quot;</span></span><br><span class="line">PASSWORD=<span class="string">&quot;1qaz2wsx3edc&quot;</span></span><br><span class="line">COUNTRY=<span class="string">&quot;CN&quot;</span></span><br><span class="line">STATE=<span class="string">&quot;sichuan&quot;</span></span><br><span class="line">CITY=<span class="string">&quot;chengdu&quot;</span></span><br><span class="line">ORGANIZATION=<span class="string">&quot;&quot;</span></span><br><span class="line">ORGANIZATIONAL_UNIT=<span class="string">&quot;Dev&quot;</span></span><br><span class="line">EMAIL=<span class="string">&quot;isguard@outlook.com&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">###start###</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;script start&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#gen ca.pem - aes256   </span></span><br><span class="line">openssl genrsa -aes256 -passout pass:<span class="variable">$PASSWORD</span> -out ca-key.pem 4096</span><br><span class="line"></span><br><span class="line">openssl req -new -x509 -passin <span class="string">&quot;pass:<span class="variable">$PASSWORD</span>&quot;</span> -days 365 -key ca-key.pem -sha256 -out ca.pem -subj <span class="string">&quot;/C=<span class="variable">$COUNTRY</span>/ST=<span class="variable">$STATE</span>/L=<span class="variable">$CITY</span>/O=<span class="variable">$ORGANIZATION</span>/OU=<span class="variable">$ORGANIZATIONAL_UNIT</span>/CN=<span class="variable">$SERVER</span>/emailAddress=<span class="variable">$EMAIL</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#gen server cert</span></span><br><span class="line">openssl genrsa -out server-key.pem 4096</span><br><span class="line"></span><br><span class="line">openssl req -subj <span class="string">&quot;/CN=<span class="variable">$SERVER</span>&quot;</span> -sha256 -new -key server-key.pem -out server.csr</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> subjectAltName = IP:<span class="variable">$SERVER</span>,IP:0.0.0.0 &gt;&gt; extfile.cnf</span><br><span class="line"><span class="built_in">echo</span> extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf</span><br><span class="line"></span><br><span class="line">openssl x509 -req -days 365 -sha256 -<span class="keyword">in</span> server.csr -CA ca.pem -CAkey ca-key.pem -passin <span class="string">&quot;pass:<span class="variable">$PASSWORD</span>&quot;</span> \-CAcreateserial -out server-cert.pem -extfile extfile.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment">#gen client cert</span></span><br><span class="line">openssl genrsa -out key.pem 4096</span><br><span class="line"></span><br><span class="line">openssl req -subj <span class="string">&#x27;/CN=client&#x27;</span> -new -key key.pem -out client.csr</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> extendedKeyUsage = clientAuth &gt;&gt; extfile.cnf</span><br><span class="line"></span><br><span class="line">openssl x509 -req -days 365 -sha256 -<span class="keyword">in</span> client.csr -CA ca.pem -CAkey ca-key.pem -passin <span class="string">&quot;pass:<span class="variable">$PASSWORD</span>&quot;</span> \-CAcreateserial -out cert.pem -extfile extfile.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment">#cert authorized</span></span><br><span class="line"><span class="built_in">chmod</span> -v 0400 ca-key.pem key.pem server-key.pem</span><br><span class="line"></span><br><span class="line"><span class="built_in">chmod</span> -v 0444 ca.pem server-cert.pem cert.pem</span><br><span class="line"></span><br><span class="line"><span class="comment">#del useless file</span></span><br><span class="line"><span class="built_in">rm</span> client.csr server.csr</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;script done&quot;</span></span><br><span class="line"><span class="comment">###end###</span></span><br></pre></td></tr></table></figure>

<h2 id="docker服务设置使用证书远程访问"><a href="#docker服务设置使用证书远程访问" class="headerlink" title="docker服务设置使用证书远程访问"></a>docker服务设置使用证书远程访问</h2><p>以下操作在docker服务器中进行</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">chmod</span> +x docker-tls.sh</span><br><span class="line">./docker-tls.sh</span><br></pre></td></tr></table></figure>



<h3 id="修改docker配置文件"><a href="#修改docker配置文件" class="headerlink" title="修改docker配置文件"></a>修改docker配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /usr/lib/systemd/system/docker.service</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 找到ExecStart前缀内容</span></span><br><span class="line"><span class="comment"># 修改内容并添加tls</span></span><br><span class="line">ExecStart=/usr/bin/dockerd  --tlsverify --tlscacert=/data/docker/ca.pem  --tlscert=/data/docker/server-cert.pem --tlskey=/data/docker/server-key.pem -H tcp://0.0.0.0:2375 -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class="line"><span class="comment"># 也可以修改端口</span></span><br><span class="line">ExecStart=/usr/bin/dockerd --tlsverify --tlscacert=/data/docker/ca.pem  --tlscert=/data/docker/server-cert.pem --tlskey=/data/docker/server-key.pem -H tcp://0.0.0.0:9999 -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class="line"></span><br><span class="line"><span class="comment"># --containerd=/run/containerd/containerd.sock可替换</span></span><br><span class="line">-H unix:///var/run/docker.sock</span><br></pre></td></tr></table></figure>

<h3 id="重启docker服务"><a href="#重启docker服务" class="headerlink" title="重启docker服务"></a>重启docker服务</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>

<h3 id="连接验证"><a href="#连接验证" class="headerlink" title="连接验证"></a>连接验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl 127.0.0.1:9999/info --cert /data/docker/cert.pem --key /data/docker/key.pem --cacert /data/docker/ca.pem</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker安装GitLab</title>
    <url>/2024/05/15/gitLab/Docker%E5%AE%89%E8%A3%85GitLab/</url>
    <content><![CDATA[<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">  --hostname gitlab.example.com \</span><br><span class="line">  --publish 443:443 --publish 80:80 --publish 22:22 \</span><br><span class="line">  --name gitlab \</span><br><span class="line">  --restart always \</span><br><span class="line">  --volume <span class="variable">$GITLAB_HOME</span>/config:/etc/gitlab:Z \</span><br><span class="line">  --volume <span class="variable">$GITLAB_HOME</span>/logs:/var/log/gitlab:Z \</span><br><span class="line">  --volume <span class="variable">$GITLAB_HOME</span>/data:/var/opt/gitlab:Z \</span><br><span class="line">  --shm-size 256m \</span><br><span class="line">  gitlab/gitlab-ce:latest</span><br></pre></td></tr></table></figure>

<h2 id="登录GitLab"><a href="#登录GitLab" class="headerlink" title="登录GitLab"></a>登录GitLab</h2><ol>
<li><p>获取GitLab的登录密码。</p>
<ul>
<li>Linux安装包方式：<code>sudo cat /etc/gitlab/initial_root_password</code></li>
<li>Docker Engine安装方式：<code>sudo docker exec -it gitlab grep &#39;Password:&#39; /etc/gitlab/initial_root_password</code></li>
</ul>
<p>回显信息类似如下所示，您可以在<code>Password</code>后获取GitLab的初始登录密码。</p>
<p><strong>重要</strong></p>
<p>出于安全原因，24小时后，该文件会被自动删除，建议您安装成功，首次登录之后，立即修改初始密码。</p>

</li>
<li><p>登录GitLab。</p>
<ul>
<li>Linux安装包方式：在浏览器的地址栏中，输入http:&#x2F;&#x2F;<em>ECS实例的公网IP</em>即可进入GitLab的登录界面。</li>
<li>Docker Engine安装方式：在浏览器的地址栏中，输入http:&#x2F;&#x2F;<em>ECS实例的公网IP:8080</em>即可进入GitLab的登录界面。</li>
</ul>
<p>首次登录使用用户名<code>root</code>，密码为步骤<a href="https://help.aliyun.com/zh/ecs/use-cases/deploy-and-use-gitlab#8c9d01b0880v4">1</a>获取的密码。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>gitLab</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gitLab</tag>
      </tags>
  </entry>
  <entry>
    <title>GitLab 授权 2099年</title>
    <url>/2024/05/15/gitLab/GitLab%E4%BC%81%E4%B8%9A%E7%89%88%E7%A0%B4%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="GitLab-授权-2099年"><a href="#GitLab-授权-2099年" class="headerlink" title="GitLab 授权 2099年"></a>GitLab 授权 2099年</h2><h3 id="创建文件license-rb"><a href="#创建文件license-rb" class="headerlink" title="创建文件license.rb"></a>创建文件license.rb</h3><p>license.rb文件 用来激活使用的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">require <span class="string">&quot;openssl&quot;</span></span><br><span class="line">require <span class="string">&quot;gitlab/license&quot;</span></span><br><span class="line"></span><br><span class="line">key_pair = OpenSSL::PKey::RSA.generate(2048)</span><br><span class="line">File.open(<span class="string">&quot;license_key&quot;</span>, <span class="string">&quot;w&quot;</span>) &#123; |f| f.write(key_pair.to_pem) &#125;</span><br><span class="line"></span><br><span class="line">public_key = key_pair.public_key</span><br><span class="line">File.open(<span class="string">&quot;license_key.pub&quot;</span>, <span class="string">&quot;w&quot;</span>) &#123; |f| f.write(public_key.to_pem) &#125;</span><br><span class="line"></span><br><span class="line">private_key = OpenSSL::PKey::RSA.new File.<span class="built_in">read</span>(<span class="string">&quot;license_key&quot;</span>)</span><br><span class="line">Gitlab::License.encryption_key = private_key</span><br><span class="line"></span><br><span class="line">license = Gitlab::License.new</span><br><span class="line">license.licensee = &#123;</span><br><span class="line">  <span class="string">&quot;Name&quot;</span> =&gt; <span class="string">&quot;Lemon&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Company&quot;</span> =&gt; <span class="string">&quot;Lemon&quot;</span>,</span><br><span class="line">  <span class="string">&quot;Email&quot;</span> =&gt; <span class="string">&quot;example@test.com&quot;</span>,</span><br><span class="line">&#125;</span><br><span class="line">license.starts_at = Date.new(2020, 1, 1) <span class="comment"># 开始时间</span></span><br><span class="line">license.expires_at = Date.new(2099, 1, 1) <span class="comment"># 结束时间</span></span><br><span class="line">license.notify_admins_at = Date.new(2049, 12, 1)</span><br><span class="line">license.notify_users_at = Date.new(2049, 12, 1)</span><br><span class="line">license.block_changes_at = Date.new(2099, 1, 1)</span><br><span class="line">license.restrictions = &#123;</span><br><span class="line">  active_user_count: 10000,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">puts <span class="string">&quot;License:&quot;</span></span><br><span class="line">puts license</span><br><span class="line"></span><br><span class="line">data = license.export</span><br><span class="line">puts <span class="string">&quot;Exported license:&quot;</span></span><br><span class="line">puts data</span><br><span class="line">File.open(<span class="string">&quot;GitLabBV.gitlab-license&quot;</span>, <span class="string">&quot;w&quot;</span>) &#123; |f| f.write(data) &#125;</span><br><span class="line"></span><br><span class="line">public_key = OpenSSL::PKey::RSA.new File.<span class="built_in">read</span>(<span class="string">&quot;license_key.pub&quot;</span>)</span><br><span class="line">Gitlab::License.encryption_key = public_key</span><br><span class="line"></span><br><span class="line">data = File.<span class="built_in">read</span>(<span class="string">&quot;GitLabBV.gitlab-license&quot;</span>)</span><br><span class="line"><span class="variable">$license</span> = Gitlab::License.import(data)</span><br><span class="line"></span><br><span class="line">puts <span class="string">&quot;Imported license:&quot;</span></span><br><span class="line">puts <span class="variable">$license</span></span><br><span class="line"></span><br><span class="line">unless <span class="variable">$license</span></span><br><span class="line">  raise <span class="string">&quot;The license is invalid.&quot;</span></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$license</span>.restricted?(:active_user_count)</span><br><span class="line">  active_user_count = 10000</span><br><span class="line">  <span class="keyword">if</span> active_user_count &gt; <span class="variable">$license</span>.restrictions[:active_user_count]</span><br><span class="line">    raise <span class="string">&quot;The active user count exceeds the allowed amount!&quot;</span></span><br><span class="line">  end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$license</span>.notify_admins?</span><br><span class="line">  puts <span class="string">&quot;The license is due to expire on #&#123;<span class="variable">$license</span>.expires_at&#125;.&quot;</span></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$license</span>.notify_users?</span><br><span class="line">  puts <span class="string">&quot;The license is due to expire on #&#123;<span class="variable">$license</span>.expires_at&#125;.&quot;</span></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">module Gitlab</span><br><span class="line">  class GitAccess</span><br><span class="line">    def check(cmd, changes = nil)</span><br><span class="line">      <span class="keyword">if</span> <span class="variable">$license</span>.block_changes?</span><br><span class="line">        <span class="built_in">return</span> build_status_object(<span class="literal">false</span>, <span class="string">&quot;License expired&quot;</span>)</span><br><span class="line">      end</span><br><span class="line">    end</span><br><span class="line">  end</span><br><span class="line">end</span><br><span class="line"></span><br><span class="line">puts <span class="string">&quot;This instance of GitLab Enterprise Edition is licensed to:&quot;</span></span><br><span class="line"><span class="variable">$license</span>.licensee.each <span class="keyword">do</span> |key, value|</span><br><span class="line">  puts <span class="string">&quot;#&#123;key&#125;: #&#123;value&#125;&quot;</span></span><br><span class="line">end</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="variable">$license</span>.expired?</span><br><span class="line">  puts <span class="string">&quot;The license expired on #&#123;<span class="variable">$license</span>.expires_at&#125;&quot;</span></span><br><span class="line">elsif <span class="variable">$license</span>.will_expire?</span><br><span class="line">  puts <span class="string">&quot;The license will expire on #&#123;<span class="variable">$license</span>.expires_at&#125;&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">  puts <span class="string">&quot;The license will never expire.&quot;</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<h3 id="创建Dockerfile"><a href="#创建Dockerfile" class="headerlink" title="创建Dockerfile"></a>创建Dockerfile</h3><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用最新的 GitLab 镜像作为基础镜像</span></span><br><span class="line"><span class="keyword">FROM</span> gitlab/gitlab-ee:latest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为我们的脚本创建一个目录</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> -p /usr/src/lemon</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 license.rb 文件复制到新创建的目录中 </span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> license.rb /usr/src/lemon</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 切换工作目录</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /usr/src/lemon</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Ruby 和必要的依赖</span></span><br><span class="line"><span class="comment">#RUN apt-get update &amp;&amp; apt-get install -y ruby ruby-dev</span></span><br><span class="line"><span class="comment">#RUN gem sources --add https://gems.ruby-china.com/ --remove https://rubygems.org/</span></span><br><span class="line"><span class="comment">#RUN gem install openssl --verbose</span></span><br><span class="line"><span class="comment">#RUN gem install gitlab-license --verbose</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行脚本并产生所需的文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> ruby license.rb</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 覆盖公钥</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">cp</span> license_key.pub /opt/gitlab/embedded/service/gitlab-rails/.license_encryption_key.pub</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改 license.rb 文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> sed -i <span class="string">&#x27;s/restricted_attr(:plan).presence || STARTER_PLAN/restricted_attr(:plan).presence || ULTIMATE_PLAN/g&#x27;</span> /opt/gitlab/embedded/service/gitlab-rails/ee/app/models/license.rb</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名 license 文件</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mv</span> GitLabBV.gitlab-license lemon.gitlab-license</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">rm</span> license.rb license_key license_key.pub</span></span><br><span class="line"><span class="comment"># 开启容器时的命令</span></span><br><span class="line"><span class="comment">#CMD [&quot;gitlab-ctl&quot;, &quot;reconfigure&quot;]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> 需要将license.rb Dockerfile两个文件放在一块即可</p>




<h3 id="构建镜像"><a href="#构建镜像" class="headerlink" title="构建镜像"></a>构建镜像</h3><p> 我以gitlab_license 为例 gitlab_license 你那边可以随意起名 起的名字是镜像的名字</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker build -t gitlab_license .</span><br></pre></td></tr></table></figure>

<p>等待构建完成后 docker images  就出现对应的你创建的镜像了</p>
<p>如果有docker-compose.yml   </p>
<p>可以按着你之前的 <code>docker-compose.yml </code>  </p>
<p>只需要将你yml的镜像改成你自己创建的镜像  <code>down up -d</code></p>
<p>我以简单的例子作为演示 ：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d -p 80:80  gitlab_license</span><br></pre></td></tr></table></figure>

<p>运行容器之后 </p>
<p>等待gitlab启动  </p>
<p>gitlab的访问地址是 你设备的 ip 加端口号  80 443 可以省略不写  </p>
<p>还有启动时间根据你的机器性能有关 </p>
<p>当出现这个页面 说明一切准备就绪</p>


<h3 id="修改默认密码"><a href="#修改默认密码" class="headerlink" title="修改默认密码"></a>修改默认密码</h3><p>第一次使用需要默认的初始密码</p>
<p>进入容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it (容器<span class="built_in">id</span> 或者容器名称) /bin/bash</span><br><span class="line">docker <span class="built_in">exec</span> -it 877c606c5e53 /bin/bash </span><br><span class="line"><span class="built_in">cat</span> /etc/gitlab/initial_root_password </span><br></pre></td></tr></table></figure>



<p>mmPPA7vlzRPgdEgQXu1LnWbok6OUNgiAgoZvhYnCgrw&#x3D;是默认的初始密码</p>
<p>我们可以在&#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb配置文件中设置自己的root密码，也可以用默认的密码登陆再修改自己想要的密码。</p>
<p><strong>要注意该文件24小时后自动删除</strong>。</p>
<h3 id="激活"><a href="#激活" class="headerlink" title="激活"></a>激活</h3><p>网页版是激活路径</p>


<p>在右侧下滑到 添加许可证</p>


<p>进入容器</p>
<p>当前目录是&#x2F;usr&#x2F;src&#x2F;lemon 如果不是 这个目录请转移到这个目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">docker exec -it (容器id 或者容器名称) /bin/bash</span><br><span class="line">docker exec -it 877c606c5e53 /bin/bash </span><br><span class="line">cat /usr/src/lemon/lemon.gitlab-license</span><br></pre></td></tr></table></figure>

<p>将当前的密钥添加到许可证密钥中即可</p>
]]></content>
      <categories>
        <category>gitLab</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>gitLab</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo01</title>
    <url>/2024/06/20/hexo/Hexo01/</url>
    <content><![CDATA[<h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line">hexo init blog</span><br><span class="line">cd blog</span><br><span class="line">npm install</span><br><span class="line">hexo server</span><br><span class="line">cd themes</span><br><span class="line">git clone https://github.com/theme-next/hexo-theme-next</span><br></pre></td></tr></table></figure>

<h2 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">hexo-theme-next</span></span><br></pre></td></tr></table></figure>

<h2 id="设置创建文件时创建目录"><a href="#设置创建文件时创建目录" class="headerlink" title="设置创建文件时创建目录"></a>设置创建文件时创建目录</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 写作</span></span><br><span class="line"><span class="attr">new_post_name:</span> <span class="string">:title.md</span> <span class="comment"># 新帖子的文件名</span></span><br><span class="line"><span class="attr">default_layout:</span> <span class="string">post</span></span><br><span class="line"><span class="attr">titlecase:</span> <span class="literal">false</span> <span class="comment"># 将标题转换为标题大小写</span></span><br><span class="line"><span class="attr">external_link:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># 在新标签页中打开外部链接</span></span><br><span class="line">  <span class="attr">field:</span> <span class="string">site</span> <span class="comment"># 适用于整个网站</span></span><br><span class="line">  <span class="attr">exclude:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line"><span class="attr">filename_case:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">render_drafts:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">post_asset_folder:</span> <span class="literal">true</span> <span class="comment"># 修改为true</span></span><br><span class="line"><span class="attr">relative_link:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<h2 id="设置目录和子目录"><a href="#设置目录和子目录" class="headerlink" title="设置目录和子目录"></a>设置目录和子目录</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page about</span><br><span class="line">hexo new page categories</span><br><span class="line">hexo new page archives</span><br></pre></td></tr></table></figure>

<h2 id="创建文章"><a href="#创建文章" class="headerlink" title="创建文章"></a>创建文章</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new [layout] &lt;title&gt;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Next 主题在 Hexo 中添加GA4</title>
    <url>/2024/06/29/hexo/Next%20%E4%B8%BB%E9%A2%98%E5%9C%A8%20Hexo%20%E4%B8%AD%E6%B7%BB%E5%8A%A0GA4/</url>
    <content><![CDATA[<p>确保您的 Next 主题是7。</p>
<h2 id="1：修改-config-yml"><a href="#1：修改-config-yml" class="headerlink" title="1：修改_config.yml"></a>1：修改_config.yml</h2><p>打开 <code>&#123;HEXO_ROOT&#125;\themes\next\_config.yml</code> 文件，找到以下代码：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">custom_file_path:</span></span><br><span class="line">  <span class="comment">#head: source/_data/head.swig</span></span><br></pre></td></tr></table></figure>

<p>删除 “#head: source&#x2F;_data&#x2F;head.swig “行中的 #。</p>
<h2 id="2：添加head-swig"><a href="#2：添加head-swig" class="headerlink" title="2：添加head.swig"></a>2：添加head.swig</h2><p>创建一个文件 <code>&#123;HEXO_ROOT&#125;\source\_data\head.swig</code> 并将 GA 代码放入该文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;</span><br><span class="line">&lt;script async src=&quot;https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line">  window.dataLayer = window.dataLayer || [];</span><br><span class="line">  function gtag()&#123;dataLayer.push(arguments);&#125;</span><br><span class="line">  gtag(&#x27;js&#x27;, new Date());</span><br><span class="line"></span><br><span class="line">  gtag(&#x27;config&#x27;, &#x27;G-XXXXXXXXXX&#x27;);</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<h2 id="3-获取代码"><a href="#3-获取代码" class="headerlink" title="3.获取代码"></a>3.获取代码</h2><ol>
<li>資料蒐集和修改 -&gt; 資料串流</li>
<li>點選你的網址</li>
<li>最下方的 查看代碼操作說明</li>
<li>選擇右邊的 手動安裝 就可以看到追蹤程式碼了</li>
</ol>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-8函数式编程1</title>
    <url>/2019/02/01/java/Java-8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B1/</url>
    <content><![CDATA[<blockquote>
<p>前言</p>
<p>Java 8 Lambdas，Richard Warburton 著（O’Reilly，2014）。版权所有， 978-1-449-37077-0</p>
<ul>
<li>如何编写出简单、干净、易读的代码 —— 尤其是对于集合的操作？</li>
<li>如何简单地使用并行计算提高性能？</li>
<li>如何准确地为问题建模，并且开发出更好的领域特定语言？</li>
<li>如何写出不易出错，并且更简单的并发代码？</li>
<li>如何测试和调试 Lambda 表达式？</li>
</ul>
<p>将<strong>Lambda 表达式</strong>加入 Java，并不只是为了提高开发人员的生产效率，业界也对这一特性有根本性的需求。</p>
</blockquote>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>在开始探索 Lambda 表达式之前，首先我们要知道它因何而生。</p>
<h2 id="为什么需要再次修改Java"><a href="#为什么需要再次修改Java" class="headerlink" title="为什么需要再次修改Java"></a>为什么需要再次修改Java</h2><p>Java还欠缺高效的并行操作</p>
<p>面向对象编程是对数据进行抽象，函数式编程是对行为进行抽象</p>
<h2 id="什么是函数式编程"><a href="#什么是函数式编程" class="headerlink" title="什么是函数式编程"></a>什么是函数式编程</h2><p>在思考问题时，使用不可变值和函数，函数对一个值进行处理，映射成另一个值</p>
<h1 id="Lambda表达式"><a href="#Lambda表达式" class="headerlink" title="Lambda表达式"></a>Lambda表达式</h1><p>Java 8 的最大变化是引入了 Lambda 表达式</p>
<h2 id="第一个Lambda表达式"><a href="#第一个Lambda表达式" class="headerlink" title="第一个Lambda表达式"></a>第一个Lambda表达式</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">button.addActionListener(new ActionListener() &#123; </span><br><span class="line">    public void actionPerformed(ActionEvent event) &#123; </span><br><span class="line">        System.out.println(&quot;button clicked&quot;); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">==</span><br><span class="line"></span><br><span class="line">button.addActionListener(event -&gt; System.out.println(&quot;button clicked&quot;));</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>和传入一个实现某接口的对象不同，我们传入了一段代码块——一个没有名字的函数。event 是参数名，和上面匿名内部类示例中的是同一个参数。-&gt; 将参数和 Lambda 表达式的主体分开，而主体是用户点击按钮时会运行的一些代码。</p>
<p>和使用匿名内部类的另一处不同在于声明 event 参数的方式。使用匿名内部类时需要显式地声明参数类型 ActionEvent  event，而在 Lambda 表达式中无需指定类型，程序依然可以编译。这是因为 javac 根据程序的上下文（addActionListener 方法的签名）在后台推断出了参数 event 的类型。这意味着如果参数类型不言而明，则无需显式指定。</p>
<blockquote>
<p>尽管与之前相比，Lambda 表达式中的参数需要的样板代码很少，但是 Java 8仍然是一种静态类型语言。为了增加可读性并迁就我们的习惯，声明参数时也可以包括类型信息，而且有时编译器不一定能根据上下文推断出参数的类型！</p>
</blockquote>
<h2 id="如何辨别Lambda表达式"><a href="#如何辨别Lambda表达式" class="headerlink" title="如何辨别Lambda表达式"></a>如何辨别Lambda表达式</h2><p>编写 Lambda 表达式的不同形式</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Runnable noArguments = () -&gt; System.out.println(&quot;Hello World&quot;); </span><br><span class="line"></span><br><span class="line">Lambda 表达式不包含参数，使用空括号 () 表示没有参数。</span><br><span class="line">该 Lambda 表达式实现了 Runnable 接口，该接口也只有一个 run 方法，没有参数，且返回类型为 void</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ActionListener oneArgument = event -&gt; System.out.println(&quot;button clicked&quot;);</span><br><span class="line"> </span><br><span class="line">Lambda 表达式包含且只包含一个参数，可省略参数的括号。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Runnable multiStatement = () -&gt; &#123;</span><br><span class="line">	System.out.print(&quot;Hello&quot;); </span><br><span class="line">	System.out.println(&quot; World&quot;); </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">Lambda 表达式的主体不仅可以是一个表达式，而且也可以是一段代码块，使用大括号（&#123;&#125;）将代码块括起来。</span><br><span class="line">该代码块和普通方法遵循的规则别无二致，可以用返回或抛出异常来退出。</span><br><span class="line">只有一行代码的 Lambda 表达式也可使用大括号，用以明确 Lambda表达式从何处开始、到哪里结束。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; add = (x, y) -&gt; x + y;</span><br><span class="line"></span><br><span class="line">Lambda 表达式也可以表示包含多个参数的方法。</span><br><span class="line">这时就有必要思考怎样去阅读该 Lambda 表达式。</span><br><span class="line">这行代码并不是将两个数字相加，而是创建了一个函数，用来计算两个数字相加的结果。</span><br><span class="line">变量 add 的类型是 BinaryOperator&lt;Long&gt;，它不是两个数字的和，而是将两个数字相加的那行代码。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BinaryOperator&lt;Long&gt; addExplicit = (Long x, Long y) -&gt; x + y; </span><br><span class="line"></span><br><span class="line">显式声明参数类型</span><br></pre></td></tr></table></figure>

<blockquote>
<p>目标类型是指 Lambda 表达式所在上下文环境的类型。<br>比如，将 Lambda 表达式赋值给一个局部变量，或传递给一个方法作为参数，局部变量或方法参数的类型就是 Lambda 表达式的目标类型。</p>
</blockquote>
<p>Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。</p>
<p>Java 中初始化数组时，数组的类型就是根据上下文推断出来的。另一个常见的例子是 null，只有将 null 赋值给一个变量，才能知道它的类型。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">final String[] array = &#123; &quot;hello&quot;, &quot;world&quot; &#125;;</span><br><span class="line">等号右边的代码并没有声明类型，系统根据上下文推断出类型信息</span><br></pre></td></tr></table></figure>

<h2 id="引用值，而不是变量"><a href="#引用值，而不是变量" class="headerlink" title="引用值，而不是变量"></a>引用值，而不是变量</h2><p>需要引用它所在方法里的变量。这时，需要将变量声明为 final</p>
<p>将变量声明为 final，意味着不能为其重复赋值。同时也意味着在使用 final 变量时，实际上是在使用赋给该变量的一个特定的值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">匿名内部类中使用 final 局部变量</span><br><span class="line"></span><br><span class="line">final String name = getUserName(); </span><br><span class="line">button.addActionListener(new ActionListener() &#123; </span><br><span class="line">    public void actionPerformed(ActionEvent event) &#123; </span><br><span class="line">        System.out.println(&quot;hi &quot; + name); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>Java 8 虽然放松了这一限制，可以引用非 final 变量，但是该变量在既成事实上必须是final。</p>
<p>虽然无需将变量声明为 final，但在 Lambda 表达式中，也无法用作非终态变量。</p>
<p>如果坚持用作非终态变量，编译器就会报错。</p>
<p>既成事实上的 final 是指只能给该变量赋值一次。</p>
<p>换句话说，Lambda 表达式引用的是值，而不是变量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Lambda 表达式中引用既成事实上的 final 变量</span><br><span class="line">name 就是一个既成事实上的 final 变量</span><br><span class="line"></span><br><span class="line">String name = getUserName(); </span><br><span class="line">button.addActionListener(event -&gt; System.out.println(&quot;hi &quot; + name));</span><br></pre></td></tr></table></figure>

<p>final 就像代码中的线路噪声，省去之后代码更易读。</p>
<p>当然，有些情况下，显式地使用 final代码更易懂。</p>
<p>是否使用这种既成事实上的 final 变量，完全取决于个人喜好。</p>
<p>如果你试图给该变量多次赋值，然后在 Lambda 表达式中引用它，编译器就会报错。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">未使用既成事实上的 final 变量，导致无法通过编译（ Lambda 表达式中引用的局部变量必须是 final 或既成事实上的 final 变量）</span><br><span class="line"></span><br><span class="line">String name = getUserName(); </span><br><span class="line">name = formatUserName(name); </span><br><span class="line">button.addActionListener(event -&gt; System.out.println(&quot;hi &quot; + name));</span><br><span class="line"></span><br><span class="line">显示出错信息：local variables referenced from a Lambda expression must be final or effectively final</span><br></pre></td></tr></table></figure>

<h2 id="函数接口"><a href="#函数接口" class="headerlink" title="函数接口"></a>函数接口</h2><blockquote>
<p>函数接口是只有一个抽象方法的接口，用作 Lambda 表达式的类型。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ActionListener 接口：接受 ActionEvent 类型的参数，返回空</span><br><span class="line"></span><br><span class="line">public interface ActionListener extends EventListener &#123; </span><br><span class="line">    public void actionPerformed(ActionEvent event); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ActionListener 只有一个抽象方法：actionPerformed，被用来表示行为：接受一个参数，返回空。</span><br><span class="line">记住，由于 actionPerformed 定义在一个接口里，因此 abstract 关键字不是必需的。</span><br><span class="line">该接口也继承自一个不具有任何方法的父接口：EventListener。</span><br></pre></td></tr></table></figure>

<p>这就是函数接口，接口中单一方法的命名并不重要，只要方法签名和 Lambda 表达式的类型匹配即可。</p>
<p>可在函数接口中为参数起一个有意义的名字，增加代码易读性，便于更透彻地理解参数的用途。</p>
<p>Java一些重要的函数接口</p>
<table>
<thead>
<tr>
<th align="center">接口</th>
<th align="center">参数</th>
<th align="center">返回类型</th>
<th align="center">示例</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Predicate<T></td>
<td align="center">T</td>
<td align="center">boolean</td>
<td align="center">用来判断真假</td>
</tr>
<tr>
<td align="center">Consumer<T></td>
<td align="center">T</td>
<td align="center">void</td>
<td align="center">输出一个值</td>
</tr>
<tr>
<td align="center">Function&lt;T,R&gt;</td>
<td align="center">T</td>
<td align="center">R</td>
<td align="center">获取Artist对象的名字</td>
</tr>
<tr>
<td align="center">Supplier<T></td>
<td align="center">None</td>
<td align="center">T</td>
<td align="center">工厂方法</td>
</tr>
<tr>
<td align="center">UnaryOperator<T></td>
<td align="center">T</td>
<td align="center">T</td>
<td align="center">逻辑非(!)</td>
</tr>
<tr>
<td align="center">BinaryOperator<T></td>
<td align="center">(T,T)</td>
<td align="center">T</td>
<td align="center">求两个数的乘积(*)</td>
</tr>
</tbody></table>
<h2 id="类型推断"><a href="#类型推断" class="headerlink" title="类型推断"></a>类型推断</h2><p>Lambda 表达式中的类型推断，实际上是 Java 7 就引入的目标类型推断的扩展。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Map&lt;String, Integer&gt; oldWordCounts = new HashMap&lt;String, Integer&gt;();</span><br><span class="line">Map&lt;String, Integer&gt; diamondWordCounts = new HashMap&lt;&gt;(); </span><br></pre></td></tr></table></figure>
<p>javac 根据 Lambda 表达式上下文信息就能推断出参数的正确类型。</p>
<p>程序依然要经过类型检查来保证运行的安全性，但不用再显式声明类型罢了。这就是所谓的类型推断。</p>
<p>用 Lambda 表达式检测一个 Integer 是否大于 5。这实际上是一个 Predicate——用来判断真假的函数接口</p>
<p><code>Predicate&lt;Integer&gt; atLeast5 = x -&gt; x &gt; 5;</code></p>
<p>Predicate 也是一个 Lambda 表达式，和前文中 ActionListener 不同的是，它还返回一个值。</p>
<p>表达式 x  &gt;  5 是 Lambda 表达式的主体。</p>
<p>这样的情况下，返回值就是Lambda 表达式主体的值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Predicate 接口的源码，接受一个对象，返回一个布尔值</span><br><span class="line"></span><br><span class="line">public interface Predicate&lt;T&gt; &#123; </span><br><span class="line">    boolean test(T t); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Predicate 只有一个泛型类型的参数，Integer 用于其中。</span><br><span class="line">Lambda表达式实现了 Predicate 接口，因此它的单一参数被推断为 Integer 类型。</span><br><span class="line">javac 还可检查Lambda 表达式的返回值是不是 boolean，这正是 Predicate 方法的返回类型。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">略显复杂的类型推断</span><br><span class="line"></span><br><span class="line">BinaryOperator&lt;Long&gt; addLongs = (x, y) -&gt; x + y;</span><br><span class="line"></span><br><span class="line">一个略显复杂的函数接口：BinaryOperator。</span><br><span class="line">该接口接受两个参数，返回一个值，参数和值的类型均相同。</span><br><span class="line">实例中所用的类型是 Long。</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">没有泛型，代码则通不过编译</span><br><span class="line"></span><br><span class="line">BinaryOperator add = (x, y) -&gt; x + y;</span><br><span class="line"></span><br><span class="line">编译器给出的报错信息如下：</span><br><span class="line">Operator &#x27;&amp; #x002B;&#x27; cannot be applied to java.lang.Object, java.lang.Object.</span><br></pre></td></tr></table></figure>

<p>BinaryOperator 毕竟是一个具有泛型参数的函数接口，该类型既是参数 x 和 y 的类型，也是返回值的类型。<br>上面的例子中并没有给出变量add 的任何泛型信息，给出的正是原始类型的定义。<br>因此，编译器认为参数和返回值都是java.lang.Object 实例。</p>
<h2 id="要点回顾"><a href="#要点回顾" class="headerlink" title="要点回顾"></a>要点回顾</h2><ul>
<li>Lambda 表达式是一个匿名方法，将行为像数据一样进行传递。</li>
<li>Lambda 表达式的常见结构：BinaryOperator<Integer> add &#x3D; (x, y) → x + y。</li>
<li>函数接口指仅具有单个抽象方法的接口，用来表示 Lambda 表达式的类型。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java-8函数式编程2</title>
    <url>/2019/02/03/java/Java-8%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B2/</url>
    <content><![CDATA[<blockquote>
<p>前言</p>
<p>Java 8 Lambdas，Richard Warburton 著（O’Reilly，2014）。版权所有， 978-1-449-37077-0</p>
<ul>
<li>如何编写出简单、干净、易读的代码 —— 尤其是对于集合的操作？</li>
<li>如何简单地使用并行计算提高性能？</li>
<li>如何准确地为问题建模，并且开发出更好的领域特定语言？</li>
<li>如何写出不易出错，并且更简单的并发代码？</li>
<li>如何测试和调试 Lambda 表达式？</li>
</ul>
<p>将<strong>Lambda 表达式</strong>加入 Java，并不只是为了提高开发人员的生产效率，业界也对这一特性有根本性的需求。</p>
</blockquote>
<h1 id="流"><a href="#流" class="headerlink" title="流"></a>流</h1><p>Java 8 中新增的特性旨在帮助程序员写出更好的代码，其中对核心类库的改进是很关键的一部分。</p>
<p>对核心类库的改进主要包括集合类的 API 和新引入的流（Stream）。</p>
<p>流使程序员得以站在更高的抽象层次上对集合进行操作。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><ul>
<li>Artist : 创作音乐的个人或团队<ul>
<li>name ：艺术家的名字</li>
<li>members ：乐队成员</li>
<li>origin ：乐队来自哪里</li>
<li>Track : 专辑中的一支曲目<ul>
<li>name : 曲目名称</li>
</ul>
</li>
<li>Album ： 专辑，若干曲目组成<ul>
<li>name ：专辑名</li>
<li>tracks ： 专辑上所有曲目的列表</li>
<li>musicians ：参与创作本专辑的艺术家列表</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="从外部迭代到内部迭代"><a href="#从外部迭代到内部迭代" class="headerlink" title="从外部迭代到内部迭代"></a>从外部迭代到内部迭代</h2><p>Java 程序员在使用集合类时，一个通用的模式是在集合上进行迭代，然后处理返回的每一个元素。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使用 for 循环计算来自伦敦的艺术家人数</span><br><span class="line"></span><br><span class="line">int count = 0; </span><br><span class="line">for (Artist artist : allArtists) &#123; </span><br><span class="line">    if (artist.isFrom(&quot;London&quot;)) &#123; </span><br><span class="line">        count++; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">尽管这样的操作可行，但存在几个问题</span><br><span class="line">1.每次迭代集合类时，都需要写很多样板代码。</span><br><span class="line">2.将for 循环改造成并行方式运行也很麻烦，需要修改每个 for 循环才能实现。</span><br><span class="line">3.上述代码无法流畅传达程序员的意图。</span><br><span class="line">	for 循环的样板代码模糊了代码的本意，程序员必须阅读整个循环体才能理解。</span><br><span class="line">	若是单一的 for 循环，倒也问题不大，但面对一个满是循环（尤其是嵌套循环）的庞大代码库时，负担就重了。</span><br></pre></td></tr></table></figure>

<p>for 循环其实是一个封装了迭代的语法糖，看看它的工作原理。</p>
<p>首先调用 iterator 方法，产生一个新的 Iterator 对象，进而控制整个迭代过程，这就是<strong>外部迭代</strong>。</p>
<p>迭代过程通过显式调用 Iterator 对象的 hasNext 和 next 方法完成迭代。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使用迭代器计算来自伦敦的艺术家人数</span><br><span class="line"></span><br><span class="line">int count = 0; </span><br><span class="line">Iterator&lt;Artist&gt; iterator = allArtists.iterator(); </span><br><span class="line">while(iterator.hasNext()) &#123; </span><br><span class="line">    Artist artist = iterator.next(); </span><br><span class="line">    if (artist.isFrom(&quot;London&quot;)) &#123; </span><br><span class="line">        count++; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>内部迭代</strong></p>
<p>首先要注意 stream() 方法的调用，它和调用 iterator() 的作用一样。</p>
<p>该方法不是返回一个控制迭代的 Iterator 对象，而是返回内部迭代中的相应接口：Stream。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">使用内部迭代计算来自伦敦的艺术家人数</span><br><span class="line"></span><br><span class="line">long count = allArtists.stream()</span><br><span class="line">			.filter(artist -&gt; artist.isFrom(&quot;London&quot;))</span><br><span class="line">			.count();</span><br><span class="line"></span><br><span class="line">被分解为两步更简单的操作：</span><br><span class="line">	找出所有来自伦敦的艺术家</span><br><span class="line">	计算他们的人数</span><br></pre></td></tr></table></figure>

<p>每种操作都对应 Stream 接口的一个方法。<br>为了找出来自伦敦的艺术家，需要对 Stream 对象进行过滤：filter。过滤在这里是指“只保留通过某项测试的对象”。<br>测试由一个函数完成，根据艺术家是否来自伦敦，该函数返回 true 或者 false。<br>由于 Stream API 的函数式编程风格，我们并没有改变集合的内容，而是描述出 Stream 里的内容。<br>count() 方法计算给定 Stream 里包含多少个对象。</p>
<blockquote>
<p>Stream 是用函数式编程方式在集合类上进行复杂操作的工具。</p>
</blockquote>
<h2 id="实现机制"><a href="#实现机制" class="headerlink" title="实现机制"></a>实现机制</h2><p>整个过程被分解为两种更简单的操作：过滤和计数，看似有化简为繁之嫌<br>但 迭代只有一个for循环 ，两种操作是否以为着需要两次循环？ 答案并不是，只需要对列表迭代一次。</p>
<p>通常，在Java中调用一个方法，计算机会随机执行操作：比如，System.out.println(“Hello World”);会在终端上输出一条信息。<br>Streatm里的一些方法却略有不同，他们虽是普通Java方法，但返回的Stream对象却不是一个新集合，而是<strong>创建新集合的配方</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">只过滤，不计数</span><br><span class="line"></span><br><span class="line">allArtists.stream().filter(artist -&gt; artist.isFrom(&quot;London&quot;));</span><br></pre></td></tr></table></figure>

<p>这行代码并未做什么实际性的工作，filter 只刻画出了 Stream，但没有产生新的集合。<br>像filter 这样只描述 Stream，最终不产生新集合的方法叫<strong>作惰性求值方法</strong>；<br>而像 count 这样最终会从 Stream 产生值的方法叫作<strong>及早求值方法</strong>。</p>
<p>在过滤器中加入一条 println 语句，来输出艺术家的名字，就能轻而易举地看出其中的不同。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">由于使用了惰性求值，没有输出艺术家的名字</span><br><span class="line"></span><br><span class="line">allArtists.stream() </span><br><span class="line">          .filter(artist -&gt; &#123; </span><br><span class="line">              System.out.println(artist.getName()); </span><br><span class="line">              return artist.isFrom(&quot;London&quot;); </span><br><span class="line">           &#125;);</span><br><span class="line"></span><br><span class="line">运行这段代码，程序不会输出任何信息！</span><br></pre></td></tr></table></figure>

<p>如果将同样的输出语句加入一个拥有终止操作的流,艺术家的名字就会被输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">long count = allArtists.stream() </span><br><span class="line">                       .filter(artist -&gt; &#123; </span><br><span class="line">                           System.out.println(artist.getName()); </span><br><span class="line">                           return artist.isFrom(&quot;London&quot;); </span><br><span class="line">                       &#125;) </span><br><span class="line">                       .count();</span><br></pre></td></tr></table></figure>

<p>判断一个操作是惰性求值还是及早求值很简单：只需看它的返回值。<br>如果返回值是 Stream，那么是惰性求值；如果返回值是另一个值或为空，那么就是及早求值。<br>使用这些操作的理想方式就是形成一个惰性求值的链，最后用一个及早求值的操作返回想要的结果，这正是它的合理之处。</p>
<h2 id="常用的流操作"><a href="#常用的流操作" class="headerlink" title="常用的流操作"></a>常用的流操作</h2><p>为了更好地理解 Stream API，掌握一些常用的 Stream 操作十分必要。除此处讲述的几种重要操作之外，该 API 的 Javadoc 中还有更多信息。</p>
<h3 id="collect-toList"><a href="#collect-toList" class="headerlink" title="collect(toList())"></a>collect(toList())</h3><blockquote>
<p>collect(toList()) 方法由 Stream 里的值生成一个列表，是一个及早求值操作。</p>
</blockquote>
<p>Stream 的 of 方法使用一组初始值生成新的 Stream。<br>事实上，collect 的用法不仅限于此，它是一个非常通用的强大结构。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; collected = Stream.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)</span><br><span class="line">                               .collect(Collectors.toList());</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">这段程序展示了如何使用 collect(toList()) 方法从 Stream 中生成一个列表。</span><br><span class="line">由于很多 Stream 操作都是惰性求值，因此调用 Stream 上一系列方法之后，还需要最后再调用一个类似 collect 的及早求值方法。</span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础1</title>
    <url>/2019/01/24/java/Java%E5%9F%BA%E7%A1%801/</url>
    <content><![CDATA[<h1 id="Java的加载与执行"><a href="#Java的加载与执行" class="headerlink" title="Java的加载与执行"></a>Java的加载与执行</h1><img data-src="/2019/01/24/java/Java%E5%9F%BA%E7%A1%801/1.png" class="">


<h1 id="基本数据类型"><a href="#基本数据类型" class="headerlink" title="基本数据类型"></a>基本数据类型</h1><ul>
<li>btye：Java中最小的数据类型，在内存中占8位(bit)，即1个字节，取值范围-128~127，默认值0</li>
<li>short：短整型，在内存中占16位，即2个字节，取值范围-32768~32717，默认值0</li>
<li>int：整型，用于存储整数，在内在中占32位，即4个字节，取值范围-2147483648~2147483647，默认值0</li>
<li>long：长整型，在内存中占64位，即8个字节-2^63~2^63-1，默认值0L</li>
<li>float：浮点型，在内存中占32位，即4个字节，用于存储带小数点的数字（与double的区别在于float类型有效小数点只有6~7位），默认值0</li>
<li>double：双精度浮点型，用于存储带有小数点的数字，在内存中占64位，即8个字节，默认值0</li>
<li>char：字符型，用于存储单个字符，占16位，即2个字节，取值范围0~65535，默认值为空</li>
<li>boolean：布尔类型，占1个字节，用于判断真或假（仅有两个值，即true、false），默认值false</li>
</ul>
<h1 id="转义符"><a href="#转义符" class="headerlink" title="转义符"></a>转义符</h1><ul>
<li>\n：表示换一行</li>
<li>\t：表示制表符</li>
<li>\\：表示输出一个\</li>
<li>&quot;:表示输出一个”</li>
<li>&#39;:表示输出一个’</li>
<li>\u0000：表示unicode转义序列符，输出一个空格</li>
</ul>
<h1 id="变量的内存分析"><a href="#变量的内存分析" class="headerlink" title="变量的内存分析"></a>变量的内存分析</h1><ol>
<li>当运行程序时，在内存中JVM会自动分配空间</li>
<li>内存中包含：<ul>
<li>栈：存放方法及方法中的局部变量</li>
<li>堆：存方法对象</li>
<li>方法区：代码片段、常量池（常量池中存放的时字符串的值）、静态属性</li>
</ul>
</li>
<li>基本数据类型内存中存放真正的值、引用数据类型内存中存放地址</li>
</ol>
<h1 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h1><ol>
<li>算术运算符：+、-、*、&#x2F;、%、++、–</li>
<li>链接运算符：+</li>
<li>赋值运算符：&#x3D;、+&#x3D;、-&#x3D;、*&#x3D;、&#x2F;&#x3D;、%&#x3D;</li>
<li>关系运算符：&gt;、&lt;、&gt;&#x3D;、&lt;&#x3D;、&#x3D;&#x3D;</li>
<li>逻辑运算符：&amp;、|、^、！、&amp;&amp;、||</li>
<li>三目运算符：条件 ？代码1 ：代码2</li>
</ol>
<h1 id="控制台输入"><a href="#控制台输入" class="headerlink" title="控制台输入"></a>控制台输入</h1><p><code>Scanner input = new Scanner(System.in);</code></p>
<h1 id="IF"><a href="#IF" class="headerlink" title="IF"></a>IF</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if(代码1）&#123;</span><br><span class="line"></span><br><span class="line">&#125;else&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">或</span><br><span class="line">if(代码1）&#123;</span><br><span class="line"></span><br><span class="line">&#125;else if(代码2)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">或</span><br><span class="line">if(代码1）&#123;</span><br><span class="line"></span><br><span class="line">&#125;else if(代码2)&#123;</span><br><span class="line"></span><br><span class="line">&#125;else&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在Java中，字符串比较，使用&#x3D;&#x3D;比较的时地址是否一致，equals()比较内容</p>
<h1 id="switch-case"><a href="#switch-case" class="headerlink" title="switch case"></a>switch case</h1><p>表达式 &#x3D; byte、short、int、char、String（JDK7.0）、枚举</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">switsh(表达式)&#123;</span><br><span class="line">case 常量1：	break；</span><br><span class="line">case 常量2： break；</span><br><span class="line">default：</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="循环"><a href="#循环" class="headerlink" title="循环"></a>循环</h1><h2 id="for"><a href="#for" class="headerlink" title="for"></a>for</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for(int i=0;i&lt;=100;i++)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="while"><a href="#while" class="headerlink" title="while"></a>while</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while(条件)&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="do-while"><a href="#do-while" class="headerlink" title="do while"></a>do while</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">do&#123;</span><br><span class="line"></span><br><span class="line">&#125;while(条件)</span><br></pre></td></tr></table></figure>

<h2 id="跳过及中断"><a href="#跳过及中断" class="headerlink" title="跳过及中断"></a>跳过及中断</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">break；中断</span><br><span class="line">continue；跳过</span><br></pre></td></tr></table></figure>
<h1 id="方法的内存分析"><a href="#方法的内存分析" class="headerlink" title="方法的内存分析"></a>方法的内存分析</h1><ul>
<li>当执行该方法时，则方法进栈（压栈）</li>
<li>当方法执行完毕，则该方法出栈（弹栈），局部变量也随之释放</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础2</title>
    <url>/2019/01/26/java/Java%E5%9F%BA%E7%A1%802/</url>
    <content><![CDATA[<h1 id="Object"><a href="#Object" class="headerlink" title="Object"></a>Object</h1><p>Object类是Java中所有类的根父类，Java中的类要么直接继承Object，要么间接继承Object类</p>
<p>Java中类的继承是可传递的，Object类中定义的方法，所有的类都能继承到</p>
<table>
<thead>
<tr>
<th align="center">Object</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">clone</td>
<td align="center">对象克隆</td>
</tr>
<tr>
<td align="center">equals</td>
<td align="center">用于判断两个对象的内容是否一样</td>
</tr>
<tr>
<td align="center">finalize</td>
<td align="center">当对象被垃圾回收器回收时，会执行对象的finalize()方法，但是垃圾回收器在什么时候回收这个对象不确定，即这个方法的执行时间不确定，一般不用</td>
</tr>
<tr>
<td align="center">getClass</td>
<td align="center">返回对象的运行时类对象，可以简单的理解为返回对象的类的字节码文件</td>
</tr>
<tr>
<td align="center">hashCode</td>
<td align="center">返回对象的哈希码</td>
</tr>
<tr>
<td align="center">notify</td>
<td align="center">在线程中用于唤醒等待中的线程</td>
</tr>
<tr>
<td align="center">notifyAll</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">toString</td>
<td align="center">把对象转换为字符串</td>
</tr>
<tr>
<td align="center">wait</td>
<td align="center">在多线程中，让线程等待</td>
</tr>
</tbody></table>
<h1 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h1><p>Collection存储数据时是单个存储的，只能存储引用类型数据</p>
<p><code>add(),remove(),contains(),iterator()</code></p>
<ul>
<li>list集合<ul>
<li>有序，可重复</li>
<li>为每个元素指定了一个索引值</li>
<li>add(index,0),remove(index),get(index),sort(Comparator)</li>
<li>ArrayList</li>
<li>Vector<ul>
<li>底层是数组，访问快，添加&#x2F;删除慢</li>
<li>初始化容量：10</li>
<li>扩容：ArrayList是1.5倍，Vector是2倍</li>
<li>Vector是线程安全的，ArrayList不是线程安全的</li>
</ul>
</li>
<li>LinkedList<ul>
<li>底层是双向链表，添加&#x2F;删除效率高，访问慢</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>ArrayList应用于以查询访问为主，很少进行添加&#x2F;删除操作<br>LinkedList应用于频繁的进行添加&#x2F;删除操作的情况</p>
<ul>
<li>Set集合<ul>
<li>无序，不可重复</li>
<li>HashSet<ul>
<li>底层是HashMap</li>
<li>HashSet就是HashMap键的集合</li>
</ul>
</li>
<li>TreeSet<ul>
<li>底层是TreeMap</li>
<li>TreeSet就是TreeMap键的集合</li>
<li>TreeSet实现了SortedSet接口，可以对元素自然排序，要求元素必须是可比较的<ul>
<li>创建TreeSet时指定Comparator比较器</li>
<li>如果没有指定Comparator比较器，元素类需要实现Comparable接口</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>List集合与HashSet集合中判断是否同一个元素，需要调用对象的equals()方法，元素的类需要重写equals()方法</p>
<p>TreeSet集合判断是否同一个元素，根据Comparator&#x2F;Comparable的比较结果是否为0判断，如果比较结果为0就认为是同一个元素</p>
<img data-src="/2019/01/26/java/Java%E5%9F%BA%E7%A1%802/1.png" class="">

<h2 id="HashSet"><a href="#HashSet" class="headerlink" title="HashSet"></a>HashSet</h2><ul>
<li>HashSet底层是HashMap<ul>
<li>向HashSet中添加元素，实际上是把元素作为键添加到底层的HashMap中</li>
<li>HashSet就是HashMap键的集合</li>
</ul>
</li>
</ul>
<h2 id="TreeSet"><a href="#TreeSet" class="headerlink" title="TreeSet"></a>TreeSet</h2><ul>
<li>TreeSet实现了SortedSet接口，可以对元素自然排序，要求集合中的元素必须是可比较的<ul>
<li>在创建TreeSet时，可以指定Comparator比较器</li>
<li>没有指定Comparator比较器，要求元素的类实现Comparable接口</li>
</ul>
</li>
<li>TreeSet底层是TreeMap<ul>
<li>向TreeSett中添加元素，实际上是把元素作为键添加到底层的TreeMap中</li>
<li>TreeSet就是TreeMap键的集合</li>
</ul>
</li>
</ul>
<h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p>Map是按&lt;键,值&gt;对的形式存储数据的</p>
<img data-src="/2019/01/26/java/Java%E5%9F%BA%E7%A1%802/2.png" class="">

<table>
<thead>
<tr>
<th align="center">Map</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">clear</td>
<td align="center">清除所有的&lt;键,值&gt;对</td>
</tr>
<tr>
<td align="center">containsKey</td>
<td align="center">判断是否包含指定的键</td>
</tr>
<tr>
<td align="center">containsValue</td>
<td align="center">判断是否包含指定的值</td>
</tr>
<tr>
<td align="center">entrySet</td>
<td align="center">返回Entry的集合，一个&lt;键,值&gt;对就是一个entry</td>
</tr>
<tr>
<td align="center">equals</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">get</td>
<td align="center">返回Key对应的值</td>
</tr>
<tr>
<td align="center">isEmpty</td>
<td align="center">判断是否为空</td>
</tr>
<tr>
<td align="center">ketSet</td>
<td align="center">返回键的集合</td>
</tr>
<tr>
<td align="center">put</td>
<td align="center">向Map中添加&lt;键,值&gt;对，如果这个键Key已存在，使用value替换原来的值，Map中的键是不重复的</td>
</tr>
<tr>
<td align="center">putAll</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">remove</td>
<td align="center">只要key匹配就删除对应的&lt;键,值&gt;对</td>
</tr>
<tr>
<td align="center">remove</td>
<td align="center">要求&lt;键,值&gt;都匹配才会删除</td>
</tr>
<tr>
<td align="center">replace</td>
<td align="center">替换</td>
</tr>
<tr>
<td align="center">size</td>
<td align="center">返回&lt;键,值&gt;对的数量</td>
</tr>
<tr>
<td align="center">values</td>
<td align="center">返回值的集合</td>
</tr>
</tbody></table>
<img data-src="/2019/01/26/java/Java%E5%9F%BA%E7%A1%802/3.png" class="">

<h2 id="HashTable"><a href="#HashTable" class="headerlink" title="HashTable"></a>HashTable</h2><ul>
<li>底层都是哈希表（散列表），但是HashTable事线程安全的，HashMap不是线程安全的</li>
<li>HashMap的父类是AbstractMap,HashTable的父类是Dictionary</li>
<li>HashMap默认的初始化容量：16，HashTable默认的初始化容量：11</li>
<li>加载因子：0.75，当&lt;键,值&gt;对的数量大于数组的容量（哈希桶的容量）*加载因子时，数组要扩容</li>
<li>HashMap扩容默认：2倍大小，HashTable扩容默认：2倍+1</li>
<li>HashMap的键与值都可以为null，HashTable的键与值都不可以为null</li>
<li>HashMap在创建时，可以指定一个初始化容量，系统会调整为2的幂次方，为了快速计算出数组的下标</li>
<li>HashTable也可以指定初始化容量，系统不调整</li>
</ul>
<h2 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h2><ul>
<li>继承了HashTable</li>
<li>他的键与值都是String字符串</li>
<li>常用于设置读取系统属性值</li>
</ul>
<h2 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h2><ul>
<li>TreeMap实现了SortedMap，可以根据键自然排序，排序原理是二叉树原理</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java基础3</title>
    <url>/2019/01/28/java/Java%E5%9F%BA%E7%A1%803/</url>
    <content><![CDATA[<h1 id="IO流"><a href="#IO流" class="headerlink" title="IO流"></a>IO流</h1><p>流是有起点和终点的有序字节序列</p>
<p>流的分类</p>
<ul>
<li>输入流&#x2F;输出流：是当前程序为参照点，程序从外面读取数据这是输入流，把程序的数据保存到外面是输出流</li>
<li>字节流&#x2F;字符流：如果是以字节为单位处理流中的数据就是字节流，如果是以字符为单位处理流中的数据就是字符流</li>
<li>节点流&#x2F;处理流：如果直接从设备（数据源）上读写数据就是节点流，处理流是对节点流的包装</li>
</ul>
<p>在程序中从文件里读写数据需要使用IO流.Java定义了相关的流类，在java.io包中，如果这个类是以Stream单词结尾就是流类，如果是以Reader结尾就是字符输入流，以Writer单词结尾就是字符输出流。</p>
<ul>
<li>FileInputStream&#x2F;FileOutputStream<ul>
<li>以节为单位读写文件内容</li>
</ul>
</li>
<li>FileReader&#x2F;FileWriter<ul>
<li>FileReader&#x2F;FileWriter只能读写与当前环境编码兼容的文本文件</li>
</ul>
</li>
<li>InputStreamReader&#x2F;OutputStreamwriter<ul>
<li>如果文本文件与当前环境编码不兼容，使用InputStreamReader&#x2F;OutputStreamwriter转换流读写</li>
</ul>
</li>
<li>BufferedReader&#x2F;Bufferedwriter<ul>
<li>字符缓冲流BufferedReader&#x2F;Bufferedwriter也是一种处理流，包装流</li>
</ul>
</li>
<li>ObjectinputStream&#x2F;ObjectOutputStream<ul>
<li>对象序列化：把对象转换为01二进制序列就是对象序列化</li>
<li>对象反序列化：把一组01二进制序列转换为对象</li>
<li>注意：对象序列化&#x2F;反序列化前提是对象的类要实现Serializable接口，该接口是一个标志性接口，没有任何方法</li>
</ul>
</li>
<li>PrintStream&#x2F;PrintWriter</li>
<li>File类<ul>
<li>读取文件内容使用IO流，操作文件&#x2F;文件来使用File类，如创建&#x2F;遍历&#x2F;删除文件来，查看文件的相关属性等操作</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">File</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">getAbsolutePath</td>
<td align="center">返回绝对路径（从根目录开始的路径）</td>
</tr>
<tr>
<td align="center">getPath</td>
<td align="center">返回路径</td>
</tr>
<tr>
<td align="center">getParent</td>
<td align="center">返回上一级文件夹</td>
</tr>
<tr>
<td align="center">getName</td>
<td align="center">对象名</td>
</tr>
<tr>
<td align="center">length</td>
<td align="center">文件大小</td>
</tr>
<tr>
<td align="center">exists</td>
<td align="center">是否存在</td>
</tr>
<tr>
<td align="center">isFile</td>
<td align="center">是否为文件</td>
</tr>
<tr>
<td align="center">isAbsolute</td>
<td align="center">是否绝对路径</td>
</tr>
<tr>
<td align="center">lastModified</td>
<td align="center">最后一次修改的时间</td>
</tr>
</tbody></table>
<h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><p>进程：进程就是操作系统运行的一个程序。</p>
<p>线程：线程就是进程的一个执行单元，一个进程至少有一个线程，如果进程有多个线程，则它就是多线程应用程序。每个线程都有独立的栈空间。</p>
<p>主线程：JVM启动主线程，主线程运行main方法</p>
<p>用户线程：开启的新的线程，也称子线程。</p>
<p>守护线程：守护线程是为其他线程提供服务的线程，不能独立运行，当JVM中只有守护线程时，JVM会退出。（垃圾回收器就是一个守护线程）</p>
<h2 id="创建线程"><a href="#创建线程" class="headerlink" title="创建线程"></a>创建线程</h2><ul>
<li><p>继承Thread</p>
</li>
<li><p>实现Runnable接口</p>
</li>
<li><p>实现Callable接口</p>
</li>
</ul>
<h2 id="线程常用操作"><a href="#线程常用操作" class="headerlink" title="线程常用操作"></a>线程常用操作</h2><table>
<thead>
<tr>
<th align="center">Thread</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">activeCount</td>
<td align="center">当前活动线程的数量</td>
</tr>
<tr>
<td align="center">currentThread</td>
<td align="center">返回当前线程</td>
</tr>
<tr>
<td align="center">getContextClassLoader</td>
<td align="center">线程的上下文类加载器</td>
</tr>
<tr>
<td align="center">getId</td>
<td align="center">返回线程的ID，每个线程都有唯一的id</td>
</tr>
<tr>
<td align="center">getName</td>
<td align="center">返回线程名称</td>
</tr>
<tr>
<td align="center">getPriority</td>
<td align="center">返回线程优先级</td>
</tr>
<tr>
<td align="center">getState</td>
<td align="center">返回线程状态</td>
</tr>
<tr>
<td align="center">interrupt</td>
<td align="center">中断线程</td>
</tr>
<tr>
<td align="center">interrupted</td>
<td align="center">测试线程是否被中断</td>
</tr>
<tr>
<td align="center">isAlive</td>
<td align="center">测试线程是否结束</td>
</tr>
<tr>
<td align="center">isDaemon</td>
<td align="center">是否守护线程</td>
</tr>
<tr>
<td align="center">isInterrupted</td>
<td align="center">测试线程是否被中断</td>
</tr>
<tr>
<td align="center">join</td>
<td align="center">合并线程（加入）</td>
</tr>
<tr>
<td align="center">run</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">setDaemon</td>
<td align="center">设置线程为守护线程</td>
</tr>
<tr>
<td align="center">setName</td>
<td align="center">设置线程名称</td>
</tr>
<tr>
<td align="center">setPriority</td>
<td align="center">设置优先级</td>
</tr>
<tr>
<td align="center">sleep</td>
<td align="center">线程休眠</td>
</tr>
<tr>
<td align="center">start</td>
<td align="center">开启线程</td>
</tr>
<tr>
<td align="center">stop</td>
<td align="center">终止线程</td>
</tr>
<tr>
<td align="center">toString</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">yield</td>
<td align="center">线程让步</td>
</tr>
</tbody></table>
<h2 id="线程生命周期"><a href="#线程生命周期" class="headerlink" title="线程生命周期"></a>线程生命周期</h2><img data-src="/2019/01/28/java/Java%E5%9F%BA%E7%A1%803/1.png" class="">

<p>线程优先级</p>
<ul>
<li>每个线程都有一个优先级，取值范围：1~10</li>
<li>所有线程默认的优先级为：5</li>
<li>优先级越高，获得CPU执行权的记录越大</li>
</ul>
<p>线程休眠（Thread.sleep(2000)）</p>
<ul>
<li>静态方法，通过类名直接调用</li>
<li>睡眠的单位是毫秒</li>
<li>sleep()有受检异常需要预处理</li>
<li>sleep()方法所在的线程睡眠</li>
</ul>
<p>线程中断（t1.interrupt()）</p>
<ul>
<li>一般情况下，是把处于睡眠&#x2F;等待中的线程给中断</li>
</ul>
<p>线程让步（Thread.yield()）</p>
<ul>
<li>把线程转换为就绪状态，重新争抢CPU执行权</li>
</ul>
<p>线程加入（合并，t1.join()）</p>
<p>终止线程</p>
<ul>
<li>想办法让run()</li>
<li>在线程中设置一个标志，定期判断这个标志是否发生变化，标志发生变化就退出run()方法</li>
</ul>
<h2 id="线程同步"><a href="#线程同步" class="headerlink" title="线程同步"></a>线程同步</h2><ul>
<li>线程安全问题。<ul>
<li>当多个线程同时操作堆区或者方法区的某个数据时，可能会出现数据不一致的现象，称为线程安全问题。</li>
</ul>
</li>
<li>出现线程安全问题怎么办？<ul>
<li>每个线程都访问自己的局部变量。</li>
<li>如果多个线程必须同时操作实例变量&#x2F;静态变量时，可以采用线程同步技术</li>
</ul>
</li>
<li>线程同步技术解决什么问题？<ul>
<li>当一个线程在操作期间，不允许其他的线程加入。</li>
<li>某一段代码在某一时刻只能由一个线程执行</li>
</ul>
</li>
</ul>
<p>同步</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">synchronized（锁对象）&#123;</span><br><span class="line">	同步代码块</span><br><span class="line">&#125;</span><br><span class="line">工作原理：</span><br><span class="line">	1）任意对象都可以作为锁对象，每个对象有一个内置锁</span><br><span class="line">	2）某一时刻，锁对象最多只能被一个线程持有。</span><br><span class="line">	3）如果线程获得了锁对象后，会一直持有，直到执行完同步代码块后才释放</span><br><span class="line">	4）线程要执行同步代码块，必须先获得锁对象。</span><br><span class="line">场景描述：假设有线程A和线程B两个线程都想要执行同步代码块。</span><br><span class="line">	1）线程A获得CPU执行权，获得了锁对象后，开始执行同步代码块</span><br><span class="line">	2）线程A在执行同步代码块期间，CPU执行权被线程B抢走了，线程A转为就绪状态</span><br><span class="line">	3）线程B获得CPU执行权，也想要执行同步代码块，必须先获得锁对象，现在锁对象被线程A持有，线程B转到等待锁对象池中进行阻塞</span><br><span class="line">	4）线程A重新获得CPU执行权，执行完同步代码块后释放锁对象。</span><br><span class="line">	5）等待锁对象池中的线程B获得了锁对象，转为就绪状态。</span><br></pre></td></tr></table></figure>

<p>死锁</p>
<p>当多个线程同步时，获得锁的顺序不一致，导致线程相互等待的情况，称为死锁现象</p>
<p>如何避免</p>
<p>保证锁的顺序都一直</p>
<img data-src="/2019/01/28/java/Java%E5%9F%BA%E7%A1%803/2.png" class="">

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java数组</title>
    <url>/2024/06/30/java/Java%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<h2 id="数组拷贝"><a href="#数组拷贝" class="headerlink" title="数组拷贝"></a>数组拷贝</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		 // 这样拷贝数组没有隔离性</span><br><span class="line">		 String[] ss1 = &#123; &quot;1&quot;, &quot;2&quot;, &quot;3&quot; &#125;;</span><br><span class="line">		 // 把ss1对数组的引用传递给变量ss2,两个变量指向的是用一个数组</span><br><span class="line">		 String[] ss2 = ss1;</span><br><span class="line">		 ss2[0] = &quot;4&quot;;</span><br><span class="line">		 System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		// 方法1</span><br><span class="line">		// 推荐</span><br><span class="line">		String[] ss1 = &#123; &quot;1&quot;, &quot;2&quot;, &quot;3&quot; &#125;;</span><br><span class="line">		// 通过new关键字再内存中开辟一块空间，ss2指向的是新的数组对象</span><br><span class="line">		String[] ss2 = new String[ss1.length];</span><br><span class="line">		for (int i = 0; i &lt; ss2.length; i++) &#123;</span><br><span class="line">			ss2[i] = ss1[i];</span><br><span class="line">		&#125;</span><br><span class="line">		ss2[0] = &quot;张三&quot;;</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		// 方法2</span><br><span class="line">		// API提供的方式，底层用C++写的，所以速度很快，比for循环的效率高</span><br><span class="line">		String[] ss1 = &#123; &quot;1&quot;, &quot;2&quot;, &quot;3&quot; &#125;;</span><br><span class="line">		String[] ss2 = new String[ss1.length];</span><br><span class="line">		System.arraycopy(ss1, 0, ss2, 0, ss1.length);</span><br><span class="line">		/**</span><br><span class="line">		 * (Object src,int srcPos,Object dest,int destPos,int length)</span><br><span class="line">		 * src:源数组,srcPos:源数组要复制的起始位置;dest:目的数组;destPos:目的数组放置的起始位置;length:复制的长度</span><br><span class="line">		 * 注意：src and dest都必须是同类型或者可以进行转换类型的数组．</span><br><span class="line">		 * 有趣的是这个函数可以实现自己到自己复制，比如：</span><br><span class="line">		 * int[] fun =&#123;0,1,2,3,4,5,6&#125;; </span><br><span class="line">		 * System.arraycopy(fun,0,fun,3,3);</span><br><span class="line">		 * 则结果为：&#123;0,1,2,0,1,2,6&#125;;</span><br><span class="line">		 */</span><br><span class="line">		System.out.println(Arrays.toString(ss2));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		//方法3</span><br><span class="line">		String[] ss1 = &#123; &quot;1&quot;, &quot;2&quot;, &quot;3&quot; &#125;;</span><br><span class="line">		String[] ss2 = Arrays.copyOf(ss1, ss1.length);</span><br><span class="line">		/**</span><br><span class="line">		 *该方法对应不同的数据类型都有各自的重载方法</span><br><span class="line">		 *original - 要复制的数组</span><br><span class="line">		 *newLength - 要返回的副本的长度</span><br><span class="line">		 *newType - 要返回的副本的类型</span><br><span class="line">		 *仔细观察发现，copyOf()内部调用了System.arraycopy()方法</span><br><span class="line">		 *区别在于：</span><br><span class="line">		 *arraycopy()需要目标数组，将原数组拷贝到你自己定义的数组里，而且可以选择拷贝的起点和长度以及放入新数组中的位置</span><br><span class="line">		 *copyOf()是系统自动在内部新建一个数组，调用arraycopy()将original内容复制到copy中去，并且长度为newLength。返回copy; 即将原数组拷贝到一个长度为newLength的新数组中，并返回该数组。</span><br><span class="line">		 *总结</span><br><span class="line">		 *Array.copyOf()可以看作是受限的System.arraycopy()，它主要是用来将原数组全部拷贝到一个新长度的数组，适用于数组扩容。</span><br><span class="line">		 */</span><br><span class="line">		System.out.println(Arrays.toString(ss2));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="数组扩容"><a href="#数组扩容" class="headerlink" title="数组扩容"></a>数组扩容</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		String[] ss1 = &#123; &quot;1&quot;, &quot;2&quot;, &quot;3&quot; &#125;;</span><br><span class="line">		ss1 = Arrays.copyOf(ss1, ss1.length + 2);</span><br><span class="line">		System.out.println(ss1.length);</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">		// 5</span><br><span class="line">		// [1, 2, 3, null, null]</span><br><span class="line">	&#125;</span><br><span class="line">常见面试题: 统计字符的位置</span><br><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		String str = &quot;统计一个字符再字符串中的所有位置&quot;;</span><br><span class="line">		int[] arry = countAll(str, &#x27;字&#x27;);</span><br><span class="line">		System.out.println(Arrays.toString(arry));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	private static int[] countAll(String str, char ch) &#123;</span><br><span class="line">		int[] array = &#123;&#125;;// 创建一个空数组</span><br><span class="line">		for (int i = 0; i &lt; str.length(); i++) &#123;</span><br><span class="line">			if (ch == str.charAt(i)) &#123;</span><br><span class="line">				// charAt(i)遍历String每个字符</span><br><span class="line">				array = Arrays.copyOf(array, array.length + 1);</span><br><span class="line">				// 扩容</span><br><span class="line">				array[array.length - 1] = i;</span><br><span class="line">				// 刚扩容的位置</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return array;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="数组排序"><a href="#数组排序" class="headerlink" title="数组排序"></a>数组排序</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">	public static void main(String[] args) &#123;</span><br><span class="line">		//Java提供排序方法</span><br><span class="line">		int[] ss1= &#123;2,3,1&#125;;</span><br><span class="line">		Arrays.sort(ss1);</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		// 方法1</span><br><span class="line">		// 冒泡排序，前一个数与后一个数进行比较</span><br><span class="line">		int[] ss1 = &#123; 2, 3, 1 &#125;;</span><br><span class="line">		int temp = 0;</span><br><span class="line">		for (int i = 0; i &lt; ss1.length - 1; i++) &#123;</span><br><span class="line">			for (int j = i + 1; j &lt; ss1.length; j++) &#123;</span><br><span class="line">				if (ss1[j] &lt; ss1[i]) &#123;</span><br><span class="line">					temp = ss1[i];</span><br><span class="line">					ss1[i] = ss1[j];</span><br><span class="line">					ss1[j] = temp;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		// 方法2</span><br><span class="line">		// 选择排序</span><br><span class="line">		int[] ss1 = &#123; 2, 3, 1 &#125;;</span><br><span class="line">		int temp = 0;</span><br><span class="line">		for (int i = 0; i &lt; ss1.length - 1; i++) &#123;</span><br><span class="line">			int min = i;</span><br><span class="line">			for (int j = i + 1; j &lt; ss1.length; j++) &#123;</span><br><span class="line">				if (ss1[min] &gt; ss1[j]) &#123;</span><br><span class="line">					// 找到比选定下标小的数</span><br><span class="line">					min = j;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">			if (min != i) &#123;</span><br><span class="line">				// 交换位置</span><br><span class="line">				temp = ss1[i];</span><br><span class="line">				ss1[i] = ss1[min];</span><br><span class="line">				ss1[min] = temp;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line">public static void main(String[] args) &#123;</span><br><span class="line">		// 方法3</span><br><span class="line">		// 插入排序</span><br><span class="line">		int[] ss1 = &#123; 2, 3, 1 &#125;;</span><br><span class="line">		int temp = 0;</span><br><span class="line">		for (int i = 1; i &lt; ss1.length; i++) &#123;</span><br><span class="line">			for (int j = i; j &gt; 0; j--) &#123;</span><br><span class="line">				if (ss1[j] &lt; ss1[j - 1]) &#123;</span><br><span class="line">					temp = ss1[j];</span><br><span class="line">					ss1[j] = ss1[j - 1];</span><br><span class="line">					ss1[j - 1] = temp;</span><br><span class="line">				&#125; else</span><br><span class="line">					break;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		System.out.println(Arrays.toString(ss1));</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// 有序数组,二分查找</span><br><span class="line">	static int bingarySerarch(int[] array, int num) &#123;</span><br><span class="line">		int low = 0;</span><br><span class="line">		int high = array.length - 1;</span><br><span class="line">		while (low &lt;= high) &#123;</span><br><span class="line">			int mid = (low + high) / 2;</span><br><span class="line">			if (num &gt; array[mid]) &#123;</span><br><span class="line">				low = mid + 1;</span><br><span class="line">			&#125; else if (num &lt; array[mid]) &#123;</span><br><span class="line">				high = mid - 1;</span><br><span class="line">			&#125; else &#123;</span><br><span class="line">				return mid;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return -1;</span><br><span class="line">	&#125;</span><br><span class="line">// 无序数组，采用遍历，也可以先排序，后采用二分查找</span><br><span class="line">	static int search(int[] array, int num) &#123;</span><br><span class="line">		int index = -1;</span><br><span class="line">		for (int i = 0; i &lt; array.length; i++) &#123;</span><br><span class="line">			if (num == array[i]) &#123;</span><br><span class="line">				index = i;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		return index;</span><br><span class="line">	&#125;</span><br><span class="line">// Java 提供的查找方式。查看源码，它的本质就是二分查找</span><br><span class="line">	static void test(int[] array, int num) &#123;</span><br><span class="line">		/**</span><br><span class="line">		 * binarySearch(Object[], Object key) a: 要搜索的数组 key：要搜索的值</span><br><span class="line">		 * 如果key在数组中，则返回搜索值的索引；否则返回-1或“-”（插入点）。插入点是索引键将要插入数组的那一点，即第一个大于该键的元素的索引。 技巧： [1]</span><br><span class="line">		 * 搜索值不是数组元素，且在数组范围内，从1开始计数，得“ - 插入点索引值”； [2] 搜索值是数组元素，从0开始计数，得搜索值的索引值； [3]</span><br><span class="line">		 * 搜索值不是数组元素，且大于数组内元素，索引值为 – (length + 1); [4] 搜索值不是数组元素，且小于数组内元素，索引值为 – 1。</span><br><span class="line">		 */</span><br><span class="line">		int index = Arrays.binarySearch(array, 8);</span><br><span class="line">		System.out.println(index);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java核心数据结构(List、Map、Set)原理与使用技巧</title>
    <url>/2019/04/06/java/Java%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84(List%E3%80%81Map%E3%80%81Set)%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</url>
    <content><![CDATA[<blockquote>
<p>JDK提供了一组主要的数据结构实现，如List、Map、Set等常用数据结构。这些数据都继承自java.util.Collection接口，并位于java.util包内</p>
</blockquote>
<h1 id="List接口"><a href="#List接口" class="headerlink" title="List接口"></a>List接口</h1><p>最重要的三种List接口实现：ArrayList、Vector、LinkedList。它们的类图如下：</p>
<img data-src="/2019/04/06/java/Java%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84(List%E3%80%81Map%E3%80%81Set)%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/1.png" class="">

<p>可以看到，3种List均来自AbstratList的实现。</p>
<p>而AbstratList直接实现了List接口，并扩展自AbstratCollection。</p>
<p>ArrayList和Vector使用了数组实现，可以认为，ArrayList封装了对内部数组的操作。比如向数组中添加、删除、插入新的元素或数组的扩展和重定义。对ArrayList或者Vector的操作，等价于对内部对象数组的操作。</p>
<p>ArrayList和Vector几乎使用了相同的算法，它们的唯一区别可以认为是对多线程的支持。ArrayList没有对一个方法做线程同步，因此不是线程安全的。Vector中绝大多数方法都做了线程同步，是一种线程安全的实现。因此ArrayList和Vector的性能特性相差无几。</p>
<p>LinkedList使用了循环双向链表数据结构。LinkedList由一系列表项连接而成。一个表项总是包含3个部分：元素内容、前驱表项和后驱表项。如图所示：</p>
<img data-src="/2019/04/06/java/Java%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84(List%E3%80%81Map%E3%80%81Set)%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/2.png" class="">

<p>LinkedList的表项源码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static class Node&lt;E&gt; &#123;</span><br><span class="line">    E item;</span><br><span class="line">    Node&lt;E&gt; next;</span><br><span class="line">    Node&lt;E&gt; prev;</span><br><span class="line"></span><br><span class="line">    Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123;</span><br><span class="line">        this.item = element;</span><br><span class="line">        this.next = next;</span><br><span class="line">        this.prev = prev;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>无论LinkedList是否为空，链表都有一个header表项，它既是链表的开始，也表示链表的结尾。它的后驱表项便是链表的第一个元素，前驱表项便是链表的最后一个元素。如图所示：</p>
<img data-src="/2019/04/06/java/Java%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84(List%E3%80%81Map%E3%80%81Set)%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/3.png" class="">

<p>下面比较下ArrayList和LinkedList的不同。</p>
<h2 id="增加元素到列表尾端"><a href="#增加元素到列表尾端" class="headerlink" title="增加元素到列表尾端"></a>增加元素到列表尾端</h2><p>对于ArrayList来说，只要当前容量足够大，add()操作的效率是非常高的。</p>
<p>只有当ArrayList对容量的需求超过当前数组的大小时，才需要进行扩容。扩容会进行大量的数组复制操作。而复制时最终调用的是System.arraycopy()方法，因此，add()效率还是相当高的。</p>
<p>LinkedList由于使用了链表的结构，因此不需要维护容量的大小。这点比ArrayList有优势，不过，由于每次元素增加都需要新建Node对象，并进行更多的赋值操作。在频繁的系统调用中，对性能会产生一定影响。</p>
<h2 id="插入元素到列表任意位置"><a href="#插入元素到列表任意位置" class="headerlink" title="插入元素到列表任意位置"></a>插入元素到列表任意位置</h2><p>ArrayList是基于数组实现的，而数组是一块连续的内存空间，每次插入操作，都会进行一次数组复制。大量的数组复制会导致系统性能低下。</p>
<p>LinkedList是基于链表实现的，在任意位置插入和在尾端增加是一样的。所以，如果系统应用需要对List对象在任意位置进行频繁的插入操作，可以考虑用LinkedList替代ArrayList。</p>
<h2 id="容量参数"><a href="#容量参数" class="headerlink" title="容量参数"></a>容量参数</h2><p>容量参数是ArrayList 和 Vector等基于数组的List的特有性能参数，它表示初始数组的大小。</p>
<p>合理的设置容量参数，可以减少数组扩容，提升系统性能。</p>
<p>默认ArrayList的数组初始大小为10。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static final int DEFAULT_CAPACITY = 10;</span><br></pre></td></tr></table></figure>

<h2 id="遍历列表"><a href="#遍历列表" class="headerlink" title="遍历列表"></a>遍历列表</h2><p>常用的三种列表遍历方式：ForEach操作、迭代器和for循环。</p>
<p>对于ForEach操作，反编译可知实际上是将ForEach循环体作为迭代器处理。不过ForEach比自定义的迭代器多了一步赋值操作，性能不如直接使用迭代器的方式。</p>
<p>使用For循环通过随机访问遍历列表，ArrayList表现很好，速度最快；但是LinkedList的表现非常差，应避免使用，这是因为对LinkedList的随机访问时，总会进行一次列表的遍历操作。</p>
<h1 id="Map接口"><a href="#Map接口" class="headerlink" title="Map接口"></a>Map接口</h1><p>Map是一种非常常用的数据结构。围绕着Map接口，最主要的实现类有Hashtable, HashMap, LinkedHashMap 和 TreeMap，在Hashtable中，还有Properties 类的实现。</p>
<img data-src="/2019/04/06/java/Java%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84(List%E3%80%81Map%E3%80%81Set)%E5%8E%9F%E7%90%86%E4%B8%8E%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/4.png" class="">

<p>Hashtable和hashMap的区别在于Hashtable的大部分方法都做了线程同步，而HashMap没有，</p>
<p>因此，Hashtable是线程安全的，HashMap不是。</p>
<p>其次，Hashtable 不允许key或value使用null值，而HashMap可以。</p>
<p>第三，它们在内部对key的hash算法和hash值到内存索引的映射算法不同。</p>
<p>由于HashMap使用广泛，本文以HashMap为例，阐述它的实现原理。</p>
<h2 id="HashMap的实现原理"><a href="#HashMap的实现原理" class="headerlink" title="HashMap的实现原理"></a>HashMap的实现原理</h2><p>简单来说，HashMap就是将key做hash算法，然后将hash值映射到内存地址，直接取得key所对应的数据。</p>
<p>在HashMap中，底层数据结构使用的是数组。所谓的内存地址，就是数组的下标索引。</p>
<p>用代码简单表示如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">object[key_hash] = value;</span><br></pre></td></tr></table></figure>

<h2 id="Hash冲突"><a href="#Hash冲突" class="headerlink" title="Hash冲突"></a>Hash冲突</h2><p>当需要存放的两个元素1和2经hash计算后，发现对应在内存中的同一个地址。此时HashMap又会如何处理以保证数据的完整存放？</p>
<p>在HashMap的底层使用数组，但数组内的元素不是简单的值，而是一个Entity类的对象。每一个Entity表项包括key，value，next，hash几项。注意这里的next部分，它指向另外一个Entity。</p>
<p>当put()操作有冲突时，新的Entity会替换原有的值，为了保证旧值不丢失，会将next指向旧值。这便实现了在一个数组空间内存放多个值项。因此，HashMap实际上是一个链表的数组。</p>
<p>而在进行get()操作时，如果定位到的数组元素不含链表（当前entry的next指向null），则直接返回；如果定位到的数组元素包含链表，则需要遍历链表，通过key对象的equals方法逐一比对查找。</p>
<h2 id="容量参数-1"><a href="#容量参数-1" class="headerlink" title="容量参数"></a>容量参数</h2><p>和ArrayList一样，基于数组的结构，不可避免的需要在数组空间不足时，进行扩展。而数组的重组比较耗时，因此对其做一定的优化很有必要了。</p>
<p>HashMap提供了两个可以指定初始化大小的构造函数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">HashMap(int initialCapacity) </span><br><span class="line">          构造一个带指定初始容量和默认负载因子 (0.75) 的空 HashMap。</span><br><span class="line"></span><br><span class="line">HashMap(int initialCapacity, float loadFactor) </span><br><span class="line">          构造一个带指定初始容量和负载因子的空 HashMap。</span><br></pre></td></tr></table></figure>

<p>其中，HashMap会使用大于等于initialCapacity并且是2的指数次幂的最小的整数作为内置数组的大小。</p>
<p>负载因子又叫做填充比，它是介于0和1之间的浮点数。</p>
<p>负载因子 &#x3D; 实际元素个数 &#x2F; 内部数组总大小</p>
<p>负载因子的作用就是决定HashMap的阈值（threshold）。</p>
<p>阈值 &#x3D; 数组总容量 × 负载因子</p>
<p>当HashMap的实际容量超过阈值便会进行扩容，每次扩容将新的数组大小设置为原大小的1.5倍。</p>
<p>默认情况下，HashMap的初始大小是16，负载因子为0.75。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16</span><br><span class="line">static final float DEFAULT_LOAD_FACTOR = 0.75f;</span><br></pre></td></tr></table></figure>

<h2 id="LinkedHashMap"><a href="#LinkedHashMap" class="headerlink" title="LinkedHashMap"></a>LinkedHashMap</h2><p>LinkedHashMap继承自HashMap，因此，它具备了HashMap的优良特性，并在此基础上，LinkedHashMap又在内部增加了一个链表，用以存放元素的顺序。</p>
<p>因此，LinkedHashMap可以简单理解为一个维护了元素次序表的HashMap.</p>
<p>LinkedHashMap提供两种类型的顺序：一是元素插入时的顺序；二是最近访问的顺序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LinkedHashMap(int initialCapacity, float loadFactor, boolean accessOrder) </span><br><span class="line">          构造一个带指定初始容量、负载因子和排序模式的空 LinkedHashMap 实例</span><br></pre></td></tr></table></figure>

<p>其中accessOrder为true时，按照元素最后访问时间排序；当accessOrder为false 时，按照插入顺序排序。默认为 false 。</p>
<p>在内部实现中，LinkedHashMap通过继承HashMap.Entity类，实现LinkedHashMap.Entity，为HashMap.Entity增加了before和after属性用以记录某一表项的前驱和后继，并构成循环链表。</p>
<h2 id="TreeMap"><a href="#TreeMap" class="headerlink" title="TreeMap"></a>TreeMap</h2><p>TreeMap可以简单理解为一种可以进行排序的Map实现。与LinkedHashMap不同，LinkedHashMap是根据元素增加或者访问的先后顺序进行排序，而TreeMap则根据元素的Key进行排序。为了确定Key的排序算法，可以使用两种方式指定：</p>
<ul>
<li>在TreeMap的构造函数中注入一个Comparator：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TreeMap(Comparator&lt;? super K&gt; comparator) </span><br></pre></td></tr></table></figure>
<ul>
<li>使用一个实现了 Comparable 接口的 Key。</li>
</ul>
<p>TreeMap的内部实现是基于红黑树的。红黑树是一种平衡查找树，这里不做过多介绍。</p>
<p>TreeMap 其它排序接口如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">subMap(K fromKey, K toKey) </span><br><span class="line">          返回此映射的部分视图，其键值的范围从 fromKey（包括）到 toKey（不包括）。</span><br><span class="line"></span><br><span class="line">tailMap(K fromKey) </span><br><span class="line">          返回此映射的部分视图，其键大于等于 fromKey。</span><br><span class="line"></span><br><span class="line">firstKey() </span><br><span class="line">          返回此映射中当前第一个（最低）键。</span><br><span class="line"></span><br><span class="line">headMap(K toKey) </span><br><span class="line">          返回此映射的部分视图，其键值严格小于 toKey。</span><br><span class="line"></span><br><span class="line">一个简单示例如下：</span><br><span class="line">public class MyKey implements Comparable&lt;MyKey&gt; &#123;</span><br><span class="line">    private int id;</span><br><span class="line"></span><br><span class="line">    public MyKey(int id) &#123;</span><br><span class="line">        this.id = id;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(MyKey o) &#123;</span><br><span class="line">        if (o.id &lt; this.id)&#123;</span><br><span class="line">            return 1;</span><br><span class="line">        &#125;else if (o.id &gt; this.id)&#123;</span><br><span class="line">            return -1;</span><br><span class="line">        &#125;</span><br><span class="line">        return 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        MyKey myKey1 = new MyKey(1);</span><br><span class="line">        MyKey myKey2 = new MyKey(2);</span><br><span class="line">        MyKey myKey3 = new MyKey(3);</span><br><span class="line">        Map&lt;MyKey,Object&gt; map = new TreeMap&lt;&gt;();</span><br><span class="line">        map.put(myKey1,&quot;一号&quot;);</span><br><span class="line">        map.put(myKey3,&quot;三号&quot;);</span><br><span class="line">        map.put(myKey2,&quot;二号&quot;);</span><br><span class="line"></span><br><span class="line">        Iterator&lt;MyKey&gt; iterator = map.keySet().iterator();</span><br><span class="line">        while (iterator.hasNext())&#123;</span><br><span class="line">            System.out.println(map.get(iterator.next()));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Set接口"><a href="#Set接口" class="headerlink" title="Set接口"></a>Set接口</h1><p>Set并没有在Collection接口之上增加额外的操作，Set集合中的元素是不能重复的。<br>其中最为重要的是HashSet、LinkedHashSet、TreeSet 的实现。这里不再一一赘述，因为所有的这些Set实现都只是对应的Map的一种封装而已。</p>
<h1 id="优化集合访问代码"><a href="#优化集合访问代码" class="headerlink" title="优化集合访问代码"></a>优化集合访问代码</h1><h2 id="分离循环中被重复调用的代码"><a href="#分离循环中被重复调用的代码" class="headerlink" title="分离循环中被重复调用的代码"></a>分离循环中被重复调用的代码</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">举个例子，当我们要使用for循环遍历集合时</span><br><span class="line">for (int i =0;i&lt;collection.size();i++)&#123;</span><br><span class="line">    //.....</span><br><span class="line">&#125;</span><br><span class="line">很明显，每次循环都会调用size()方法，并且每次都会返回相同的数值。分离所有类似的代码对提升循环性能有着积极地意义。因此，可以将上段代码改造成</span><br><span class="line">int size= collection.size();</span><br><span class="line">for (int i =0;i&lt;size;i++)&#123;</span><br><span class="line">    //.....</span><br><span class="line">&#125;</span><br><span class="line">当元素的数量越多时，这样的处理就越有意义。</span><br></pre></td></tr></table></figure>

<h2 id="省略相同的操作"><a href="#省略相同的操作" class="headerlink" title="省略相同的操作"></a>省略相同的操作</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">假设我们有一段类似的操作如下</span><br><span class="line">int size= collection.size();</span><br><span class="line">for (int i =0;i&lt;size;i++)&#123;</span><br><span class="line">    if (list.get(i)==1||list.get(i)==2||list.get(i)==3)&#123;</span><br><span class="line">        //...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">虽然每次循环调用get(i)的返回值不同，但在同一次调用中，结果是相同的，因此可以提取这些相同的操作。</span><br><span class="line">int size= collection.size();</span><br><span class="line">int k=0;</span><br><span class="line">for (int i =0;i&lt;size;i++)&#123;</span><br><span class="line">    if ((k = list.get(i))==1||k==2||k==3)&#123;</span><br><span class="line">        //...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="减少方法调用"><a href="#减少方法调用" class="headerlink" title="减少方法调用"></a>减少方法调用</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">方法调用是需要消耗系统堆栈的，如果可以，则尽量访问内部元素，而不要调用对应的接口，函数调用是需要消耗系统资源的，直接访问元素会更高效。</span><br><span class="line">假设上面的代码是Vector.class的子类的部分代码，那么可以这么改写</span><br><span class="line">int size = this.elementCount;</span><br><span class="line">Object k=null;</span><br><span class="line">for (int i =0;i&lt;size;i++)&#123;</span><br><span class="line">    if ((k = elementData[i])==&quot;1&quot;||k==&quot;2&quot;||k==&quot;3&quot;)&#123;</span><br><span class="line">        //...</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">可以看到，原本的 size() 和 get() 方法被直接替代为访问原始变量，这对系统性能的提升是非常有用的。</span><br></pre></td></tr></table></figure>

<h1 id="RandomAccess接口"><a href="#RandomAccess接口" class="headerlink" title="RandomAccess接口"></a>RandomAccess接口</h1><p>RandomAccess接口是一个标志接口，本身并没有提供任何方法，任何实现RandomAccess接口的对象都可以认为是支持快速随机访问的对象。此接口的主要目的是标识那些可以支持快速随机访问的List实现。</p>
<p>在JDK中，任何一个基于数组的List实现都实现了RandomAccess接口，而基于链表的实现则没有。这很好理解，只有数组能够快速随机访问，（比如：通过 object[5]，object[6]可以直接查找并返回对象），而对链表的随机访问需要进行链表的遍历。</p>
<p>在实际操作中，可以根据list instanceof RandomAccess来判断对象是否实现 RandomAccess接口，从而选择是使用随机访问还是iterator迭代器进行访问。</p>
<p>在应用程序中，如果需要通过索引下标对 List 做随机访问，尽量不要使用 LinkedList，ArrayList和Vector都是不错的选择。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Thread Local</title>
    <url>/2019/04/06/java/Thread%20Local/</url>
    <content><![CDATA[<blockquote>
<p>高并发处理 : 在当前进程取出对象，不会冲突<br>放入的东西<br>各个线程保存的东西是分开只与进程有关系<br>每个进程会处理自己的内容</p>
</blockquote>
<h1 id="ThreadLocal"><a href="#ThreadLocal" class="headerlink" title="ThreadLocal"></a>ThreadLocal</h1><p>ThreadLocal的是一个本地线程副本变量工具类。</p>
<p>主要用于将私有线程和该线程存放的副本对象做一个映射，各个线程之间的变量互不干扰，在高并发场景下，可以实现无状态的调用，特别适用于各个线程依赖不通的变量值完成操作的场景。</p>
<p>原理大佬说的很清楚了》<a href="https://www.jianshu.com/p/98b68c97df9b">https://www.jianshu.com/p/98b68c97df9b</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">示例：</span><br><span class="line">   private static final ThreadLocal&lt;SysUser&gt; userHolder = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">   private static final ThreadLocal&lt;HttpServletRequest&gt; requestHolder = new ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">   public static void add(SysUser sysUser)&#123;</span><br><span class="line">       userHolder.set(sysUser);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   public static void add(HttpServletRequest request)&#123;</span><br><span class="line">       requestHolder.set(request);</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   public static SysUser getCurrentUser()&#123;</span><br><span class="line">       return userHolder.get();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   public static HttpServletRequest getCurrentRequest()&#123;</span><br><span class="line">       return requestHolder.get();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   public static void remove()&#123;</span><br><span class="line">       userHolder.remove();</span><br><span class="line">       requestHolder.remove();</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>获取ip</title>
    <url>/2019/04/06/java/%E8%8E%B7%E5%8F%96ip/</url>
    <content><![CDATA[<p>util</p>
<span id="more"></span>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">import lombok.extern.slf4j.Slf4j;</span><br><span class="line">import org.apache.commons.lang3.StringUtils;</span><br><span class="line"></span><br><span class="line">import javax.servlet.http.HttpServletRequest;</span><br><span class="line">import java.net.InetAddress;</span><br><span class="line">import java.net.UnknownHostException;</span><br><span class="line">import java.util.regex.Matcher;</span><br><span class="line">import java.util.regex.Pattern;</span><br><span class="line"></span><br><span class="line">@Slf4j</span><br><span class="line">public class IpUtil &#123;</span><br><span class="line"></span><br><span class="line">    public final static String ERROR_IP = &quot;127.0.0.1&quot;;</span><br><span class="line"></span><br><span class="line">    public final static Pattern pattern = Pattern.</span><br><span class="line">            compile(&quot;(2[5][0-5]|2[0-4]\\d|1\\d&#123;2&#125;|\\d&#123;1,2&#125;)\\.(25[0-5]|2[0-4]\\d|1\\d&#123;2&#125;|\\d&#123;1,2&#125;)\\.(25[0-5]|2[0-4]\\d|1\\d&#123;2&#125;|\\d&#123;1,2&#125;)\\.(25[0-5]|2[0-4]\\d|1\\d&#123;2&#125;|\\d&#123;1,2&#125;)&quot;);</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 取外网IP</span><br><span class="line">     *</span><br><span class="line">     * @param request</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public static String getRemoteIp(HttpServletRequest request) &#123;</span><br><span class="line">        String ip = request.getHeader(&quot;x-real-ip&quot;);</span><br><span class="line">        if (ip == null) &#123;</span><br><span class="line">            ip = request.getRemoteAddr();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        //过滤反向代理的ip</span><br><span class="line">        String[] stemps = ip.split(&quot;,&quot;);</span><br><span class="line">        if (stemps != null &amp;&amp; stemps.length &gt;= 1) &#123;</span><br><span class="line">            //得到第一个IP，即客户端真实IP</span><br><span class="line">            ip = stemps[0];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ip = ip.trim();</span><br><span class="line">        if (ip.length() &gt; 23) &#123;</span><br><span class="line">            ip = ip.substring(0, 23);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 获取用户的真实ip</span><br><span class="line">     *</span><br><span class="line">     * @param request</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public static String getUserIP(HttpServletRequest request) &#123;</span><br><span class="line"></span><br><span class="line">        // 优先取X-Real-IP</span><br><span class="line">        String ip = request.getHeader(&quot;X-Real-IP&quot;);</span><br><span class="line">        if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = request.getHeader(&quot;x-forwarded-for&quot;);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (ip == null || ip.length() == 0 || &quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = request.getRemoteAddr();</span><br><span class="line">            if (&quot;0:0:0:0:0:0:0:1&quot;.equals(ip)) &#123;</span><br><span class="line">                ip = ERROR_IP;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if (&quot;unknown&quot;.equalsIgnoreCase(ip)) &#123;</span><br><span class="line">            ip = ERROR_IP;</span><br><span class="line">            return ip;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        int pos = ip.indexOf(&#x27;,&#x27;);</span><br><span class="line">        if (pos &gt;= 0) &#123;</span><br><span class="line">            ip = ip.substring(0, pos);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String getLastIpSegment(HttpServletRequest request) &#123;</span><br><span class="line">        String ip = getUserIP(request);</span><br><span class="line">        if (ip != null) &#123;</span><br><span class="line">            ip = ip.substring(ip.lastIndexOf(&#x27;.&#x27;) + 1);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            ip = &quot;0&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        return ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static boolean isValidIP(HttpServletRequest request) &#123;</span><br><span class="line">        String ip = getUserIP(request);</span><br><span class="line">        return isValidIP(ip);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * 判断我们获取的ip是否是一个符合规则ip</span><br><span class="line">     *</span><br><span class="line">     * @param ip</span><br><span class="line">     * @return</span><br><span class="line">     */</span><br><span class="line">    public static boolean isValidIP(String ip) &#123;</span><br><span class="line">        if (StringUtils.isEmpty(ip)) &#123;</span><br><span class="line">            log.debug(&quot;ip is null. valid result is false&quot;);</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Matcher matcher = pattern.matcher(ip);</span><br><span class="line">        boolean isValid = matcher.matches();</span><br><span class="line">        log.debug(&quot;valid ip:&quot; + ip + &quot; result is: &quot; + isValid);</span><br><span class="line">        return isValid;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String getLastServerIpSegment() &#123;</span><br><span class="line">        String ip = getServerIP();</span><br><span class="line">        if (ip != null) &#123;</span><br><span class="line">            ip = ip.substring(ip.lastIndexOf(&#x27;.&#x27;) + 1);</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            ip = &quot;0&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        return ip;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static String getServerIP() &#123;</span><br><span class="line">        InetAddress inet;</span><br><span class="line">        try &#123;</span><br><span class="line">            inet = InetAddress.getLocalHost();</span><br><span class="line">            String hostAddress = inet.getHostAddress();</span><br><span class="line">            return hostAddress;</span><br><span class="line">        &#125; catch (UnknownHostException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        return &quot;127.0.0.1&quot;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Could-not-find-result-map</title>
    <url>/2019/01/19/%E9%97%AE%E9%A2%98/Could-not-find-result-map-20190119/</url>
    <content><![CDATA[<p>今天在写代码的时候，写完代码测试的时候发现登陆的时候登陆不进去，然后在登陆的断点处，抛出了这个异常</p>
<p><code>Could not find result map ren.guard.dao.SysDeptMapper.int</code></p>
<p>就是在 SysDeptMapper .xml里面本该是</p>
<p><code>resultType=&#39;int&#39;</code></p>
<p>写成了</p>
<p><code>resultMap=&#39;int&#39;</code></p>
]]></content>
      <categories>
        <category>问题</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>问题</tag>
      </tags>
  </entry>
  <entry>
    <title>问题：因为在此系统上禁止运行脚本。</title>
    <url>/2024/06/20/%E9%97%AE%E9%A2%98/%E9%97%AE%E9%A2%98%EF%BC%9A%E5%9B%A0%E4%B8%BA%E5%9C%A8%E6%AD%A4%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%A6%81%E6%AD%A2%E8%BF%90%E8%A1%8C%E8%84%9A%E6%9C%AC%E3%80%82/</url>
    <content><![CDATA[<h2 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h2><p>在VSCode终端使用npm命令时，出现如下报错信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm : 无法加载文件 D:\ProgramFiles\nodejs\npm.ps1，因为在此系统上禁止运行脚本。有关详细信息，请参阅 https:/go.microsoft.com/fwlink/?Link</span><br><span class="line">ID=135170 中的 about_Execution_Policies。</span><br><span class="line">所在位置 行:1 字符: 1</span><br><span class="line">+ npm i</span><br><span class="line">+ ~~~</span><br><span class="line">    + CategoryInfo          : SecurityError: (:) []，PSSecurityException</span><br><span class="line">    + FullyQualifiedErrorId : UnauthorizedAccess</span><br></pre></td></tr></table></figure>

<h2 id="解决方法："><a href="#解决方法：" class="headerlink" title="解决方法："></a>解决方法：</h2><p>在终端输入get-ExecutionPolicy查看执行策略&#x2F;权限；<br>输出Restricted(受限制的)；<br>终端输入Set-ExecutionPolicy -Scope CurrentUser命令给用户赋予权限；<br>输入RemoteSigned；<br>终端输入get-ExecutionPolicy查看一下权限，显示RemoteSigned就可以了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">get-ExecutionPolicy</span><br><span class="line">Set-ExecutionPolicy -Scope CurrentUser</span><br><span class="line">RemoteSigned</span><br><span class="line">get-ExecutionPolicy</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>问题</category>
      </categories>
      <tags>
        <tag>问题</tag>
      </tags>
  </entry>
</search>
